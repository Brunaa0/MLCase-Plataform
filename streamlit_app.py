########### Bibliotecas Necessﾃ｡rias ###########

# -------------------------------------
# 東 Bibliotecas para Interface com Utilizador (Streamlit)
# -------------------------------------
import streamlit as st  # Framework para criaﾃｧﾃ｣o de interfaces web interativas
import streamlit.components.v1 as components  # Permite adicionar componentes HTML/CSS personalizados

# -------------------------------------
# 東 Manipulaﾃｧﾃ｣o e Anﾃ｡lise de Dados
# -------------------------------------
import pandas as pd  # Manipulaﾃｧﾃ｣o de DataFrames e sﾃｩries temporais
import numpy as np  # Operaﾃｧﾃｵes numﾃｩricas e matrizes eficientes

# -------------------------------------
# 東 Visualizaﾃｧﾃ｣o de Dados
# -------------------------------------
import matplotlib.pyplot as plt  # Criaﾃｧﾃ｣o de grﾃ｡ficos estﾃ｡ticos
import seaborn as sns  # Grﾃ｡ficos estatﾃｭsticos avanﾃｧados baseados no Matplotlib
import plotly.express as px  # Grﾃ｡ficos interativos e visualizaﾃｧﾃｵes dinﾃ｢micas

# -------------------------------------
# 東 Modelos de Machine Learning
# -------------------------------------
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor  # Modelos baseados em ﾃ｡rvores de decisﾃ｣o
from sklearn.linear_model import LogisticRegression, LinearRegression  # Modelos lineares para classificaﾃｧﾃ｣o e regressﾃ｣o
from sklearn.svm import SVC, SVR  # Modelos de Support Vector Machine (SVM) para classificaﾃｧﾃ｣o e regressﾃ｣o
from sklearn.cluster import KMeans, AgglomerativeClustering  # Algoritmos de clustering
from sklearn.neighbors import KNeighborsClassifier  # Modelo de vizinhos mais prﾃｳximos (KNN)
from sklearn import svm, tree, neighbors  # Modelos adicionais do sklearn

# -------------------------------------
# 東 Seleﾃｧﾃ｣o de Features (Atributos)
# -------------------------------------
from mlxtend.feature_selection import SequentialFeatureSelector  # Seleﾃｧﾃ｣o sequencial de variﾃ｡veis para otimizar modelos

# -------------------------------------
# 東 Mﾃｩtricas de Avaliaﾃｧﾃ｣o
# -------------------------------------
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,  # Mﾃｩtricas para classificaﾃｧﾃ｣o
    confusion_matrix, classification_report, roc_auc_score,  # Matriz de confusﾃ｣o e anﾃ｡lise ROC
    mean_squared_error, mean_absolute_error, r2_score,  # Mﾃｩtricas para regressﾃ｣o
    silhouette_score, davies_bouldin_score, calinski_harabasz_score  # Mﾃｩtricas para clustering
)

# -------------------------------------
# 東 Prﾃｩ-Processamento e Pipeline
# -------------------------------------
from sklearn.model_selection import (
    train_test_split,  # Separaﾃｧﾃ｣o entre dados de treino e teste
    KFold, LeaveOneOut, cross_val_score,  # Validaﾃｧﾃ｣o cruzada para avaliar modelos
    GridSearchCV  # Procura de melhores hiperparﾃ｢metros usando Grid Search
)
from sklearn.preprocessing import StandardScaler, LabelEncoder  # Normalizaﾃｧﾃ｣o e codificaﾃｧﾃ｣o de variﾃ｡veis categﾃｳricas
from sklearn.impute import SimpleImputer  # Tratamento de valores ausentes

# -------------------------------------
# 東 Utilitﾃ｡rios Diversos
# -------------------------------------
import os  # Operaﾃｧﾃｵes no sistema de arquivos (criaﾃｧﾃ｣o de pastas, leitura de arquivos)
import joblib  # Guardar e carregar  modelos treinados
import pickle  # Serializaﾃｧﾃ｣o e desserializaﾃｧﾃ｣o de objetos Python
import json  # Manipulaﾃｧﾃ｣o de arquivos JSON
import requests  # Requisiﾃｧﾃｵes HTTP para acesso a APIs externas
import unidecode  # Remoﾃｧﾃ｣o de acentos e normalizaﾃｧﾃ｣o de caracteres especiais

# -------------------------------------
# 東 Manipulaﾃｧﾃ｣o de Arquivos e Dados Binﾃ｡rios
# -------------------------------------
from io import BytesIO  # Manipulaﾃｧﾃ｣o de streams binﾃ｡rios para arquivos em memﾃｳria
import tempfile  # Criaﾃｧﾃ｣o de arquivos e diretﾃｳrios temporﾃ｡rios

# -------------------------------------
# 東 Manipulaﾃｧﾃ｣o de Datas e Cﾃ｡lculos Matemﾃ｡ticos
# -------------------------------------
from datetime import datetime  # Manipulaﾃｧﾃ｣o de datas e horas
from decimal import Decimal  # Precisﾃ｣o extra em cﾃ｡lculos decimais
from fractions import Fraction  # Trabalha com fraﾃｧﾃｵes matemﾃ｡ticas exatas
from scipy.sparse import csr_matrix  # Representaﾃｧﾃ｣o eficiente de matrizes esparsas
import scipy  # Biblioteca cientﾃｭfica para estatﾃｭsticas, ﾃ｡lgebra linear e otimizaﾃｧﾃ｣o
import time  # Mediﾃｧﾃ｣o do tempo de execuﾃｧﾃ｣o de processos

# -------------------------------------
# 東 Bibliotecas para Geraﾃｧﾃ｣o de Relatﾃｳrios
# -------------------------------------
from fpdf import FPDF  # Criaﾃｧﾃ｣o de documentos PDF programaticamente
from reportlab.lib.pagesizes import letter  # Definiﾃｧﾃ｣o do tamanho da pﾃ｡gina nos relatﾃｳrios
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle  # Estilos para formataﾃｧﾃ｣o de texto
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image  # Estruturaﾃｧﾃ｣o de documentos PDF
from reportlab.lib import colors  # Definiﾃｧﾃ｣o de cores em relatﾃｳrios
from reportlab.lib.units import inch  # Unidades de medida para layout de documentos



##############################################
# -------------------------------------
# 東 Funﾃｧﾃ｣o JavaScript para voltar ao topo da pﾃ｡gina
# -------------------------------------

# Script JavaScript que permite rolar automaticamente para o topo da pﾃ｡gina
scroll_to_top_js = """
<script>
    function scrollToTop() {
        window.scrollTo(0, 0);  // Move a pﾃ｡gina para o topo (coordenadas 0,0)
    }
</script>
"""

# Insere o JavaScript na pﾃ｡gina com Streamlit
# Definiﾃｧﾃ｣o de height=0 e width=0 para evitar que o cﾃｳdigo ocupe espaﾃｧo visﾃｭvel na interface
components.html(scroll_to_top_js, height=0, width=0)  

# -------------------------------------
# 東 Ajustes de Exibiﾃｧﾃ｣o do Pandas Styler
# -------------------------------------

# Define o nﾃｺmero mﾃ｡ximo de elementos a serem renderizados no Styler do Pandas
pd.set_option("styler.render.max_elements", 2000000)  # Ajustar se necessﾃ｡rio para grandes DataFrames

# Configura a exibiﾃｧﾃ｣o de todas as linhas e colunas de um DataFrame
pd.set_option("display.max_rows", None)  # Permite visualizar todas as linhas sem truncamento
pd.set_option("display.max_columns", None)  # Permite visualizar todas as colunas sem truncamento


##############################################
def fix_dataframe_types(df):
    """Corrigir tipos de dados num DataFrame para compatibilidade com PyArrow"""

    # Verificar se o objeto ﾃｩ um Styler e extrair o DataFrame
    if hasattr(df, 'data'):  # Objetos Styler possuem um atributo .data
        df = df.data
    elif hasattr(df, 'render') and not hasattr(df, 'copy'):  # Outra forma de identificar um Styler
        # Para versﾃｵes mais recentes do pandas
        if hasattr(df, '_data'):
            df = df._data
        # Para versﾃｵes ainda mais recentes do pandas, onde a estrutura pode ser diferente
        elif hasattr(df, 'data'):
            df = df.data
        # Se ainda nﾃ｣o for possﾃｭvel extrair o DataFrame
        else:
            # Tentar converter primeiro para dicionﾃ｡rio e depois para DataFrame
            try:
                df = pd.DataFrame(df.to_dict())
            except:
                # Se falhar, retornar um DataFrame vazio
                return pd.DataFrame()
    
    # Se o objeto final nﾃ｣o for um DataFrame, retornar um DataFrame vazio
    if not isinstance(df, pd.DataFrame):
        return pd.DataFrame()
        
    # Criar uma cﾃｳpia do DataFrame para evitar modificar o original
    df_fixed = df.copy()
    
    # Percorrer todas as colunas para corrigir tipos de dados problemﾃ｡ticos
    for col in df_fixed.columns:
        # Converter colunas do tipo Int64 para int64 padrﾃ｣o (evita problemas de compatibilidade)
        if hasattr(df_fixed[col], 'dtype') and str(df_fixed[col].dtype) == 'Int64':
            df_fixed[col] = df_fixed[col].fillna(-1).astype('int64')  # Substituir valores nulos por -1 antes da conversﾃ｣o
        
        # Converter colunas do tipo objeto (strings e dados complexos) para string
        elif df_fixed[col].dtype == 'object':
            try:
                # Tentar converter diretamente para string
                df_fixed[col] = df_fixed[col].astype(str)
            except:
                # Se falhar, aplicar uma conversﾃ｣o manual, garantindo que valores None sejam tratados
                df_fixed[col] = df_fixed[col].apply(lambda x: str(x) if x is not None else "")
    
    # Retornar o DataFrame corrigido
    return df_fixed


##############################################
# -------------------------------------
# 東 Funﾃｧﾃ｣o para Configurar a Barra Lateral
# -------------------------------------

def configure_sidebar():
    """Configura a barra lateral com o logﾃｳtipo da instituiﾃｧﾃ｣o e informaﾃｧﾃｵes sobre a plataforma."""
    
    with st.sidebar:  # Define que os elementos serﾃ｣o adicionados na barra lateral
        st.image(
            "https://www.ipleiria.pt/normasgraficas/wp-content/uploads/sites/80/2017/09/estg_v-01.jpg",  # URL da imagem
            width=80,  # Define o tamanho da imagem (largura em pixels)
            caption="Logﾃｳtipo da Escola"  # Texto exibido abaixo da imagem
        )
        
        # Exibe o nome da plataforma em formato HTML para maior personalizaﾃｧﾃ｣o
        st.markdown("<p>MLCase - Plataforma de Machine Learning</p>", unsafe_allow_html=True)
        
        # Exibe o nome da autora com destaque em negrito usando HTML
        st.markdown("<p><b>Autora:</b> Bruna Sousa</p>", unsafe_allow_html=True)

# Chamada da funﾃｧﾃ｣o para configurar a barra lateral
configure_sidebar()


##############################################
import matplotlib
matplotlib.use('Agg')  # Usar backend nﾃ｣o interativo
import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
##############################################

# -------------------------------------
# 東 FUNﾃﾃグ DE UPLOAD DE FICHEIROS
# -------------------------------------

# Funﾃｧﾃ｣o para inicializar variﾃ｡veis de estado na aplicaﾃｧﾃ｣o
def initialize_state():
    """Inicializa variﾃ｡veis de estado utilizadas na aplicaﾃｧﾃ｣o para gerir diferentes etapas do processo."""
    st.session_state.step = 'data_preview'  # Define o estado inicial como prﾃｩ-visualizaﾃｧﾃ｣o dos dados
    st.session_state.selected_columns = []  # Lista para armazenar colunas selecionadas pelo utilizador
    st.session_state.numeric_types = {}  # Dicionﾃ｡rio para armazenar tipos numﾃｩricos das variﾃ｡veis
    st.session_state.variable_types = {}  # Dicionﾃ｡rio para armazenar os tipos das variﾃ｡veis
    st.session_state.treatment_state = {}  # Dicionﾃ｡rio para armazenar o estado do tratamento dos dados
    st.session_state.all_treated = False  # Flag para indicar se todos os dados foram tratados

# -------------------------------------
# 東 Funﾃｧﾃ｣o auxiliar para escolher o delimitador de ficheiros CSV
# -------------------------------------

def choose_delimiter():
    """Permite ao utilizador escolher um delimitador para ficheiros CSV carregados."""
    
    # Lista de delimitadores comuns, incluindo a opﾃｧﾃ｣o personalizada
    delimiters = [",", ";", "\t", "|", "Outro"]
    
    # Cria um seletor na barra lateral para escolha do delimitador
    delimiter = st.sidebar.selectbox("Escolha o delimitador para CSV", delimiters, index=0)
    
    # Se o utilizador escolher a opﾃｧﾃ｣o "Outro", permite inserir um delimitador personalizado
    if delimiter == "Outro":
        delimiter = st.sidebar.text_input("Digite o delimitador personalizado:")
    
    return delimiter

# -------------------------------------
# 東 Funﾃｧﾃ｣o para a etapa de upload do ficheiro
# -------------------------------------

def upload_file():
    """Permite ao utilizador carregar um ficheiro de dados para a plataforma."""
    
    st.title("MLCase - Plataforma de Machine Learning")  # Tﾃｭtulo principal da aplicaﾃｧﾃ｣o

    # Seleﾃｧﾃ｣o do tipo de ficheiro a ser carregado
    file_type = st.sidebar.selectbox("Selecione o tipo de arquivo", ["CSV", "Excel", "JSON"])
    delimiter = ","  # Define o delimitador padrﾃ｣o para CSV

    # Processo de upload conforme o tipo de ficheiro selecionado
    if file_type == "CSV":
        delimiter = choose_delimiter()  # Permite selecionar um delimitador para o CSV
        file = st.sidebar.file_uploader("Carregar arquivo", type=["csv"])  # Botﾃ｣o de upload
    elif file_type == "Excel":
        file = st.sidebar.file_uploader("Carregar arquivo", type=["xlsx", "xls"])  # Upload de ficheiro Excel
    elif file_type == "JSON":
        file = st.sidebar.file_uploader("Carregar arquivo", type=["json"])  # Upload de ficheiro JSON

    # Se um ficheiro for carregado, tenta processﾃ｡-lo
    if file is not None:
        try:
            # Chama a funﾃｧﾃ｣o de carregamento de dados e inicializa as variﾃ｡veis de estado
            st.session_state.data = load_data(file_type, file, delimiter)
            initialize_state()
            st.sidebar.success(f"Conjunto de dados {file_type} carregado com sucesso!")  # Mensagem de sucesso

            # Botﾃ｣o para avanﾃｧar para a prﾃｳxima etapa (prﾃｩ-visualizaﾃｧﾃ｣o dos dados)
            if st.sidebar.button("Dados Carregados"):
                st.session_state.step = 'data_preview'  # Atualiza o estado para a prﾃｩ-visualizaﾃｧﾃ｣o
                st.stop()  # Para a execuﾃｧﾃ｣o para refletir as mudanﾃｧas

        except Exception as e:
            st.sidebar.error(f"Erro ao carregar o arquivo: {e}")  # Exibe mensagem de erro caso algo corra mal

# -------------------------------------
# 東 Funﾃｧﾃ｣o para carregar dados com cache (evita recarregamento desnecessﾃ｡rio)
# -------------------------------------

@st.cache_data  # Usa cache para evitar recarregar os dados vﾃ｡rias vezes
def load_data(file_type, file, delimiter):
    """Carrega um ficheiro de dados conforme o tipo selecionado pelo utilizador."""
    
    if file_type == "CSV":
        return pd.read_csv(file, delimiter=delimiter)  # Carrega dados CSV com o delimitador escolhido
    elif file_type == "Excel":
        return pd.read_excel(file)  # Carrega ficheiro Excel
    elif file_type == "JSON":
        return pd.read_json(file)  # Carrega ficheiro JSON

##############################################
# -------------------------------------
# 東 FUNﾃﾃグ DE SELEﾃﾃグ DE COLUNAS
# -------------------------------------

# Funﾃｧﾃ｣o para prﾃｩ-visualizar os dados e permitir a seleﾃｧﾃ｣o de colunas e tipos de variﾃ｡veis
def data_preview():
    """Permite visualizar os dados carregados, selecionar colunas e definir os seus tipos."""

    # Exibir uma prﾃｩ-visualizaﾃｧﾃ｣o dos primeiros registos do dataset (com correﾃｧﾃ｣o de tipos)
    st.subheader("Prﾃｩ-visualizaﾃｧﾃ｣o dos dados")
    st.dataframe(fix_dataframe_types(st.session_state.data.head()))  # Corrige os tipos antes da exibiﾃｧﾃ｣o

    # Obter a lista de colunas do dataset
    columns = st.session_state.data.columns.tolist()

    # Criar uma caixa de seleﾃｧﾃ｣o mﾃｺltipla para escolher quais colunas utilizar
    selected_columns = st.multiselect("Colunas", columns, columns)  # Por defeito, todas as colunas sﾃ｣o selecionadas
    st.session_state.selected_columns = selected_columns  # Guardar as colunas selecionadas no estado global

    # Preservar transformaﾃｧﾃｵes no estado global
    if 'filtered_data' not in st.session_state:
        st.session_state.filtered_data = st.session_state.data.copy()  # Criar uma cﾃｳpia inicial dos dados
    else:
        # Atualizar os dados filtrados apenas com as colunas selecionadas, mantendo transformaﾃｧﾃｵes jﾃ｡ aplicadas
        st.session_state.filtered_data = st.session_state.data[selected_columns]

    # Se houver colunas selecionadas, permitir a identificaﾃｧﾃ｣o dos tipos de variﾃ｡veis
    if selected_columns:
        st.subheader("Identificar tipos de variﾃ｡veis")

        # Inicializar dicionﾃ｡rio para armazenar os tipos de variﾃ｡veis, caso ainda nﾃ｣o exista
        if 'variable_types' not in st.session_state:
            st.session_state.variable_types = {}

        variable_types = st.session_state.variable_types
        st.session_state.numeric_types = {}  # Dicionﾃ｡rio para armazenar os tipos numﾃｩricos

        # Percorrer cada coluna selecionada para definir os tipos de variﾃ｡veis
        for col in selected_columns:
            # Criar um seletor para definir se a variﾃ｡vel ﾃｩ Numﾃｩrica, Categﾃｳrica ou Data
            var_type = st.selectbox(
                f"Tipo de variﾃ｡vel para {col}",
                ["Numﾃｩrica", "Categﾃｳrica", "Data"],
                index=0 if pd.api.types.is_numeric_dtype(st.session_state.filtered_data[col]) else 1,
                key=f"var_{col}"  # Cada seletor tem uma chave ﾃｺnica para evitar conflitos
            )
            variable_types[col] = var_type  # Guardar o tipo selecionado

            # Se a variﾃ｡vel for numﾃｩrica, permitir configurar o tipo especﾃｭfico
            if var_type == "Numﾃｩrica":
                num_type = st.selectbox(
                    f"Tipo numﾃｩrico para {col}",
                    ["Int", "Float", "Complex", "Dec", "Frac", "Bool"],
                    index=0 if pd.api.types.is_integer_dtype(st.session_state.filtered_data[col]) else 1,
                    key=f"num_{col}"  # Chave ﾃｺnica para o seletor de tipo numﾃｩrico
                )
                st.session_state.numeric_types[col] = num_type  # Guardar o tipo numﾃｩrico no estado global

                # Discretizaﾃｧﾃ｣o da variﾃ｡vel (conversﾃ｣o para categorias)
                # Verifica primeiro se a coluna jﾃ｡ foi discretizada
                if col not in st.session_state.filtered_data.columns or pd.api.types.is_numeric_dtype(st.session_state.filtered_data[col]):
                    if st.checkbox(f"Discretizar {col}?", key=f"discretize_{col}"):
                        discretize_column(col)  # Aplica a funﾃｧﾃ｣o de discretizaﾃｧﾃ｣o
                else:
                    st.write(f"Coluna {col} jﾃ｡ foi discretizada.")  # Informaﾃｧﾃ｣o para o utilizador

        # Atualizar o estado global com os tipos de variﾃ｡veis definidos
        st.session_state.variable_types = variable_types

    # Criar uma cﾃｳpia dos dados filtrados para manter alteraﾃｧﾃｵes recentes
    st.session_state.filtered_data = st.session_state.filtered_data.copy()

    # -------------------------------------
    # 東 Navegaﾃｧﾃ｣o entre etapas
    # -------------------------------------

    col1, col2 = st.columns(2)  # Criar duas colunas para os botﾃｵes "Voltar" e "Prﾃｳxima etapa"

    # Botﾃ｣o para voltar ﾃ etapa anterior
    with col1:
        if st.button("Voltar"):
            # Apagar estados salvos explicitamente para evitar conflitos
            keys_to_reset = [
                'filtered_data', 'selected_columns', 'variable_types',
                'numeric_types', 'treatment_state'
            ]
            for key in keys_to_reset:
                st.session_state.pop(key, None)  # Remove do estado se existir

            # Restaurar os dados originais
            st.session_state.data = st.session_state.data.copy()

            # Voltar para a etapa de upload do ficheiro
            st.session_state.step = 'file_upload'
            st.rerun()  # Recarregar a aplicaﾃｧﾃ｣o para refletir as mudanﾃｧas

    # Botﾃ｣o para avanﾃｧar para a prﾃｳxima etapa
    with col2:
        if st.button("Prﾃｳxima etapa"):
            apply_numeric_types()  # Aplicar os tipos numﾃｩricos definidos pelo utilizador
            st.session_state.step = 'missing_values'  # Atualizar o estado para a etapa seguinte
            st.rerun()  # Recarregar a aplicaﾃｧﾃ｣o para refletir as alteraﾃｧﾃｵes


# -------------------------------------
# 東 Funﾃｧﾃ｣o para Aplicar Tipos Numﾃｩricos ﾃs Colunas Filtradas
# -------------------------------------

def apply_numeric_types():
    """Aplica os tipos numﾃｩricos definidos pelo utilizador ﾃs colunas filtradas no dataset."""
    
    # Percorre todas as colunas que tﾃｪm tipos numﾃｩricos definidos pelo utilizador
    for col, num_type in st.session_state.numeric_types.items():
        # Verifica se a coluna ainda existe no conjunto de dados filtrado
        if col in st.session_state.filtered_data.columns:
            # Converte a coluna para o tipo numﾃｩrico selecionado
            st.session_state.filtered_data[col] = convert_numeric_type(st.session_state.filtered_data[col], num_type)

# -------------------------------------
# 東 Funﾃｧﾃ｣o para Conversﾃ｣o de Tipos de Dados Numﾃｩricos
# -------------------------------------

def convert_numeric_type(series, num_type):
    """
    Converte uma sﾃｩrie de dados para o tipo numﾃｩrico especificado.
    
    Parﾃ｢metros:
    - series: pd.Series -> Coluna do DataFrame a ser convertida.
    - num_type: str -> Tipo numﾃｩrico desejado ("Int", "Float", "Complex", "Dec", "Frac", "Bool", "Date", "Duration").

    Retorna:
    - pd.Series convertida para o tipo especificado ou a mesma sﾃｩrie original caso ocorra um erro.
    """
    
    try:
        # Conversﾃ｣o para nﾃｺmero inteiro (Int64)
        if num_type == "Int":
            return pd.to_numeric(series, errors='coerce').astype('Int64')  # Mantﾃｩm valores nulos compatﾃｭveis com Pandas

        # Conversﾃ｣o para nﾃｺmero decimal (Float)
        elif num_type == "Float":
            return pd.to_numeric(series, errors='coerce').astype(float)

        # Conversﾃ｣o para nﾃｺmero complexo
        elif num_type == "Complex":
            return pd.to_numeric(series, errors='coerce').apply(lambda x: complex(x) if pd.notnull(x) else np.nan)

        # Conversﾃ｣o para Decimal (melhor precisﾃ｣o para cﾃ｡lculos financeiros)
        elif num_type == "Dec":
            return series.apply(lambda x: Decimal(x) if pd.notnull(x) else np.nan)

        # Conversﾃ｣o para Fraﾃｧﾃ｣o (representaﾃｧﾃ｣o matemﾃ｡tica exata)
        elif num_type == "Frac":
            return series.apply(lambda x: Fraction(x) if pd.notnull(x) else np.nan)

        # Conversﾃ｣o para Booleano (True/False)
        elif num_type == "Bool":
            return series.apply(lambda x: str(x).strip().lower() in ['true', '1'])

        # Conversﾃ｣o para Data/Hora
        elif num_type == "Date":
            return pd.to_datetime(series, errors='coerce')

        # Conversﾃ｣o para Duraﾃｧﾃ｣o/Intervalo de Tempo
        elif num_type == "Duration":
            return pd.to_timedelta(series, errors='coerce')

        # Se o tipo especificado nﾃ｣o estiver listado, retorna a sﾃｩrie original sem alteraﾃｧﾃｵes
        else:
            return series

    except Exception as e:
        # Exibe um erro no Streamlit caso ocorra um problema na conversﾃ｣o
        st.error(f"Erro ao converter coluna {series.name} para tipo {num_type}: {e}")


# -------------------------------------
# 東 Funﾃｧﾃ｣o para Discretizar uma Coluna Numﾃｩrica
# -------------------------------------

def discretize_column(col):
    """Permite ao utilizador discretizar uma coluna numﾃｩrica, transformando-a em categorias definidas manualmente."""

    # -------------------------------------
    # 東 Seﾃｧﾃ｣o de Ajuda - Explicaﾃｧﾃ｣o sobre Discretizaﾃｧﾃ｣o
    # -------------------------------------
    
    # Explicaﾃｧﾃ｣o interativa sobre como definir bins (intervalos) e labels (categorias)
    with st.expander("Como preencher os bins e labels?"):
        st.write("**Bins:** Intervalos numﾃｩricos para discretizaﾃｧﾃ｣o.")
        st.write("**Labels:** Nomeiam os intervalos.")
        st.write("**Exemplo:**")
        st.write("- **Bins:** -2,1,2,6,inf")
        st.write("- **Labels:** Baixo, Mﾃｩdio, Alto, Muito Alto")

    # -------------------------------------
    # 東 Diagnﾃｳstico Inicial Antes da Discretizaﾃｧﾃ｣o
    # -------------------------------------

    st.write("### Diagnﾃｳstico antes da discretizaﾃｧﾃ｣o:")
    st.write(f"- **Mﾃｭnimo:** {st.session_state.filtered_data[col].min()}")  # Valor mﾃｭnimo da coluna
    st.write(f"- **Mﾃ｡ximo:** {st.session_state.filtered_data[col].max()}")  # Valor mﾃ｡ximo da coluna
    st.write(f"- **Mﾃｩdia:** {st.session_state.filtered_data[col].mean():.2f}")  # Mﾃｩdia da coluna
    st.write(f"- **Mediana:** {st.session_state.filtered_data[col].median():.2f}")  # Mediana da coluna
    st.write(f"- **Valores ausentes antes:** {st.session_state.filtered_data[col].isna().sum()}")  # Contagem de valores nulos

    # -------------------------------------
    # 東 Entrada de Dados do Utilizador (Bins e Labels)
    # -------------------------------------

    # Caixa de texto para o utilizador inserir os bins (intervalos numﾃｩricos)
    bins_input = st.text_input(
        f"Digite os bins para {col} (separados por vﾃｭrgulas)",
        value="-2,1,2,6,inf", key=f"bins_{col}"
    )

    # Caixa de texto para o utilizador inserir os labels (nomes das categorias correspondentes aos bins)
    labels_input = st.text_input(
        f"Digite os labels para {col} (separados por vﾃｭrgulas)",
        value="Baixo,Mﾃｩdio,Alto,Muito Alto", key=f"labels_{col}"
    )

    # -------------------------------------
    # 東 Aplicaﾃｧﾃ｣o da Discretizaﾃｧﾃ｣o Apﾃｳs Confirmaﾃｧﾃ｣o
    # -------------------------------------

    # Se o utilizador clicar no botﾃ｣o, iniciar a conversﾃ｣o
    if st.button(f"Confirmar Discretizaﾃｧﾃ｣o para {col}", key=f"confirm_{col}"):

        # Verificar se o utilizador preencheu os bins e labels corretamente
        if bins_input and labels_input:
            try:
                # Converter a string de bins para uma lista de valores numﾃｩricos (float)
                bins = list(map(float, bins_input.split(',')))

                # Converter a string de labels para uma lista de nomes de categorias
                labels = labels_input.split(',')

                # -------------------------------------
                # 東 Validaﾃｧﾃ｣o de Dados Antes da Conversﾃ｣o
                # -------------------------------------

                # O nﾃｺmero de labels deve ser igual ao nﾃｺmero de bins menos um
                if len(labels) != len(bins) - 1:
                    st.error(f"O nﾃｺmero de labels deve ser igual ao nﾃｺmero de bins menos um para a coluna {col}.")

                else:
                    # Converter a coluna para tipo numﾃｩrico para evitar erros
                    st.session_state.filtered_data[col] = pd.to_numeric(
                        st.session_state.filtered_data[col], errors='coerce'
                    )

                    # Preencher valores ausentes com a mediana da coluna
                    median_value = st.session_state.filtered_data[col].median()
                    st.session_state.filtered_data[col].fillna(median_value, inplace=True)

                    # Diagnﾃｳstico apﾃｳs preenchimento de valores ausentes
                    st.write(f"Valores ausentes apﾃｳs preenchimento: {st.session_state.filtered_data[col].isna().sum()}")

                    # -------------------------------------
                    # 東 Aplicaﾃｧﾃ｣o da Discretizaﾃｧﾃ｣o
                    # -------------------------------------

                    # Criar categorias com base nos bins e labels definidos pelo utilizador
                    categorized = pd.cut(
                        st.session_state.filtered_data[col],  # Coluna de dados a ser discretizada
                        bins=bins,  # Intervalos definidos
                        labels=labels,  # Nomes das categorias correspondentes
                        include_lowest=True  # Inclui o menor valor nos intervalos
                    )

                    # Converter para tipo categﾃｳrico
                    categorized = categorized.astype('category')

                    # Adicionar uma categoria extra para valores fora do intervalo definido
                    categorized = categorized.cat.add_categories(["Fora do Intervalo"])
                    categorized = categorized.fillna("Fora do Intervalo")  # Substituir valores nﾃ｣o categorizados

                    # -------------------------------------
                    # 東 Atualizaﾃｧﾃ｣o do Estado Global e Diagnﾃｳstico Final
                    # -------------------------------------

                    # Salvar a coluna discretizada no dataset filtrado
                    st.session_state.filtered_data[col] = categorized

                    # Criar uma nova cﾃｳpia do dataset para garantir a consistﾃｪncia dos dados
                    st.session_state.filtered_data = st.session_state.filtered_data.copy()

                    # Mensagem de sucesso
                    st.success(f"Coluna {col} discretizada com sucesso!")

                    # Exibir o tipo de dados final da coluna
                    st.write(st.session_state.filtered_data[col].dtype)

                    # Exibir as categorias ﾃｺnicas geradas
                    st.write(st.session_state.filtered_data[col].unique())

                    # Exibir uma prﾃｩ-visualizaﾃｧﾃ｣o dos dados apﾃｳs a discretizaﾃｧﾃ｣o
                    st.write("Prﾃｩ-visualizaﾃｧﾃ｣o dos dados apﾃｳs discretizaﾃｧﾃ｣o:")
                    st.dataframe(fix_dataframe_types(st.session_state.filtered_data.head()))

            except ValueError as e:
                # Mensagem de erro caso a conversﾃ｣o falhe
                st.error(f"Erro ao discretizar {col}: {e}")



##############################################
# -------------------------------------
# 東 FUNﾃﾃグ DE TRATAMENTO DE VALORES OMISSOS (MISSING VALUES)
# -------------------------------------

# -------------------------------------
# 東 Funﾃｧﾃ｣o para destacar valores ausentes no DataFrame
# -------------------------------------

def highlight_missing():
    """Aplica um estilo ao DataFrame, destacando cﾃｩlulas com valores ausentes em amarelo."""

    # Funﾃｧﾃ｣o interna que aplica a cor amarela ﾃs cﾃｩlulas com valores nulos (NaN)
    def highlight_na(s):
        return ['background-color: yellow' if pd.isnull(v) else '' for v in s]

    # Aplica o estilo ao DataFrame filtrado e retorna o objeto Styler
    return st.session_state.filtered_data.style.apply(highlight_na, subset=st.session_state.filtered_data.columns)

# -------------------------------------
# 東 Funﾃｧﾃ｣o para formatar valores na tabela
# -------------------------------------

def format_table():
    """Formata os valores do DataFrame para exibiﾃｧﾃ｣o, ajustando casas decimais e representaﾃｧﾃｵes de NaN."""
    
    # Criar uma cﾃｳpia do DataFrame para evitar modificar os dados originais
    formatted_df = st.session_state.filtered_data.copy()

    # Iterar sobre todas as colunas do DataFrame
    for col in formatted_df.columns:
        # Verificar se a coluna contﾃｩm valores numﾃｩricos
        if pd.api.types.is_numeric_dtype(formatted_df[col]):
            # Formatar os valores numﾃｩricos para exibiﾃｧﾃ｣o com 2 casas decimais
            formatted_df[col] = formatted_df[col].map(lambda x: f"{x:.2f}" if pd.notnull(x) else 'NaN')

    return formatted_df  # Retorna o DataFrame formatado

# -------------------------------------
# 東 Funﾃｧﾃ｣o para exibir a prﾃｩ-visualizaﾃｧﾃ｣o dos dados com tipos de variﾃ｡veis
# -------------------------------------

def show_preview_with_types(variable_types):
    """Exibe os dados com uma prﾃｩ-visualizaﾃｧﾃ｣o dos tipos de variﾃ｡veis identificados."""

    # Tﾃｭtulo da seﾃｧﾃ｣o
    st.subheader("Prﾃｩ-visualizaﾃｧﾃ｣o dos dados com tipos de variﾃ｡veis")

    # Exibir os tipos de variﾃ｡veis definidos pelo utilizador
    st.write("Tipos de variﾃ｡veis:")
    st.write(variable_types)

    # Formatar os dados antes da exibiﾃｧﾃ｣o
    formatted_df = format_table()

    # Aplicar destaque para valores ausentes e corrigir tipos de dados antes de exibir
    st.dataframe(fix_dataframe_types(highlight_missing(formatted_df)))


# -------------------------------------
# 東 Funﾃｧﾃ｣o para Aplicar Tratamento de Valores Ausentes
# -------------------------------------

def apply_missing_value_treatment(column, method, constant_value=None):
    """Aplica um tratamento especﾃｭfico para valores ausentes numa coluna selecionada do dataset."""

    # Usa diretamente os dados filtrados armazenados no estado global
    data = st.session_state.filtered_data

    # Verifica se a coluna ﾃｩ numﾃｩrica
    if pd.api.types.is_numeric_dtype(data[column]):
        # Substituir valores ausentes pela mﾃｩdia da coluna
        if method == "Mﾃｩdia":
            data[column].fillna(data[column].mean(), inplace=True)

        # Substituir valores ausentes pela mediana da coluna
        elif method == "Mediana":
            data[column].fillna(data[column].median(), inplace=True)

        # Substituir valores ausentes pela moda (valor mais frequente) da coluna
        elif method == "Moda":
            data[column].fillna(data[column].mode().iloc[0], inplace=True)

        # Excluir linhas onde hﾃ｡ valores ausentes nesta coluna
        elif method == "Excluir":
            data.dropna(subset=[column], inplace=True)

        # Substituir por um valor constante definido pelo utilizador
        elif method == "Valor constante" and constant_value is not None:
            data[column].fillna(constant_value, inplace=True)

    # Se a coluna for categﾃｳrica (texto, categorias, etc.)
    else:
        # Substituir valores ausentes pela moda (valor mais frequente)
        if method == "Substituir por moda":
            data[column].fillna(data[column].mode().iloc[0], inplace=True)

        # Substituir valores ausentes por um valor fixo definido pelo utilizador
        elif method == "Substituir por valor constante" and constant_value is not None:
            data[column].fillna(constant_value, inplace=True)

        # Nﾃ｣o faz nada (mantﾃｩm os valores ausentes)
        elif method == "Manter valores ausentes":
            pass  

        # Excluir linhas com valores ausentes nesta coluna
        elif method == "Excluir":
            data.dropna(subset=[column], inplace=True)

    # Atualiza os dados processados no estado global
    st.session_state.filtered_data = data

# -------------------------------------
# 東 Funﾃｧﾃ｣o para Selecionar Automaticamente o Mﾃｩtodo de Tratamento de Valores Ausentes
# -------------------------------------

def auto_select_method(column_name):
    """Seleciona automaticamente o melhor mﾃｩtodo para tratar valores ausentes numa coluna."""

    # Obtﾃｩm a coluna a partir dos dados filtrados
    column = st.session_state.filtered_data[column_name]

    # Calcula a percentagem de valores ausentes na coluna
    missing_percentage = column.isnull().sum() / len(column)

    # Para colunas numﾃｩricas
    if pd.api.types.is_numeric_dtype(column):
        if missing_percentage > 0.5:
            return "Excluir"  # Se mais de 50% dos valores estﾃ｣o ausentes, sugere excluir a coluna
        else:
            return "Substituir por Mediana"  # Caso contrﾃ｡rio, sugere substituir pela mediana

    # Para colunas categﾃｳricas (texto, categorias)
    else:
        if missing_percentage > 0.5:
            return "Excluir"  # Se mais de 50% dos valores estﾃ｣o ausentes, sugere excluir a coluna
        else:
            return "Substituir por Moda"  # Caso contrﾃ｡rio, sugere substituir pela moda (valor mais frequente)

# -------------------------------------
# 東 Funﾃｧﾃ｣o para Exibir Tabela com Valores Ausentes
# -------------------------------------

def display_missing_values(dataframe):
    """Exibe uma tabela com a contagem de valores ausentes em cada coluna do dataset."""

    # Conta o nﾃｺmero de valores ausentes por coluna
    missing_data = dataframe.isnull().sum()

    # Mantﾃｩm apenas as colunas que possuem valores ausentes
    missing_data = missing_data[missing_data > 0]
    
    # Converte para DataFrame para melhor visualizaﾃｧﾃ｣o
    missing_data = missing_data.reset_index()
    missing_data.columns = ['Coluna', 'Valores Ausentes']

    # Se houver valores ausentes, exibir a tabela
    if not missing_data.empty:
        st.write("Tabela de valores ausentes:")
        st.dataframe(fix_dataframe_types(missing_data))  # Aplica correﾃｧﾃｵes de tipo antes de exibir
    else:
        st.write("Nﾃ｣o hﾃ｡ valores ausentes.")  # Mensagem caso nﾃ｣o existam valores em falta

# -------------------------------------
# 東 FUNﾃﾃグ PARA MOSTRAR E TRATAR VALORES AUSENTES
# -------------------------------------

def handle_missing_values():
    """Gerencia o tratamento de valores ausentes no dataset carregado."""

    # Exibe o tﾃｭtulo da seﾃｧﾃ｣o no Streamlit
    st.subheader("Tratamento de Valores Ausentes")

    # Obtﾃｩm os dados filtrados armazenados no estado da sessﾃ｣o
    filtered_data = st.session_state.get('filtered_data', None)

    # -------------------------------------
    # 東 Verificaﾃｧﾃ｣o Inicial dos Dados
    # -------------------------------------

    # Verifica se hﾃ｡ dados carregados e nﾃ｣o estﾃ｣o vazios
    if filtered_data is not None and not filtered_data.empty:

        # -------------------------------------
        # 東 Funﾃｧﾃ｣o Interna para Exibir Valores Ausentes
        # -------------------------------------

        def display_missing_values(df):
            """Gera uma tabela resumida com a contagem de valores ausentes por coluna."""

            # Conta a quantidade de valores ausentes em cada coluna
            missing_data = df.isnull().sum()

            # Mantﾃｩm apenas as colunas que possuem valores ausentes
            missing_data = missing_data[missing_data > 0]

            # Exibe os valores ausentes caso existam
            if not missing_data.empty:
                st.write("Resumo dos Valores Ausentes:")
                st.dataframe(fix_dataframe_types(missing_data.rename("Total de Valores Ausentes")))
            else:
                st.success("Nﾃ｣o hﾃ｡ valores ausentes nos dados.")  # Exibe uma mensagem caso nﾃ｣o haja valores ausentes

        # Exibir o resumo dos valores ausentes no dataset
        display_missing_values(filtered_data)

        # -------------------------------------
        # 東 Configuraﾃｧﾃ｣o das Opﾃｧﾃｵes de Tratamento de Valores Ausentes
        # -------------------------------------

        # Verifica se existem valores ausentes em qualquer coluna
        has_missing_values = filtered_data.isnull().any().any()

        if has_missing_values:
            # Inicializar dicionﾃ｡rio de tratamento no estado global, caso ainda nﾃ｣o exista
            if 'treatment_state' not in st.session_state:
                st.session_state.treatment_state = {
                    col: {"method": None, "constant": None}
                    for col in filtered_data.columns
                }

            # Percorre cada coluna que possui valores ausentes para exibir opﾃｧﾃｵes de tratamento
            for col in filtered_data.columns:
                if filtered_data[col].isnull().sum() > 0:
                    col_state = st.session_state.treatment_state.get(col, {"method": None, "constant": None})
                    is_numeric = pd.api.types.is_numeric_dtype(filtered_data[col])

                    # -------------------------------------
                    # 東 Tratamento de Valores Ausentes em Colunas Numﾃｩricas
                    # -------------------------------------

                    if is_numeric:
                        # Opﾃｧﾃｵes disponﾃｭveis para tratamento de valores ausentes em variﾃ｡veis numﾃｩricas
                        options = ["Substituir por Mﾃｩdia", "Substituir por Mediana", "Substituir por Moda", 
                                   "Substituir por Valor Constante", "Excluir", "Manter Valores Ausentes"]
                        
                        # Seletor para escolher o mﾃｩtodo de tratamento
                        missing_value_method = st.selectbox(
                            f"Mﾃｩtodo para tratar valores ausentes em {col}",
                            options,
                            index=options.index(col_state["method"]) if col_state["method"] in options else 0,
                            key=f"missing_value_{col}"
                        )

                        # Definir valor constante caso o utilizador escolha essa opﾃｧﾃ｣o
                        constant_value = None
                        if missing_value_method == "Substituir por Valor Constante":
                            constant_value = st.text_input(
                                f"Digite o valor constante para {col}:",
                                value=col_state["constant"] if col_state["constant"] else '',
                                key=f"constant_{col}"
                            )

                    # -------------------------------------
                    # 東 Tratamento de Valores Ausentes em Colunas Categﾃｳricas
                    # -------------------------------------

                    else:
                        # Opﾃｧﾃｵes disponﾃｭveis para colunas categﾃｳricas
                        options = ["Substituir por Moda", "Substituir por Valor Constante", "Manter Valores Ausentes", "Excluir"]
                        
                        # Seletor para escolher o mﾃｩtodo de tratamento
                        missing_value_method = st.selectbox(
                            f"Mﾃｩtodo para tratar valores ausentes em {col}",
                            options,
                            index=options.index(col_state["method"]) if col_state["method"] in options else 0,
                            key=f"cat_missing_value_{col}"
                        )

                        # Definir valor constante caso o utilizador escolha essa opﾃｧﾃ｣o
                        constant_value = None
                        if missing_value_method == "Substituir por Valor Constante":
                            constant_value = st.text_input(
                                f"Digite o valor constante para {col}:",
                                value=col_state["constant"] if col_state["constant"] else '',
                                key=f"cat_constant_{col}"
                            )

                    # Atualizar o estado global com as escolhas do utilizador para essa coluna
                    st.session_state.treatment_state[col] = {"method": missing_value_method, "constant": constant_value}

            # -------------------------------------
            # 東 Aplicaﾃｧﾃ｣o dos Tratamentos Escolhidos
            # -------------------------------------

            if st.button("Aplicar tratamentos"):
                for col, treatment in st.session_state.treatment_state.items():
                    method = treatment["method"]
                    constant_value = treatment["constant"]

                    # Aplicar o mﾃｩtodo selecionado para tratamento dos valores ausentes
                    if method == "Substituir por Mﾃｩdia":
                        filtered_data[col].fillna(filtered_data[col].mean(), inplace=True)
                    elif method == "Substituir por Mediana":
                        filtered_data[col].fillna(filtered_data[col].median(), inplace=True)
                    elif method == "Substituir por Moda":
                        filtered_data[col].fillna(filtered_data[col].mode().iloc[0], inplace=True)
                    elif method == "Substituir por Valor Constante" and constant_value is not None:
                        filtered_data[col].fillna(constant_value, inplace=True)
                    elif method == "Excluir":
                        filtered_data.dropna(subset=[col], inplace=True)

                # Atualizar os dados processados no estado global
                st.session_state.data = filtered_data.copy()

                # Mensagem de sucesso
                st.success("Tratamentos aplicados com sucesso!")

        # -------------------------------------
        # 東 Navegaﾃｧﾃ｣o entre Etapas
        # -------------------------------------

        col1, col2 = st.columns(2)

        # Botﾃ｣o para voltar ﾃ etapa anterior
        with col1:
            if st.button("Voltar"):
                st.session_state.step = 'data_preview'
                st.rerun()

        # Botﾃ｣o para avanﾃｧar para a prﾃｳxima etapa
        with col2:
            if st.button("Prﾃｳxima etapa"):
                st.session_state.step = 'outlier_detection'
                st.rerun()

    else:
        # Caso nﾃ｣o haja dados disponﾃｭveis, exibir uma mensagem de erro
        st.error("Nenhum dado disponﾃｭvel para tratamento de valores ausentes.")


##############################################
# -------------------------------------
# 東 FUNﾃﾃグ DE TRATAMENTO DE OUTLIERS (VALORES EXTREMOS)
# -------------------------------------

# -------------------------------------
# 東 Funﾃｧﾃ｣o para Detetar e Calcular Informaﾃｧﾃｵes sobre Outliers
# -------------------------------------

@st.cache_data  # Usa cache para evitar recﾃ｡lculo desnecessﾃ｡rio ao interagir com a aplicaﾃｧﾃ｣o
def calculate_outliers(columns, data):
    """
    Identifica e calcula estatﾃｭsticas sobre outliers em variﾃ｡veis numﾃｩricas.

    Parﾃ｢metros:
    - columns: lista com os nomes das colunas a serem analisadas.
    - data: DataFrame contendo os dados.

    Retorna:
    - variables_with_outliers: Lista com as variﾃ｡veis que possuem outliers.
    - outlier_summary: Lista de dicionﾃ｡rios com informaﾃｧﾃｵes detalhadas sobre os outliers identificados.
    """

    # Lista para armazenar os nomes das variﾃ｡veis que contﾃｪm outliers
    variables_with_outliers = []

    # Lista para armazenar o resumo estatﾃｭstico dos outliers encontrados
    outlier_summary = []

    # Percorre todas as colunas selecionadas para anﾃ｡lise de outliers
    for col in columns:
        # Verifica se a coluna contﾃｩm dados numﾃｩricos antes de continuar a anﾃ｡lise
        if pd.api.types.is_numeric_dtype(data[col]):

            # -------------------------------------
            # 東 Cﾃ｡lculo do Intervalo Interquartil (IQR)
            # -------------------------------------

            # Primeiro quartil (Q1) - 25% dos dados estﾃ｣o abaixo deste valor
            Q1 = data[col].quantile(0.25)

            # Terceiro quartil (Q3) - 75% dos dados estﾃ｣o abaixo deste valor
            Q3 = data[col].quantile(0.75)

            # Intervalo Interquartil (IQR) - Diferenﾃｧa entre Q3 e Q1
            IQR = Q3 - Q1

            # Definiﾃｧﾃ｣o dos limites para deteﾃｧﾃ｣o de outliers
            lower_bound = Q1 - 1.5 * IQR  # Limite inferior
            upper_bound = Q3 + 1.5 * IQR  # Limite superior

            # -------------------------------------
            # 東 Identificaﾃｧﾃ｣o de Outliers
            # -------------------------------------

            # Contagem de outliers, ou seja, valores que estﾃ｣o abaixo do limite inferior ou acima do superior
            num_outliers = len(data[(data[col] < lower_bound) | (data[col] > upper_bound)])

            # Se forem encontrados outliers na coluna, armazenar os resultados
            if num_outliers > 0:
                # Calcular a percentagem de outliers em relaﾃｧﾃ｣o ao total de dados na variﾃ｡vel
                percentage_outliers = (num_outliers / len(data[col])) * 100

                # Adicionar o nome da variﾃ｡vel ﾃ lista de variﾃ｡veis com outliers
                variables_with_outliers.append(col)

                # Criar um dicionﾃ｡rio com o resumo estatﾃｭstico dos outliers na variﾃ｡vel analisada
                outlier_summary.append({
                    "Variﾃ｡vel": col,
                    "Total de Outliers": num_outliers,
                    "Percentagem de Outliers (%)": round(percentage_outliers, 2)
                })

    # Retorna a lista de variﾃ｡veis que possuem outliers e o resumo estatﾃｭstico
    return variables_with_outliers, outlier_summary


# Interface de detecﾃｧﾃ｣o e tratamento de outliers
# -------------------------------------
# 東 FUNﾃﾃグ DE DETEﾃﾃグ E TRATAMENTO DE OUTLIERS
# -------------------------------------

def outlier_detection():
    """Realiza a deteﾃｧﾃ｣o e o tratamento de outliers (valores extremos) em variﾃ｡veis numﾃｩricas do dataset."""

    # Exibir o tﾃｭtulo da seﾃｧﾃ｣o no Streamlit
    st.subheader("Deteﾃｧﾃ｣o de Outliers")

    # -------------------------------------
    # 東 Armazenamento dos Dados Originais
    # -------------------------------------

    # Se for a primeira execuﾃｧﾃ｣o, armazenar uma cﾃｳpia dos dados originais
    if 'original_data' not in st.session_state:
        st.session_state.original_data = st.session_state.data.copy()

    # -------------------------------------
    # 東 Boxplot Inicial (Visualizaﾃｧﾃ｣o dos Dados Antes do Tratamento)
    # -------------------------------------

    st.write("### Boxplot Inicial (Dados Originais)")
    fig, ax = plt.subplots(figsize=(12, 6))
    st.session_state.original_data.boxplot(ax=ax)  # Criar boxplot para visualizar outliers
    plt.xticks(rotation=45)  # Ajustar rotaﾃｧﾃ｣o dos rﾃｳtulos do eixo X
    st.pyplot(fig)  # Exibir grﾃ｡fico no Streamlit

    # -------------------------------------
    # 東 Inicializar Estados Globais Necessﾃ｡rios
    # -------------------------------------

    # Armazena colunas que jﾃ｡ passaram por tratamento
    if 'treated_columns' not in st.session_state:
        st.session_state.treated_columns = []

    # Armazena detalhes sobre os outliers identificados
    if 'outlier_details' not in st.session_state:
        st.session_state.outlier_details = {}

    # Armazena os limites iniciais dos outliers (antes do tratamento)
    if 'initial_limits' not in st.session_state:
        st.session_state.initial_limits = {}

    # Lista de colunas que possuem outliers
    if 'columns_with_outliers' not in st.session_state:
        st.session_state.columns_with_outliers = []

    # Estado global para armazenar as decisﾃｵes do utilizador sobre tratamento de outliers
    if 'outlier_treatment_state' not in st.session_state:
        st.session_state.outlier_treatment_state = {}

    # Flag para indicar se todos os outliers foram tratados
    if 'all_outliers_treated' not in st.session_state:
        st.session_state.all_outliers_treated = False

    # -------------------------------------
    # 東 Verificaﾃｧﾃ｣o da Disponibilidade dos Dados
    # -------------------------------------

    if 'data' not in st.session_state or st.session_state.data is None:
        st.error("Os dados nﾃ｣o estﾃ｣o carregados! Volte para a etapa anterior.")
        return

    # -------------------------------------
    # 東 Identificaﾃｧﾃ｣o de Outliers
    # -------------------------------------

    # Selecionar apenas as colunas numﾃｩricas do dataset
    numeric_columns = list(st.session_state.data.select_dtypes(include=[np.number]).columns)

    # Lista para armazenar resumo dos outliers
    outlier_summary = []

    # Percorrer todas as colunas numﾃｩricas para calcular limites e identificar outliers
    for col in numeric_columns:

        # Ignorar colunas que jﾃ｡ foram tratadas
        if col in st.session_state.treated_columns:
            continue

        # Calcular o primeiro quartil (Q1) e o terceiro quartil (Q3)
        Q1 = st.session_state.data[col].quantile(0.25)
        Q3 = st.session_state.data[col].quantile(0.75)

        # Calcular o intervalo interquartil (IQR)
        IQR = Q3 - Q1

        # Definir limites inferior e superior para identificaﾃｧﾃ｣o de outliers
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Contar outliers normais (fora do intervalo IQR)
        total_outliers = len(st.session_state.data[(st.session_state.data[col] < lower_bound) | 
                                                   (st.session_state.data[col] > upper_bound)])

        # Contar outliers severos (fora do intervalo 3*IQR)
        total_severe_outliers = len(st.session_state.data[(st.session_state.data[col] < (Q1 - 3.0 * IQR)) | 
                                                           (st.session_state.data[col] > (Q3 + 3.0 * IQR))])

        # Se a variﾃ｡vel contiver outliers, armazenar detalhes
        if total_outliers > 0:
            st.session_state.initial_limits[col] = {
                "lower_bound": lower_bound,
                "upper_bound": upper_bound,
            }

            st.session_state.outlier_details[col] = {
                "total_outliers": total_outliers,
                "total_severe_outliers": total_severe_outliers,
                "skewness": st.session_state.data[col].skew()  # Assimetria da distribuiﾃｧﾃ｣o
            }

            # Adicionar ao resumo estatﾃｭstico
            outlier_summary.append({
                "Nome variﾃ｡vel": col,
                "Total de outliers": total_outliers,
                "Total de outliers severos": total_severe_outliers
            })

            # Adicionar ﾃ lista de colunas com outliers
            if col not in st.session_state.columns_with_outliers:
                st.session_state.columns_with_outliers.append(col)

    # Salvar o resumo inicial no estado global
    st.session_state.initial_outlier_summary = outlier_summary

    # -------------------------------------
    # 東 Verificar se Restam Outliers para Tratar
    # -------------------------------------

    remaining_outliers = [col for col in st.session_state.columns_with_outliers 
                          if col not in st.session_state.treated_columns]

    if not remaining_outliers:
        if not outlier_summary and not st.session_state.columns_with_outliers:
            st.success("Nenhum outlier detetado nas variﾃ｡veis numﾃｩricas!")
        else:
            st.success("Todos os outliers detetados foram tratados!")
    else:
        st.write("Resumo dos Outliers:")
        st.dataframe(fix_dataframe_types(pd.DataFrame(outlier_summary)))

    # -------------------------------------
    # 東 Exibiﾃｧﾃ｣o e Tratamento de Outliers Restantes
    # -------------------------------------

    for col in remaining_outliers:
        st.write(f"**Diagnﾃｳstico para {col}:**")
        details = st.session_state.outlier_details[col]
        st.write(f"- Total de Registos: {len(st.session_state.data)}")
        st.write(f"- Outliers: {details['total_outliers']} ({(details['total_outliers'] / len(st.session_state.data)):.2%})")
        st.write(f"- Outliers Severos: {details['total_severe_outliers']} ({(details['total_severe_outliers'] / len(st.session_state.data)):.2%})")
        st.write(f"- Assimetria (Skewness): {details['skewness']:.2f}")

        # Sugestﾃ｣o automﾃ｡tica de mﾃｩtodo de tratamento
        if col not in st.session_state.outlier_treatment_state:
            suggested_method = auto_select_outlier_treatment(
                col, st.session_state.data, st.session_state.initial_limits[col]["lower_bound"], st.session_state.initial_limits[col]["upper_bound"]
            )
            st.session_state.outlier_treatment_state[col] = suggested_method

        # Seletor de mﾃｩtodo de tratamento
        method = st.selectbox(
            f"Selecione o mﾃｩtodo para tratar outliers em {col}",
            ["Sem Aﾃｧﾃ｣o", "Remover Outliers", "Remover Outliers Severos", "Substituir por Limites", "Substituir por Mﾃｩdia", "Substituir por Mediana"],
            index=["Sem Aﾃｧﾃ｣o", "Remover Outliers", "Remover Outliers Severos", "Substituir por Limites", "Substituir por Mﾃｩdia", "Substituir por Mediana"].index(
                st.session_state.outlier_treatment_state[col]
            ),
            key=f"outlier_method_{col}_{len(st.session_state.treated_columns)}"
        )

        # Botﾃ｣o para aplicar o tratamento selecionado
        if st.button(f"Aplicar tratamento em {col}"):
            apply_outlier_treatment(col, method, st.session_state.initial_limits[col]["lower_bound"], st.session_state.initial_limits[col]["upper_bound"])
            if col not in st.session_state.treated_columns:
                st.session_state.treated_columns.append(col)
            st.rerun()

    # -------------------------------------
    # 東 Boxplot Final Apﾃｳs Tratamento
    # -------------------------------------

    st.write("### Boxplot Apﾃｳs Tratamento")
    fig, ax = plt.subplots(figsize=(12, 6))
    st.session_state.data.boxplot(ax=ax)
    plt.xticks(rotation=45)
    st.pyplot(fig)

    # -------------------------------------
    # 東 Botﾃ｣o para Avanﾃｧar para a Prﾃｳxima Etapa
    # -------------------------------------

    if st.button("Prﾃｳxima etapa"):
        st.session_state.step = 'data_summary'
        st.rerun()

# -------------------------------------
# 東 FUNﾃﾃグ DE SUGESTﾃグ AUTOMﾃゝICA PARA TRATAMENTO DE OUTLIERS
# -------------------------------------

def auto_select_outlier_treatment(col, data, lower_bound, upper_bound):
    """
    Sugere automaticamente o melhor mﾃｩtodo de tratamento de outliers com base na distribuiﾃｧﾃ｣o dos dados.

    Parﾃ｢metros:
    - col: Nome da coluna a ser analisada.
    - data: DataFrame contendo os dados.
    - lower_bound: Limite inferior dos valores considerados normais (IQR 1.5x abaixo do Q1).
    - upper_bound: Limite superior dos valores considerados normais (IQR 1.5x acima do Q3).

    Retorna:
    - Mﾃｩtodo sugerido para tratamento dos outliers.
    """

    # -------------------------------------
    # 東 Cﾃ｡lculo da Proporﾃｧﾃ｣o de Outliers
    # -------------------------------------

    total = len(data)  # Nﾃｺmero total de registos

    # Contar outliers normais (fora do intervalo de 1.5 * IQR)
    total_outliers = len(data[(data[col] < lower_bound) | (data[col] > upper_bound)])

    # Contar outliers severos (fora do intervalo de 3 * IQR)
    total_severe_outliers = len(data[(data[col] < (lower_bound - 1.5 * (upper_bound - lower_bound))) |
                                     (data[col] > (upper_bound + 1.5 * (upper_bound - lower_bound)))])

    # Calcular percentagens
    percentage = total_outliers / total  # Percentagem de outliers normais
    severe_percentage = total_severe_outliers / total  # Percentagem de outliers severos

    # -------------------------------------
    # 東 Verificaﾃｧﾃ｣o da Assimetria dos Dados (Skewness)
    # -------------------------------------

    skewness = data[col].skew()  # Medida de assimetria da distribuiﾃｧﾃ｣o dos dados

    # -------------------------------------
    # 東 Definiﾃｧﾃ｣o das Regras para Sugerir o Melhor Mﾃｩtodo
    # -------------------------------------

    if severe_percentage > 0.10:
        # Se mais de 10% dos valores forem outliers severos, recomenda-se remover apenas os extremos
        return "Remover Outliers Severos"
    elif percentage > 0.20:
        # Se mais de 20% dos valores forem outliers, recomenda-se remover todos os outliers
        return "Remover Outliers"
    elif percentage > 0.05:
        # Se entre 5% e 20% forem outliers, recomenda-se substituﾃｭ-los pelos limites aceitﾃ｡veis
        return "Substituir por Limites"
    else:
        # Se houver menos de 5% de outliers, a escolha entre mﾃｩdia e mediana ﾃｩ baseada na simetria
        if abs(skewness) > 1:
            return "Substituir por Mediana"  # Se houver alta assimetria, usa-se a mediana
        else:
            return "Substituir por Mﾃｩdia"  # Caso contrﾃ｡rio, a mﾃｩdia ﾃｩ uma escolha razoﾃ｡vel

# -------------------------------------
# 東 FUNﾃﾃグ PARA APLICAR TRATAMENTO DE OUTLIERS
# -------------------------------------

def apply_outlier_treatment(col, method, lower_bound, upper_bound):
    """
    Aplica o tratamento de outliers na coluna especificada, conforme o mﾃｩtodo escolhido.

    Parﾃ｢metros:
    - col: Nome da coluna a ser tratada.
    - method: Mﾃｩtodo de tratamento selecionado.
    - lower_bound: Limite inferior considerado aceitﾃ｡vel.
    - upper_bound: Limite superior considerado aceitﾃ｡vel.
    """

    # Obter os dados do estado global
    data = st.session_state.data

    # -------------------------------------
    # 東 Remover Todos os Outliers (Fora do Intervalo 1.5 * IQR)
    # -------------------------------------
    
    if method == "Remover Outliers":
        st.session_state.data = data[
            (data[col] >= lower_bound) & (data[col] <= upper_bound)
        ]
        st.success(f"Todos os outliers removidos na coluna '{col}'.")

    # -------------------------------------
    # 東 Remover Apenas Outliers Severos (Fora do Intervalo 3 * IQR)
    # -------------------------------------

    elif method == "Remover Outliers Severos":
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1

        # Definir limites mais rigorosos para outliers severos (3 * IQR)
        severe_lower = Q1 - 3.0 * IQR
        severe_upper = Q3 + 3.0 * IQR

        st.session_state.data = data[
            (data[col] >= severe_lower) & (data[col] <= severe_upper)
        ]
        st.success(f"Outliers severos removidos na coluna '{col}'.")

    # -------------------------------------
    # 東 Substituir Outliers pelos Limites Aceitﾃ｡veis
    # -------------------------------------

    elif method == "Substituir por Limites":
        st.session_state.data[col] = data[col].clip(lower_bound, upper_bound)
        st.success(f"Valores substituﾃｭdos pelos limites na coluna '{col}'.")

    # -------------------------------------
    # 東 Substituir Outliers pela Mﾃｩdia da Coluna
    # -------------------------------------

    elif method == "Substituir por Mﾃｩdia":
        mean_value = data[col].mean()
        mask = (data[col] < lower_bound) | (data[col] > upper_bound)
        st.session_state.data.loc[mask, col] = mean_value
        st.success(f"Valores substituﾃｭdos pela mﾃｩdia ({mean_value:.2f}) na coluna '{col}'.")

    # -------------------------------------
    # 東 Substituir Outliers pela Mediana da Coluna
    # -------------------------------------

    elif method == "Substituir por Mediana":
        median_value = data[col].median()
        mask = (data[col] < lower_bound) | (data[col] > upper_bound)
        st.session_state.data.loc[mask, col] = median_value
        st.success(f"Valores substituﾃｭdos pela mediana ({median_value:.2f}) na coluna '{col}'.")


##########################################################
# -------------------------------------
# 東 FUNﾃﾃグ PARA GUARDAR O DATASET APﾃ鉄 O PRﾃ-PROCESSAMENTO
# -------------------------------------

def save_modified_dataset_in_memory():
    """
    Salva o dataset tratado na memﾃｳria (session_state) para uso posterior.
    """

    # Criar uma cﾃｳpia do dataset tratado e armazenﾃ｡-lo no estado da sessﾃ｣o
    st.session_state.data_tratada = st.session_state.data.copy()

    # Exibir uma mensagem de sucesso
    st.success("O dataset tratado foi salvo na memﾃｳria para uso posterior.")

# -------------------------------------
# 東 FUNﾃﾃグ PARA PERMITIR O DOWNLOAD DO DATASET TRATADO
# -------------------------------------

def download_button(df, filename="dataset_tratado.csv"):
    """
    Permite ao utilizador descarregar o dataset tratado em formato CSV.

    Parﾃ｢metros:
    - df: DataFrame tratado a ser disponibilizado para download.
    - filename: Nome do ficheiro CSV a ser descarregado (padrﾃ｣o: "dataset_tratado.csv").
    """

    # Converter o DataFrame para formato CSV (sem ﾃｭndice)
    csv = df.to_csv(index=False)

    # Criar um buffer de memﾃｳria para armazenar o conteﾃｺdo do ficheiro
    buf = io.BytesIO()

    # Escrever o conteﾃｺdo do CSV no buffer e posicionar o cursor no inﾃｭcio
    buf.write(csv.encode())  # Converter para bytes e armazenar no buffer
    buf.seek(0)  # Definir a posiﾃｧﾃ｣o do cursor para o inﾃｭcio do ficheiro

    # Criar um botﾃ｣o de download no Streamlit
    st.download_button(
        label="Baixar Dataset Tratado",  # Texto do botﾃ｣o
        data=buf,  # Ficheiro a ser descarregado
        file_name=filename,  # Nome do ficheiro ao fazer o download
        mime="text/csv"  # Tipo MIME do ficheiro
    )


##########################################################
# -------------------------------------
# 東 CLASSE PARA CRIAR O PDF COM O RESUMO APﾃ鉄 O PRﾃ-PROCESSAMENTO
# -------------------------------------

from fpdf import FPDF
import requests
import tempfile
from datetime import datetime

class CustomPDF(FPDF):
    """
    Classe personalizada para gerar um relatﾃｳrio em PDF com cabeﾃｧalho e rodapﾃｩ customizados.
    """

    def header(self):
        """
        Mﾃｩtodo para gerar o cabeﾃｧalho do PDF, incluindo o logﾃｳtipo da instituiﾃｧﾃ｣o.
        """

        # URL do logﾃｳtipo da instituiﾃｧﾃ｣o
        logo_url = 'https://www.ipleiria.pt/normasgraficas/wp-content/uploads/sites/80/2017/09/estg_v-01.jpg'

        # Fazer o download da imagem
        response = requests.get(logo_url)

        if response.status_code == 200:
            # Criar um ficheiro temporﾃ｡rio para armazenar a imagem baixada
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmpfile:
                tmpfile.write(response.content)  # Escrever o conteﾃｺdo da imagem no ficheiro temporﾃ｡rio
                tmpfile_path = tmpfile.name  # Obter o caminho do ficheiro

                # Adicionar a imagem no cabeﾃｧalho do PDF
                self.image(tmpfile_path, x=10, y=8, w=20)  # Definir posiﾃｧﾃ｣o e tamanho da imagem
        else:
            # Se a imagem nﾃ｣o for baixada corretamente, exibir mensagem no PDF
            self.set_font('Arial', 'B', 12)
            self.cell(0, 10, "Logo nﾃ｣o disponﾃｭvel", align='C')

        # Definir a fonte do cabeﾃｧalho
        self.set_font('Arial', 'B', 12)

        # Adicionar o tﾃｭtulo da plataforma no cabeﾃｧalho
        self.cell(0, 10, 'MLCase - Plataforma de Machine Learning', align='C', ln=True)

        # Criar um espaﾃｧo entre o cabeﾃｧalho e o conteﾃｺdo
        self.ln(15)

    def footer(self):
        """
        Mﾃｩtodo para gerar o rodapﾃｩ do PDF, incluindo a data e nﾃｺmero da pﾃ｡gina.
        """

        # Definir a posiﾃｧﾃ｣o do rodapﾃｩ a 1.5 cm do final da pﾃ｡gina
        self.set_y(-15)

        # Definir a fonte do rodapﾃｩ
        self.set_font('Arial', 'I', 10)

        # Obter a data atual no formato dia/mﾃｪs/ano
        current_date = datetime.now().strftime('%d/%m/%Y')

        # Adicionar rodapﾃｩ com a data e o nﾃｺmero da pﾃ｡gina
        self.cell(0, 10, f'{current_date} - Pﾃ｡gina {self.page_no()}  |  Autora da Plataforma: Bruna Sousa', align='C')

# -------------------------------------
# 東 FUNﾃﾃグ PARA GERAR O PDF COM O RESUMO DO PRﾃ-PROCESSAMENTO
# -------------------------------------

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO

def generate_pdf_resumo(dataset, summary_df, missing_data, outlier_summary):
    """
    Gera um relatﾃｳrio em PDF com informaﾃｧﾃｵes estatﾃｭsticas do dataset, valores ausentes, outliers,
    matriz de correlaﾃｧﾃ｣o e boxplot.

    Parﾃ｢metros:
    - dataset: DataFrame original apﾃｳs prﾃｩ-processamento.
    - summary_df: DataFrame com estatﾃｭsticas descritivas do dataset.
    - missing_data: Sﾃｩrie contendo a contagem de valores ausentes por coluna.
    - outlier_summary: Lista contendo o resumo dos outliers identificados.

    Retorna:
    - Um buffer de memﾃｳria contendo o PDF gerado.
    """

    # -------------------------------------
    # 東 Funﾃｧﾃ｣o Auxiliar para Limpar Texto
    # -------------------------------------

    def clean_text(text):
        """Remove caracteres incompatﾃｭveis com a codificaﾃｧﾃ｣o do PDF."""
        if not isinstance(text, str):
            return text
        return text.encode('latin-1', errors='ignore').decode('latin-1')

    # -------------------------------------
    # 東 Inicializaﾃｧﾃ｣o do PDF
    # -------------------------------------

    pdf = CustomPDF(format='A4')
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=8)

    # -------------------------------------
    # 東 Tﾃｭtulo do Relatﾃｳrio
    # -------------------------------------

    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Relatﾃｳrio Resumo dos Dados"), ln=True, align="C")
    pdf.ln(5)

    # -------------------------------------
    # 東 Estatﾃｭsticas Descritivas Simplificadas
    # -------------------------------------

    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Estatﾃｭsticas Descritivas"), ln=True)
    pdf.set_font("Arial", size=8)

    # Criar DataFrame simplificado com estatﾃｭsticas principais
    summary_simplified = pd.DataFrame({
        'Coluna': dataset.columns,
        'Tipo de Dados': dataset.dtypes,
        'Count': dataset.count(),
        'Top': dataset.mode().iloc[0],  # Valor mais frequente (moda)
    })

    # Inicializar colunas estatﾃｭsticas apenas para colunas numﾃｩricas
    summary_simplified['std'] = None
    summary_simplified['min'] = None
    summary_simplified['max'] = None
    summary_simplified['Mﾃｩdia'] = None

    numeric_columns = dataset.select_dtypes(include=['float64', 'int64']).columns
    summary_simplified.loc[summary_simplified['Coluna'].isin(numeric_columns), 'Mﾃｩdia'] = dataset[numeric_columns].mean()
    summary_simplified.loc[summary_simplified['Coluna'].isin(numeric_columns), 'std'] = dataset[numeric_columns].std()
    summary_simplified.loc[summary_simplified['Coluna'].isin(numeric_columns), 'min'] = dataset[numeric_columns].min()
    summary_simplified.loc[summary_simplified['Coluna'].isin(numeric_columns), 'max'] = dataset[numeric_columns].max()

    # Formatar valores numﾃｩricos para 4 casas decimais
    for col in ['Mﾃｩdia', 'std', 'min', 'max']:
        summary_simplified[col] = summary_simplified[col].apply(lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x)

    # Substituir 'nan' por vazio
    summary_simplified = summary_simplified.fillna('')

    # -------------------------------------
    # 東 Adicionar Tabela das Estatﾃｭsticas ao PDF
    # -------------------------------------

    pdf.set_fill_color(144, 238, 144)  # Cor de fundo do cabeﾃｧalho
    col_widths = [pdf.get_string_width(col) for col in summary_simplified.columns]
    max_width = 180

    total_width = sum(col_widths)
    scale_factor = max_width / total_width
    col_widths = [width * scale_factor for width in col_widths]

    for i, col in enumerate(summary_simplified.columns):
        pdf.cell(col_widths[i], 10, clean_text(col), 1, 0, 'C', True)
    pdf.ln()

    for i, row in summary_simplified.iterrows():
        for j, cell in enumerate(row):
            pdf.cell(col_widths[j], 8, clean_text(str(cell)), 1, 0, 'C')
        pdf.ln()

    pdf.ln(10)

    # -------------------------------------
    # 東 Resumo de Valores Ausentes
    # -------------------------------------

    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Resumo de Valores Ausentes"), ln=True)
    pdf.set_font("Arial", size=8)

    if not missing_data.empty:
        pdf.set_fill_color(144, 238, 144)
        pdf.cell(50, 10, clean_text("Variﾃ｡vel"), 1, 0, 'C', True)
        pdf.cell(50, 10, clean_text("Total de Ausentes"), 1, 1, 'C', True)
        for col, count in missing_data.items():
            pdf.cell(50, 10, clean_text(col), 1)
            pdf.cell(50, 10, clean_text(str(count)), 1, 1)
        pdf.ln(10)
    else:
        pdf.cell(0, 10, txt=clean_text("Nﾃ｣o hﾃ｡ valores ausentes."), ln=True)

    # -------------------------------------
    # 東 Resumo de Outliers
    # -------------------------------------

    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Resumo de Outliers"), ln=True)
    pdf.set_font("Arial", size=8)

    if outlier_summary:
        pdf.set_fill_color(144, 238, 144)
        pdf.cell(50, 10, clean_text("Variﾃ｡vel"), 1, 0, 'C', True)
        pdf.cell(50, 10, clean_text("Total de Outliers"), 1, 1, 'C', True)
        for entry in outlier_summary:
            pdf.cell(50, 10, clean_text(entry["Variﾃ｡vel"]), 1)
            pdf.cell(50, 10, clean_text(str(entry["Total de Outliers"])), 1, 1)
        pdf.ln(10)
    else:
        pdf.cell(0, 10, txt=clean_text("Nﾃ｣o hﾃ｡ outliers."), ln=True)

    # -------------------------------------
    # 東 Matriz de Correlaﾃｧﾃ｣o (Heatmap)
    # -------------------------------------

    pdf.cell(0, 10, txt=clean_text("Matriz de Correlaﾃｧﾃ｣o das Variﾃ｡veis"), ln=True)
    numeric_data = dataset.select_dtypes(include=['float64', 'int64'])
    correlation_matrix = numeric_data.corr()

    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".4f", cbar=True, square=True)
    plt.title('Matriz de Correlaﾃｧﾃ｣o das Variﾃ｡veis', fontsize=14, fontweight='bold')

    temp_filename = "correlation_heatmap.png"
    plt.savefig(temp_filename)
    plt.close()
    pdf.image(temp_filename, x=10, w=180)
    pdf.ln(95)

    # -------------------------------------
    # 東 Boxplot das Variﾃ｡veis Numﾃｩricas
    # -------------------------------------

    pdf.cell(0, 10, txt=clean_text("Boxplot das Variﾃ｡veis Numﾃｩricas"), ln=True)
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=numeric_data)
    plt.title('Boxplot das Variﾃ｡veis Numﾃｩricas')

    temp_filename_boxplot = "boxplot_combined.png"
    plt.savefig(temp_filename_boxplot)
    plt.close()
    pdf.image(temp_filename_boxplot, x=10, w=180)
    pdf.ln(75)

    # -------------------------------------
    # 東 Gerar o PDF no Buffer de Memﾃｳria
    # -------------------------------------

    pdf_buffer = BytesIO()
    pdf_output = pdf.output(dest='S').encode('latin-1', errors='ignore')
    pdf_buffer.write(pdf_output)
    pdf_buffer.seek(0)

    return pdf_buffer

# -------------------------------------
# 東 FUNﾃﾃグ PARA SALVAR UMA TABELA COMO IMAGEM (PNG)
# -------------------------------------

import matplotlib.pyplot as plt

def save_table_as_image(df, filename="table_image.png"):
    """
    Converte um DataFrame Pandas numa imagem (PNG), formatando os valores para melhor visualizaﾃｧﾃ｣o.

    Parﾃ｢metros:
    - df: DataFrame contendo a tabela a ser convertida em imagem.
    - filename: Nome do ficheiro da imagem a ser salva (padrﾃ｣o: "table_image.png").
    """

    # -------------------------------------
    # 東 Tratamento de Valores no DataFrame Antes da Geraﾃｧﾃ｣o da Imagem
    # -------------------------------------

    # Substituir valores `NaN` por valores vazios para evitar exibiﾃｧﾃｵes incorretas
    df = df.fillna('')

    # Formatar valores numﾃｩricos para 4 casas decimais
    for col in df.select_dtypes(include=['float64', 'int64']).columns:
        df[col] = df[col].apply(lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x)

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o da Figura para Geraﾃｧﾃ｣o da Tabela
    # -------------------------------------

    fig, ax = plt.subplots(figsize=(8, 4))  # Define o tamanho da imagem gerada
    ax.axis('tight')  # Ajusta os limites para caber na figura
    ax.axis('off')  # Remove os eixos para melhor visualizaﾃｧﾃ｣o

    # Criar a tabela no grﾃ｡fico
    table = ax.table(
        cellText=df.values,  # Conteﾃｺdo da tabela
        colLabels=df.columns,  # Cabeﾃｧalhos das colunas
        loc='center',  # Centralizar a tabela na imagem
        cellLoc='center',  # Centralizar o texto nas cﾃｩlulas
        colColours=['#D9EAF7'] * len(df.columns)  # Definir cor do cabeﾃｧalho da tabela
    )

    # -------------------------------------
    # 東 Ajustes de Formataﾃｧﾃ｣o da Tabela
    # -------------------------------------

    table.auto_set_font_size(False)  # Desativar ajuste automﾃ｡tico do tamanho da fonte
    table.set_fontsize(10)  # Definir tamanho da fonte manualmente
    table.auto_set_column_width(col=list(range(len(df.columns))))  # Ajustar automaticamente a largura das colunas

    # -------------------------------------
    # 東 Salvamento da Tabela Como Imagem (PNG)
    # -------------------------------------

    plt.savefig(filename, format='png', bbox_inches='tight')  # Salvar imagem no formato PNG
    plt.close()  # Fechar a figura para evitar sobrecarga de memﾃｳria

# Resumo do Prﾃｩ-processamento de dados:
# -------------------------------------
# 東 FUNﾃﾃグ PARA GERAR O RESUMO DOS DADOS
# -------------------------------------

def data_summary():
    """
    Apresenta um resumo dos dados tratados, incluindo estatﾃｭsticas descritivas, valores ausentes,
    detecﾃｧﾃ｣o de outliers, boxplots e matriz de correlaﾃｧﾃ｣o. Alﾃｩm disso, permite o download do resumo
    em PDF e do dataset tratado.
    """

    st.subheader("Resumo dos Dados")

    # -------------------------------------
    # 東 Verificar Disponibilidade do Dataset
    # -------------------------------------

    if 'data' in st.session_state and st.session_state.data is not None:
        dataset = st.session_state.data
        st.success("Usando o dataset tratado!")
    else:
        st.error("Nenhum dataset estﾃ｡ disponﾃｭvel. Por favor, execute o tratamento de dados antes.")
        return  # Encerra a funﾃｧﾃ｣o caso nﾃ｣o haja dados disponﾃｭveis

    # -------------------------------------
    # 東 Seleﾃｧﾃ｣o de Colunas para Exibiﾃｧﾃ｣o
    # -------------------------------------

    # Obter colunas selecionadas ou usar todas as colunas do dataset
    selected_columns = st.session_state.get('selected_columns', [])
    if not selected_columns:
        selected_columns = dataset.columns.tolist()

    # Permitir que o utilizador selecione as colunas para visualizaﾃｧﾃ｣o
    selected_columns_to_display = st.multiselect(
        "Selecione as variﾃ｡veis para visualizar as estatﾃｭsticas",
        options=selected_columns,
        default=selected_columns
    )

    # Exibir o nﾃｺmero de linhas e colunas do dataset filtrado
    st.write("Nﾃｺmero de linhas e colunas:", dataset[selected_columns_to_display].shape)

    # -------------------------------------
    # 東 Estatﾃｭsticas Descritivas
    # -------------------------------------

    # Identificar colunas numﾃｩricas
    numeric_columns = dataset[selected_columns_to_display].select_dtypes(include=['number']).columns

    # Criar um dicionﾃ｡rio para armazenar estatﾃｭsticas
    summary_data = {
        'Count': dataset[selected_columns_to_display].count(),
        'Mean': dataset[numeric_columns].mean(),
        'Std': dataset[numeric_columns].std(),
        'Min': dataset[numeric_columns].min(),
        '25%': dataset[numeric_columns].quantile(0.25),
        '50%': dataset[numeric_columns].median(),
        '75%': dataset[numeric_columns].quantile(0.75),
        'Max': dataset[numeric_columns].max(),
    }

    # Converter para DataFrame e adicionar os tipos de dados
    summary_df = pd.DataFrame(summary_data)
    summary_df['Tipo de Dados'] = dataset[selected_columns_to_display].dtypes

    # Arredondar valores numﾃｩricos para 4 casas decimais e preencher valores ausentes com 0
    summary_df = summary_df.round(4).fillna(0)

    # Exibir a tabela de estatﾃｭsticas descritivas
    st.write("Estatﾃｭsticas Descritivas e Tipos de Dados")
    st.dataframe(fix_dataframe_types(summary_df))

    # -------------------------------------
    # 東 Anﾃ｡lise de Valores Ausentes
    # -------------------------------------

    st.subheader("Resumo de Valores Ausentes")

    # Identificar colunas com valores ausentes
    missing_data = dataset[selected_columns_to_display].isnull().sum()
    missing_data = missing_data[missing_data > 0]

    if not missing_data.empty:
        st.write("Valores ausentes encontrados:")
        st.dataframe(fix_dataframe_types(missing_data.rename("Total de Valores Ausentes")))
    else:
        st.write("Nﾃ｣o hﾃ｡ valores ausentes nas variﾃ｡veis selecionadas.")

    # -------------------------------------
    # 東 Anﾃ｡lise de Outliers
    # -------------------------------------

    st.subheader("Resumo de Outliers")

    # Selecionar apenas colunas numﾃｩricas
    numeric_data = dataset[selected_columns_to_display].select_dtypes(include=['number'])

    # Obter colunas jﾃ｡ tratadas
    treated_columns = st.session_state.get('treated_columns', [])

    # Criar lista para armazenar o resumo dos outliers
    outlier_summary = []

    if not numeric_data.empty:
        for column in numeric_data.columns:
            if column in treated_columns:  # Ignorar colunas jﾃ｡ tratadas
                continue

            # Cﾃ｡lculo dos quartis e do intervalo interquartil (IQR)
            Q1 = numeric_data[column].quantile(0.25)
            Q3 = numeric_data[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            # Identificar outliers
            outliers = numeric_data[(numeric_data[column] < lower_bound) | (numeric_data[column] > upper_bound)]
            if len(outliers) > 0:
                outlier_summary.append({
                    "Variﾃ｡vel": column,
                    "Total de Outliers": len(outliers)
                })

        # Exibir o resumo dos outliers encontrados
        if outlier_summary:
            st.dataframe(fix_dataframe_types(pd.DataFrame(outlier_summary)))
        else:
            st.write("Nﾃ｣o hﾃ｡ outliers nas variﾃ｡veis selecionadas.")
    else:
        st.write("Nenhuma variﾃ｡vel numﾃｩrica para anﾃ｡lise de outliers.")

    # -------------------------------------
    # 東 Grﾃ｡fico Boxplot das Variﾃ｡veis Numﾃｩricas
    # -------------------------------------

    st.subheader("Boxplot das Variﾃ｡veis Numﾃｩricas")

    plt.figure(figsize=(10, 6))
    sns.boxplot(data=numeric_data)
    plt.title('Boxplot das Variﾃ｡veis Numﾃｩricas')
    st.pyplot(plt)

    # -------------------------------------
    # 東 Matriz de Correlaﾃｧﾃ｣o (Heatmap)
    # -------------------------------------

    st.subheader("Matriz de Correlaﾃｧﾃ｣o das Variﾃ｡veis")

    # Calcular a correlaﾃｧﾃ｣o entre variﾃ｡veis numﾃｩricas
    correlation_matrix = numeric_data.corr()

    # Gerar e exibir o heatmap da correlaﾃｧﾃ｣o
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".4f", cbar=True, square=True)
    plt.title('Matriz de Correlaﾃｧﾃ｣o das Variﾃ｡veis', fontsize=14, fontweight='bold', fontname='Arial')
    st.pyplot(plt)

    # -------------------------------------
    # 東 Download do Resumo em PDF
    # -------------------------------------

    pdf_buffer = generate_pdf_resumo(dataset, summary_df, missing_data, outlier_summary)
    st.download_button(
        label="Baixar PDF com o Resumo",
        data=pdf_buffer,
        file_name="resumo_dos_dados.pdf",
        mime="application/pdf"
    )

    # -------------------------------------
    # 東 Download do Dataset Tratado
    # -------------------------------------

    dataset_to_download = dataset[selected_columns_to_display]
    download_button(dataset_to_download)

    # -------------------------------------
    # 東 Navegaﾃｧﾃ｣o Entre Etapas
    # -------------------------------------

    col1, col2 = st.columns([1, 1])

    with col1:
        if st.button("Voltar"):
            st.session_state.step = 'outlier_detection'
            st.rerun()

    with col2:
        if st.button("Prﾃｳxima etapa"):
            st.session_state.step = 'model_selection'
            st.rerun()


##########################################################
# -------------------------------------
# 東 FUNﾃﾃグ PARA PLOTAR Mﾃ欝RICAS DE DESEMPENHO DOS MODELOS
# -------------------------------------

import streamlit as st
import matplotlib.pyplot as plt

def plot_metrics(metrics_df):
    """
    Gera grﾃ｡ficos para visualizar as mﾃｩtricas de desempenho dos modelos, diferenciando entre
    tarefas de classificaﾃｧﾃ｣o e regressﾃ｣o.

    Parﾃ｢metros:
    - metrics_df: DataFrame contendo as mﾃｩtricas de desempenho dos modelos.

    Retorno:
    - Exibe os grﾃ｡ficos no Streamlit.
    """

    try:
        # -------------------------------------
        # 東 Inicializar Armazenamento de Mﾃｩtricas no Estado da Sessﾃ｣o
        # -------------------------------------

        # Se a chave 'metrics' ainda nﾃ｣o estiver no session_state, inicializﾃ｡-la
        if 'metrics' not in st.session_state:
            st.session_state['metrics'] = {}

        # Verificar se o DataFrame estﾃ｡ vazio
        if metrics_df.empty:
            st.warning("Nenhum dado para exibir no grﾃ｡fico.")
            return

        # Armazenar as mﾃｩtricas no estado da sessﾃ｣o para referﾃｪncia posterior
        for _, row in metrics_df.iterrows():
            model_name = row.name  # Assumindo que o ﾃｭndice contﾃｩm o nome do modelo
            st.session_state['metrics'][model_name] = row.to_dict()

        # -------------------------------------
        # 東 Configuraﾃｧﾃ｣o do ﾃ肱dice e Identificaﾃｧﾃ｣o do Tipo de Modelo
        # -------------------------------------

        # Definir a coluna 'Modelo' como ﾃｭndice, se ainda nﾃ｣o estiver
        metrics_df.set_index('Modelo', inplace=True)

        # Listas de mﾃｩtricas tﾃｭpicas para classificaﾃｧﾃ｣o e regressﾃ｣o
        classification_columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        regression_columns = ['MSE', 'MAE', 'Rﾂｲ']

        # -------------------------------------
        # 東 Plotagem de Grﾃ｡ficos de Classificaﾃｧﾃ｣o
        # -------------------------------------

        if all(col in metrics_df.columns for col in classification_columns):
            # Criar a figura do grﾃ｡fico de barras
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # Plotar as mﾃｩtricas de classificaﾃｧﾃ｣o
            metrics_df[classification_columns].plot(kind='bar', ax=ax)

            # Configuraﾃｧﾃ｣o do grﾃ｡fico
            plt.title('Mﾃｩtricas de Desempenho dos Modelos (Classificaﾃｧﾃ｣o)', fontsize=16)
            plt.ylabel('Valor', fontsize=14)
            plt.xlabel('Modelos', fontsize=14)
            plt.xticks(rotation=45, ha='right', fontsize=12)
            plt.ylim(0, 1)  # As mﾃｩtricas de classificaﾃｧﾃ｣o geralmente variam entre 0 e 1
            plt.legend(loc='lower right', fontsize=12)
            plt.grid(axis='y', linestyle='--', alpha=0.7)

        # -------------------------------------
        # 東 Plotagem de Grﾃ｡ficos de Regressﾃ｣o
        # -------------------------------------

        elif all(col in metrics_df.columns for col in regression_columns):
            # Criar a figura do grﾃ｡fico de barras
            fig, ax = plt.subplots(figsize=(10, 6))

            # Plotar as mﾃｩtricas de regressﾃ｣o
            metrics_df[regression_columns].plot(kind='bar', ax=ax)

            # Configuraﾃｧﾃ｣o do grﾃ｡fico
            plt.title('Mﾃｩtricas de Desempenho dos Modelos (Regressﾃ｣o)', fontsize=16)
            plt.ylabel('Valor', fontsize=14)
            plt.xlabel('Modelos', fontsize=14)
            plt.xticks(rotation=45, ha='right', fontsize=12)
            plt.legend(loc='upper right', fontsize=12)
            plt.grid(axis='y', linestyle='--', alpha=0.7)

        else:
            st.error("O DataFrame nﾃ｣o contﾃｩm mﾃｩtricas vﾃ｡lidas para classificaﾃｧﾃ｣o ou regressﾃ｣o.")
            return  # Se nﾃ｣o hﾃ｡ mﾃｩtricas vﾃ｡lidas, encerra a funﾃｧﾃ｣o

        # -------------------------------------
        # 東 Exibir o Grﾃ｡fico no Streamlit
        # -------------------------------------

        st.pyplot(fig)

    except Exception as e:
        # Tratamento de erros genﾃｩrico para evitar falhas inesperadas
        st.error(f"Ocorreu um erro ao plotar as mﾃｩtricas: {str(e)}")

    finally:
        # Limpar a figura para evitar sobreposiﾃｧﾃ｣o de grﾃ｡ficos na interface do Streamlit
        plt.clf()

# -------------------------------------
# 東 FUNﾃﾃグ PARA DEFINIR O GRID DE HIPERPARﾃMETROS PADRﾃグ PARA CADA MODELO
# -------------------------------------

def get_default_param_grid(model_name):
    """
    Retorna um dicionﾃ｡rio contendo os hiperparﾃ｢metros padrﾃ｣o para cada modelo de Machine Learning.

    Parﾃ｢metros:
    - model_name: Nome do modelo para o qual se deseja obter o conjunto de hiperparﾃ｢metros.

    Retorno:
    - Dicionﾃ｡rio com os hiperparﾃ｢metros e os respetivos intervalos de valores para otimizaﾃｧﾃ｣o.
    """

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o do Grid Search para Support Vector Classification (SVC)
    # -------------------------------------
    if model_name == "Support Vector Classification (SVC)":
        return {
            'C': [0.1, 1, 10],  # Define a penalizaﾃｧﾃ｣o do erro
            'kernel': ['linear', 'rbf'],  # Tipos de kernel utilizados
            'gamma': ['scale', 'auto']  # Apenas utilizado quando kernel='rbf'
        }

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o do Grid Search para K-Nearest Neighbors (KNN)
    # -------------------------------------
    elif model_name == "K-Nearest Neighbors (KNN)":
        return {
            'n_neighbors': list(range(1, 21)),  # Testa todos os valores de 1 a 20 para o nﾃｺmero de vizinhos
            'weights': ['uniform', 'distance']  # Define a forma de ponderaﾃｧﾃ｣o das distﾃ｢ncias
        }

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o do Grid Search para Random Forest
    # -------------------------------------
    elif model_name == "Random Forest":
        # Geraﾃｧﾃ｣o dinﾃ｢mica do parﾃ｢metro `max_depth`
        max_depth_range = [None] + list(range(5, 21, 5))  # [None, 5, 10, 15, 20]
        return {
            'max_depth': max_depth_range,  # Profundidade mﾃ｡xima da ﾃ｡rvore
            'n_estimators': [10, 50, 100]  # Nﾃｺmero de ﾃ｡rvores na floresta
        }

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o do Grid Search para Suporte de Vetores em Regressﾃ｣o (SVR)
    # -------------------------------------
    elif model_name == "Regressﾃ｣o por Vetores de Suporte (SVR)":
        return {
            'C': [1, 10],  # Penalizaﾃｧﾃ｣o do erro
            'epsilon': [0.1, 0.2],  # Margem de tolerﾃ｢ncia para erro
            'kernel': ['linear', 'rbf']  # Tipos de kernel utilizados
        }

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o para Regressﾃ｣o Linear Simples (RLS)
    # -------------------------------------
    elif model_name == "Regressﾃ｣o Linear Simples (RLS)":
        return {}  # A regressﾃ｣o linear geralmente nﾃ｣o requer ajuste de hiperparﾃ｢metros

    # -------------------------------------
    # 東 Retorno para modelos nﾃ｣o especificados
    # -------------------------------------
    else:
        return {}  # Se o modelo nﾃ｣o for reconhecido, retorna um dicionﾃ｡rio vazio

# -------------------------------------
# 東 FUNﾃﾃグ PARA CONFIGURAﾃﾃグ MANUAL DOS PARﾃMETROS DOS MODELOS
# -------------------------------------

import streamlit as st
import json

def configure_manual_params(model_key, param_grid, manual_params):
    """
    Permite a configuraﾃｧﾃ｣o manual dos hiperparﾃ｢metros para o modelo selecionado, 
    exibindo intervalos personalizados para os parﾃ｢metros numﾃｩricos.

    Parﾃ｢metros:
    - model_key: Nome do modelo a ser ajustado.
    - param_grid: Dicionﾃ｡rio com os hiperparﾃ｢metros e opﾃｧﾃｵes disponﾃｭveis.
    - manual_params: Dicionﾃ｡rio onde os valores dos hiperparﾃ｢metros serﾃ｣o armazenados.

    Retorno:
    - manual_params atualizado com os valores configurados pelo utilizador.
    """

    st.write(f"Configuraﾃｧﾃｵes manuais para o modelo: {model_key}")

    # -------------------------------------
    # 東 Limpar Parﾃ｢metros Invﾃ｡lidos no Estado Global
    # -------------------------------------

    # Remover 'gamma' do estado global se ele estiver presente
    if 'manual_params' in st.session_state and 'gamma' in st.session_state['manual_params']:
        del st.session_state['manual_params']['gamma']

    # -------------------------------------
    # 東 Definiﾃｧﾃ｣o de Intervalos Personalizados para Parﾃ｢metros Numﾃｩricos
    # -------------------------------------

    param_ranges = {
        'C': {'min': 0.1, 'max': 100.0, 'step': 0.1, 'default': 1.0},  # Controle de penalizaﾃｧﾃ｣o do erro
        'epsilon': {'min': 0.01, 'max': 1.0, 'step': 0.01, 'default': 0.1},  # Tolerﾃ｢ncia ao erro em SVR
        'gamma': {'min': 0.01, 'max': 1.0, 'step': 0.01, 'default': 0.1},  # Parﾃ｢metro do kernel 'rbf'
        'degree': {'min': 1, 'max': 5, 'step': 1, 'default': 3},  # Apenas para kernel 'poly'
    }

    # -------------------------------------
    # 東 Criar Widgets para Configuraﾃｧﾃ｣o de Parﾃ｢metros
    # -------------------------------------

    for param in param_grid:
        # Se o parﾃ｢metro for categﾃｳrico (exemplo: 'kernel', 'weights')
        if isinstance(param_grid[param][0], str):
            manual_params[param] = st.selectbox(
                f"{param} (Opﾃｧﾃｵes: {', '.join(param_grid[param])}):",
                options=param_grid[param],
                index=0,
                key=f"{model_key}_{param}"
            )

        # Se o parﾃ｢metro for numﾃｩrico (inteiro ou float)
        elif isinstance(param_grid[param][0], (int, float)):
            param_type = float if any(isinstance(x, float) for x in param_grid[param]) else int

            # Verificar se o parﾃ｢metro tem um intervalo personalizado definido
            if param in param_ranges:
                config = param_ranges[param]

                # Exibir informaﾃｧﾃ｣o sobre o intervalo aceito
                st.write(f"**{param}** (Intervalo: {config['min']} a {config['max']})")

                # Se for 'max_depth' (pode ser `None`), criar um selectbox
                if param == 'max_depth':
                    manual_params[param] = st.selectbox(
                        f"{param}:",
                        options=[None] + list(range(1, 21)),  # Permite selecionar `None`
                        index=0 if config['default'] is None else list(range(1, 21)).index(config['default']),
                        key=f"{model_key}_{param}"
                    )

                else:
                    # Criar um input numﾃｩrico para outros parﾃ｢metros
                    manual_params[param] = st.number_input(
                        f"{param}:",
                        min_value=config['min'],
                        max_value=config['max'],
                        value=config['default'],
                        step=config['step'],
                        key=f"{model_key}_{param}"
                    )

    # -------------------------------------
    # 東 Configuraﾃｧﾃ｣o Dinﾃ｢mica do Parﾃ｢metro 'gamma'
    # -------------------------------------

    # O parﾃ｢metro 'gamma' sﾃｳ deve ser configurado se o kernel for 'rbf'
    if 'kernel' in manual_params and manual_params['kernel'] == 'rbf':
        config = param_ranges['gamma']
        st.write(f"**gamma** (Intervalo: {config['min']} a {config['max']})")
        manual_params['gamma'] = st.number_input(
            "gamma:",
            min_value=config['min'],
            max_value=config['max'],
            value=config['default'],
            step=config['step'],
            key=f"{model_key}_gamma"
        )
    else:
        # Se o kernel nﾃ｣o for 'rbf', remover 'gamma' do estado global e do dicionﾃ｡rio de parﾃ｢metros
        manual_params.pop('gamma', None)
        if 'manual_params' in st.session_state and 'gamma' in st.session_state['manual_params']:
            del st.session_state['manual_params']['gamma']

    # -------------------------------------
    # 東 Atualizar Estado Global com Parﾃ｢metros Configurados
    # -------------------------------------

    st.session_state['manual_params'] = manual_params
    st.session_state['best_params_str'] = json.dumps(manual_params, indent=2)  # Armazena como JSON formatado

    # Exibir os parﾃ｢metros configurados
    st.write("Parﾃ｢metros manuais salvos:", st.session_state['manual_params'])

    return manual_params

# -------------------------------------
# 東 DICIONﾃヽIO DE PARﾃMETROS Vﾃ´IDOS PARA CADA MODELO
# -------------------------------------

VALID_PARAMS = {
    "Random Forest": ["n_estimators", "max_depth"],  # Ajustﾃ｡veis para Random Forest
    "Support Vector Classification (SVC)": ["C", "kernel", "gamma"],  # Agora inclui "gamma"
    "K-Nearest Neighbors (KNN)": ["n_neighbors", "weights"],  # Nﾃｺmero de vizinhos e peso das distﾃ｢ncias
    "Regressﾃ｣o Linear Simples (RLS)": [],  # Sem hiperparﾃ｢metros ajustﾃ｡veis
    "Regressﾃ｣o por Vetores de Suporte (SVR)": ["C", "epsilon", "kernel"],  # Hiperparﾃ｢metros tﾃｭpicos do SVR
}



# -------------------------------------
# 東 FUNﾃﾃグ PARA CONFIGURAR A VALIDAﾃﾃグ CRUZADA COM BASE NA ESCOLHA DO UTILIZADOR
# -------------------------------------

def get_cv_strategy(cv_choice, X_train, y_train):
    """
    Retorna a estratﾃｩgia de validaﾃｧﾃ｣o cruzada com base na escolha do utilizador.

    Parﾃ｢metros:
    - cv_choice: Tipo de validaﾃｧﾃ｣o cruzada selecionado pelo utilizador.
    - X_train: Dados de treino.
    - y_train: Labels do conjunto de treino.

    Retorno:
    - Objeto da estratﾃｩgia de validaﾃｧﾃ｣o cruzada correspondente.
    """
    
    if cv_choice == "K-Fold":
        return KFold(n_splits=5, shuffle=True, random_state=42)  # Divide os dados em 5 partes aleatﾃｳrias

    elif cv_choice == "Leave-One-Out":
        return LeaveOneOut()  # Usa cada amostra individualmente como conjunto de teste

    elif cv_choice == "Divisﾃ｣o em Treino e Teste":
        # Divide os dados de treino em 70% treino e 30% teste
        return train_test_split(X_train, y_train, test_size=0.3, random_state=42)

    elif cv_choice == "Holdout":
        # Funciona de forma semelhante ao treino-teste, com um conjunto adicional
        return train_test_split(X_train, y_train, test_size=0.3, random_state=42)

    else:
        # Se a escolha for invﾃ｡lida, usa K-Fold como padrﾃ｣o
        return KFold(n_splits=5, shuffle=True, random_state=42)

# -------------------------------------
# 東 FUNﾃﾃグ PARA CONFIGURAR MANUALMENTE O SVR (SUPPORT VECTOR REGRESSION)
# -------------------------------------

def configure_svr(model_key, manual_params):
    """
    Configuraﾃｧﾃ｣o manual dos parﾃ｢metros para o modelo Support Vector Regression (SVR).

    Parﾃ｢metros:
    - model_key: Nome do modelo (SVR).
    - manual_params: Dicionﾃ｡rio para armazenar os hiperparﾃ｢metros configurados pelo utilizador.

    Retorno:
    - Dicionﾃ｡rio manual_params atualizado com os valores escolhidos pelo utilizador.
    """
    
    st.write("Configuraﾃｧﾃ｣o de parﾃ｢metros para Support Vector Regression (SVR)")

    # Configuraﾃｧﾃ｣o dos hiperparﾃ｢metros principais
    c = st.number_input(
        "Parﾃ｢metro C (Regularizaﾃｧﾃ｣o)", min_value=0.1, max_value=100.0, step=0.1, value=1.0
    )
    epsilon = st.number_input(
        "Parﾃ｢metro epsilon", min_value=0.0, max_value=1.0, step=0.1, value=0.1
    )
    kernel = st.selectbox(
        "Escolha o kernel", options=["linear", "rbf", "poly", "sigmoid"], index=0
    )

    # Guardar os valores no dicionﾃ｡rio de parﾃ｢metros
    manual_params['C'] = c
    manual_params['epsilon'] = epsilon
    manual_params['kernel'] = kernel

    # Configuraﾃｧﾃ｣o extra para o kernel 'rbf'
    if kernel == "rbf":
        gamma = st.number_input(
            "Parﾃ｢metro gamma", min_value=0.0, max_value=1.0, step=0.1, value=0.1
        )
        manual_params['gamma'] = gamma

    return manual_params

# -------------------------------------
# 東 FUNﾃﾃグ PARA CONFIGURAR MANUALMENTE O SVC (SUPPORT VECTOR CLASSIFICATION)
# -------------------------------------

def configure_svc(model_key, manual_params):
    """
    Configuraﾃｧﾃ｣o manual dos parﾃ｢metros para o modelo Support Vector Classification (SVC).

    Parﾃ｢metros:
    - model_key: Nome do modelo (SVC).
    - manual_params: Dicionﾃ｡rio para armazenar os hiperparﾃ｢metros configurados pelo utilizador.

    Retorno:
    - Dicionﾃ｡rio manual_params atualizado com os valores escolhidos pelo utilizador.
    """

    # Exibir o estado inicial dos parﾃ｢metros (para depuraﾃｧﾃ｣o)
    st.write("Estado inicial dos parﾃ｢metros:", st.session_state.get('manual_params', {}))

    # Seleﾃｧﾃ｣o do tipo de kernel
    kernel_value = st.selectbox(
        "Escolha o valor para 'kernel'",
        options=["linear", "rbf"],  # Opﾃｧﾃｵes disponﾃｭveis
        index=0,  # Define 'linear' como padrﾃ｣o
        key="kernel_selectbox"
    )

    # Definiﾃｧﾃ｣o do valor de 'C' (Parﾃ｢metro de regularizaﾃｧﾃ｣o)
    C_value = st.number_input(
        "Defina o valor para 'C'",
        min_value=0.01, step=0.01, value=1.0,
        key="C_input"
    )

    # Inicializar manual_params com os valores escolhidos
    manual_params = {
        "C": C_value,
        "kernel": kernel_value
    }

    # **Exibir 'gamma' apenas se o kernel for 'rbf'**
    if kernel_value == "rbf":
        gamma_value = st.selectbox(
            "Escolha o valor para 'gamma'",
            options=["scale", "auto"],  # Opﾃｧﾃｵes disponﾃｭveis
            index=0,
            key="gamma_selectbox"
        )
        manual_params["gamma"] = gamma_value  # Adiciona 'gamma' se necessﾃ｡rio

    else:
        # **Remover 'gamma' se o kernel for 'linear'**
        # Remover do manual_params local
        manual_params.pop('gamma', None)
        
        # Remover do estado global (caso tenha sido armazenado anteriormente)
        if 'manual_params' in st.session_state and 'gamma' in st.session_state['manual_params']:
            del st.session_state['manual_params']['gamma']  # Remove globalmente
            
        if 'best_params_str' in st.session_state:  # Remove dos parﾃ｢metros guardados
            st.session_state['best_params_str'] = json.dumps(manual_params, indent=2)

    # Exibir os parﾃ｢metros atualizados apﾃｳs a seleﾃｧﾃ｣o manual
    st.write("Parﾃ｢metros atualizados:", manual_params)

    # **Guardar os parﾃ｢metros configurados no estado global**
    st.session_state['manual_params'] = manual_params
    st.session_state['best_params_str'] = json.dumps(manual_params, indent=2)

    # Exibir os parﾃ｢metros guardados para depuraﾃｧﾃ｣o
    st.write("Parﾃ｢metros manuais salvos:", st.session_state['manual_params'])

    return manual_params


import pickle
import os

# -------------------------------------
# 東 FUNﾃﾃ髭S PARA GUARDAR E CARREGAR OS MELHORES PARﾃMETROS
# -------------------------------------

def save_best_params(params):
    """
    Guarda os melhores hiperparﾃ｢metros encontrados num ficheiro pickle.

    Parﾃ｢metros:
    - params (dict): Dicionﾃ｡rio contendo os melhores hiperparﾃ｢metros.
    
    Retorno:
    - Nenhum (apenas salva os dados).
    """
    with open('best_params.pkl', 'wb') as f:
        pickle.dump(params, f)

def load_best_params():
    """
    Carrega os melhores hiperparﾃ｢metros previamente guardados, se existirem.

    Retorno:
    - dict: Dicionﾃ｡rio contendo os melhores hiperparﾃ｢metros, ou None se nﾃ｣o existirem parﾃ｢metros guardados.
    """
    if os.path.exists('best_params.pkl'):
        with open('best_params.pkl', 'rb') as f:
            return pickle.load(f)
    return None


# -------------------------------------
# 東 FUNﾃﾃグ PARA TREINAR UM MODELO SVR COM OU SEM GRID SEARCH
# -------------------------------------

def train_svr_with_gridsearch(X_train, y_train, X_test, y_test, use_grid_search=True, manual_params=None):
    """
    Treina um modelo de Support Vector Regression (SVR) com ou sem otimizaﾃｧﾃ｣o de hiperparﾃ｢metros via GridSearchCV.

    Parﾃ｢metros:
    -----------
    - X_train : array-like
        Matriz de features do conjunto de treino.
    - y_train : array-like
        Vetor de rﾃｳtulos do conjunto de treino.
    - X_test : array-like
        Matriz de features do conjunto de teste.
    - y_test : array-like
        Vetor de rﾃｳtulos do conjunto de teste.
    - use_grid_search : bool (padrﾃ｣o=True)
        Define se serﾃ｡ utilizada a busca de hiperparﾃ｢metros via GridSearchCV.
    - manual_params : dict (opcional)
        Parﾃ｢metros especificados manualmente para substituir o GridSearch.

    Retorno:
    --------
    - dict:
        Dicionﾃ｡rio contendo as mﾃｩtricas de desempenho do modelo treinado e os melhores hiperparﾃ｢metros encontrados.
    """
    try:
        # -------------------------------------
        # 東 1. Padronizar os dados de entrada (necessﾃ｡rio para SVR)
        # -------------------------------------
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)  # Ajusta e transforma os dados de treino
        X_test_scaled = scaler.transform(X_test)  # Apenas transforma os dados de teste com os mesmos parﾃ｢metros

        # -------------------------------------
        # 東 2. Definir o modelo base SVR
        # -------------------------------------
        svr = SVR()

        # -------------------------------------
        # 東 3. Definir o grid de hiperparﾃ｢metros padrﾃ｣o para SVR
        # -------------------------------------
        param_grid = {
            'C': [0.1, 1, 10, 100],  # Parﾃ｢metro de regularizaﾃｧﾃ｣o
            'epsilon': [0.01, 0.1, 0.2],  # Margem de erro permitida
            'kernel': ['linear', 'rbf'],  # Tipos de kernel suportados
            'gamma': ['scale', 'auto']  # Ajuste da largura da funﾃｧﾃ｣o kernel
        }

        # Se o utilizador forneceu parﾃ｢metros manuais, substituir os valores no grid
        if manual_params:
            for param, value in manual_params.items():
                # Garante que o valor seja uma lista para compatibilidade com o GridSearchCV
                param_grid[param] = [value] if not isinstance(value, list) else value

        # -------------------------------------
        # 東 4. Definir a estratﾃｩgia de validaﾃｧﾃ｣o cruzada
        # -------------------------------------
        cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)  # Divide os dados em 5 partes

        # -------------------------------------
        # 東 5. Escolher entre GridSearchCV ou parﾃ｢metros manuais
        # -------------------------------------
        if use_grid_search:
            # Executar GridSearchCV para encontrar os melhores hiperparﾃ｢metros
            grid_search = GridSearchCV(
                estimator=svr, 
                param_grid=param_grid, 
                cv=cv_strategy, 
                scoring='neg_mean_squared_error',  # Critﾃｩrio de avaliaﾃｧﾃ｣o (erro quadrﾃ｡tico mﾃｩdio negativo)
                n_jobs=-1  # Utilizar todos os processadores disponﾃｭveis
            )
            grid_search.fit(X_train_scaled, y_train)

            # Melhor modelo encontrado pelo GridSearch
            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_
        
        else:
            # Aplicar parﾃ｢metros manuais, caso existam
            if manual_params:
                svr.set_params(**manual_params)

            # Treinar o modelo diretamente sem GridSearch
            best_model = svr.fit(X_train_scaled, y_train)
            best_params = manual_params or {}

        # -------------------------------------
        # 東 6. Fazer previsﾃｵes no conjunto de teste
        # -------------------------------------
        y_pred = best_model.predict(X_test_scaled)

        # -------------------------------------
        # 東 7. Calcular mﾃｩtricas de desempenho
        # -------------------------------------
        mse = mean_squared_error(y_test, y_pred)  # Erro Quadrﾃ｡tico Mﾃｩdio
        mae = mean_absolute_error(y_test, y_pred)  # Erro Absoluto Mﾃｩdio
        r2 = r2_score(y_test, y_pred)  # Rﾂｲ Score (coeficiente de determinaﾃｧﾃ｣o)

        # -------------------------------------
        # 東 8. Criar um dicionﾃ｡rio com as mﾃｩtricas do modelo
        # -------------------------------------
        metrics = {
            "Modelo": "Support Vector Regression (SVR)",
            "Rﾂｲ": r2,
            "MAE": mae,
            "MSE": mse,
            "Best Parameters": best_params  # Hiperparﾃ｢metros utilizados
        }

        return metrics  # Retorna as mﾃｩtricas para anﾃ｡lise
    
    except Exception as e:
        st.error(f"Erro ao treinar o modelo SVR: {str(e)}")  # Exibir erro no Streamlit caso ocorra
        return None


def train_model_with_gridsearch(model, param_grid, X_train, y_train, use_grid_search, manual_params=None, cv_choice="K-Fold"):
    """
    Treina um modelo de Machine Learning com ou sem otimizaﾃｧﾃ｣o de hiperparﾃ｢metros via GridSearchCV.

    Parﾃ｢metros:
    -----------
    - model : objeto do modelo
        Modelo de Machine Learning a ser treinado (ex: RandomForest, SVC, SVR, etc.).
    - param_grid : dict
        Dicionﾃ｡rio contendo os hiperparﾃ｢metros a serem ajustados.
    - X_train : array-like
        Matriz de features do conjunto de treino.
    - y_train : array-like
        Vetor de rﾃｳtulos do conjunto de treino.
    - use_grid_search : bool
        Define se serﾃ｡ utilizada a busca de hiperparﾃ｢metros via GridSearchCV.
    - manual_params : dict (opcional)
        Parﾃ｢metros especificados manualmente para substituir o GridSearch.
    - cv_choice : str (padrﾃ｣o="K-Fold")
        Mﾃｩtodo de validaﾃｧﾃ｣o cruzada a ser utilizado.

    Retorno:
    --------
    - best_model : objeto do modelo treinado
        Melhor modelo encontrado apﾃｳs o treino.
    - best_params : dict
        Dicionﾃ｡rio com os melhores hiperparﾃ｢metros utilizados.
    """
    try:
        # -------------------------------------
        # 東 1. Inicializar parﾃ｢metros manuais, caso nﾃ｣o tenham sido fornecidos
        # -------------------------------------
        if manual_params is None:
            manual_params = {}

        # Obter o nome do modelo
        model_name = type(model).__name__

        # Diagnﾃｳstico: Exibir parﾃ｢metros no estado global antes do treino
        st.write("剥 Parﾃ｢metros no estado global antes do treino:")
        st.write("笨 best_params:", st.session_state.get('best_params', {}))
        st.write("笨 manual_params:", st.session_state.get('manual_params', {}))

        # -------------------------------------
        # 東 2. Carregar parﾃ｢metros previamente guardados, se existirem
        # -------------------------------------
        saved_params = st.session_state.get('best_params', None)

        # Se houver parﾃ｢metros guardados e GridSearch nﾃ｣o for utilizado, aplicar os parﾃ｢metros salvos
        if saved_params and not use_grid_search:
            st.info(f"邃ｹｸ Aplicando parﾃ｢metros salvos ao modelo: {saved_params}")
            model.set_params(**saved_params)

        # -------------------------------------
        # 東 3. Ajustar manualmente parﾃ｢metros incompatﾃｭveis
        # -------------------------------------
        # Se o modelo for SVM e o kernel for 'linear', o parﾃ｢metro 'gamma' nﾃ｣o ﾃｩ necessﾃ｡rio
        if manual_params.get("kernel") == "linear" and "gamma" in manual_params:
            del manual_params["gamma"]

            # Remover 'gamma' do estado global, se presente
            if 'gamma' in st.session_state.get('manual_params', {}):
                del st.session_state['manual_params']['gamma']

        # -------------------------------------
        # 東 4. Treinar modelo com GridSearchCV (se ativado)
        # -------------------------------------
        if use_grid_search:
            # Atualizar o grid de hiperparﾃ｢metros com os valores fornecidos manualmente
            if manual_params:
                for param, value in manual_params.items():
                    if not isinstance(value, list):  # Garantir que o valor seja uma lista para compatibilidade com GridSearch
                        manual_params[param] = [value]
                param_grid.update(manual_params)

            # Definir estratﾃｩgia de validaﾃｧﾃ｣o cruzada
            cv_strategy = get_cv_strategy(cv_choice, X_train, y_train)

            # Definir mﾃｩtrica de avaliaﾃｧﾃ｣o (Rﾂｲ para regressﾃ｣o, accuracy para classificaﾃｧﾃ｣o)
            scoring = 'r2' if model_name == "SVR" else 'accuracy'

            # Configurar GridSearchCV para encontrar os melhores hiperparﾃ｢metros
            grid_search = GridSearchCV(
                estimator=model, 
                param_grid=param_grid, 
                cv=cv_strategy, 
                scoring=scoring, 
                n_jobs=-1  # Utilizar todos os processadores disponﾃｭveis
            )
            grid_search.fit(X_train, y_train)

            # Extrair melhor modelo e hiperparﾃ｢metros encontrados
            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_

            # Guardar os melhores parﾃ｢metros no estado global
            st.session_state['best_params'] = best_params
            st.success(f"識 Melhores parﾃ｢metros encontrados: {best_params}")

            return best_model, best_params

        # -------------------------------------
        # 東 5. Treinar modelo sem GridSearch (caso desativado)
        # -------------------------------------
        else:
            # Filtrar apenas os parﾃ｢metros vﾃ｡lidos para o modelo
            valid_params = model.get_params().keys()
            manual_params = {k: v for k, v in manual_params.items() if k in valid_params}

            # Aplicar os parﾃ｢metros escolhidos manualmente
            model.set_params(**manual_params)

            # Treinar o modelo diretamente sem GridSearch
            model.fit(X_train, y_train)

            # Guardar os parﾃ｢metros manuais no estado global
            st.session_state['manual_params'] = manual_params
            st.success(f"統 Parﾃ｢metros manuais salvos: {manual_params}")

            return model, manual_params

    # -------------------------------------
    # 東 6. Capturar e exibir erros, caso ocorram
    # -------------------------------------
    except Exception as e:
        st.error(f"笶 Ocorreu um erro ao treinar o modelo: {str(e)}")
        return None, None


# Funﾃｧﾃ｣o para calcular o Gap Statistic para o Clustering Hierﾃ｡rquico
def calculate_gap_statistic_hierarchical(X, n_clusters_range, n_ref=10):
    """
    Calcula a estatﾃｭstica de Gap (Gap Statistic) para o algoritmo AgglomerativeClustering.

    Parﾃ｢metros:
    -----------
    - X (ndarray): Dados de entrada no formato (n_samples x n_features).
    - n_clusters_range (tuple): Intervalo de nﾃｺmeros de clusters a serem avaliados, ex: (2, 10).
    - n_ref (int, padrﾃ｣o=10): Nﾃｺmero de amostras de referﾃｪncia aleatﾃｳrias geradas para cﾃ｡lculo do Gap.

    Retorno:
    --------
    - gap_scores (list): Lista com os valores de Gap Statistic para cada nﾃｺmero de clusters avaliado.
    """
    # -------------------------------------
    # 東 1. Normalizar os dados antes do clustering
    # -------------------------------------
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Lista para armazenar os valores de Gap Statistic
    gap_scores = []

    # -------------------------------------
    # 東 2. Avaliar diferentes nﾃｺmeros de clusters
    # -------------------------------------
    for n_clusters in range(n_clusters_range[0], n_clusters_range[1] + 1):
        # **Ajustar o modelo AgglomerativeClustering aos dados reais**
        model = AgglomerativeClustering(n_clusters=n_clusters)
        model.fit(X_scaled)
        labels = model.labels_

        # **Calcular a soma das distﾃ｢ncias intra-cluster**
        intra_cluster_dist = sum([
            np.sum(np.linalg.norm(X_scaled[labels == i] - X_scaled[labels == i].mean(axis=0), axis=1))
            for i in range(n_clusters)
        ])

        # -------------------------------------
        # 東 3. Criar conjuntos de dados de referﾃｪncia aleatﾃｳrios
        # -------------------------------------
        ref_inertias = []
        for _ in range(n_ref):
            # Gerar dados aleatﾃｳrios no mesmo espaﾃｧo dimensional
            random_data = np.random.random_sample(size=X_scaled.shape)

            # Aplicar AgglomerativeClustering nos dados aleatﾃｳrios
            random_model = AgglomerativeClustering(n_clusters=n_clusters)
            random_model.fit(random_data)
            ref_labels = random_model.labels_

            # **Calcular a soma das distﾃ｢ncias intra-cluster para os dados aleatﾃｳrios**
            ref_inertia = sum([
                np.sum(np.linalg.norm(random_data[ref_labels == i] - random_data[ref_labels == i].mean(axis=0), axis=1))
                for i in range(n_clusters)
            ])
            ref_inertias.append(ref_inertia)

        # -------------------------------------
        # 東 4. Calcular a estatﾃｭstica de Gap
        # -------------------------------------
        # Mﾃｩdia e desvio padrﾃ｣o das inﾃｩrcias dos clusters aleatﾃｳrios
        ref_inertia_mean = np.mean(ref_inertias)
        ref_inertia_std = np.std(ref_inertias)

        # Gap Statistic: diferenﾃｧa entre a inﾃｩrcia real e a mﾃｩdia das inﾃｩrcias aleatﾃｳrias
        gap = np.log(ref_inertia_mean) - np.log(intra_cluster_dist)
        gap_scores.append(gap)

    return gap_scores


# Funﾃｧﾃ｣o para a seleﾃｧﾃ｣o e treino de modelos
def model_selection():
    """
    Esta funﾃｧﾃ｣o permite ao utilizador selecionar e treinar um modelo de Machine Learning 
    atravﾃｩs da interface do Streamlit.
    """
    st.subheader("Seleﾃｧﾃ｣o e Treino de Modelos")

    # 東 1. Verificaﾃｧﾃ｣o se os dados estﾃ｣o disponﾃｭveis
    if 'data' not in st.session_state or st.session_state.data is None:
        st.error("Dados nﾃ｣o encontrados. Por favor, carregue os dados primeiro.")
        return

    # Obter os dados e as colunas disponﾃｭveis
    data = st.session_state.data
    columns = data.columns.tolist()

    # 東 2. Inicializar variﾃ｡veis de estado caso nﾃ｣o existam
    if 'target_column' not in st.session_state:
        st.session_state.target_column = None
    if 'target_column_confirmed' not in st.session_state:
        st.session_state.target_column_confirmed = False
    if 'validation_method' not in st.session_state:
        st.session_state.validation_method = None
    if 'validation_confirmed' not in st.session_state:
        st.session_state.validation_confirmed = False
    if 'model_type' not in st.session_state:
        st.session_state.model_type = None
    if 'model_type_confirmed' not in st.session_state:
        st.session_state.model_type_confirmed = False
    if 'X_train' not in st.session_state:
        st.session_state.X_train = None
    if 'X_test' not in st.session_state:
        st.session_state.X_test = None
    if 'y_train' not in st.session_state:
        st.session_state.y_train = None
    if 'y_test' not in st.session_state:
        st.session_state.y_test = None
    if 'feature_selection_done' not in st.session_state:
        st.session_state.feature_selection_done = False

    # 東 3. Configuraﾃｧﾃｵes gerais
    st.write("### Configuraﾃｧﾃｵes")

    # 東 4. Escolha do Tipo de Modelo
    if not st.session_state.model_type_confirmed:
        st.write("Escolha o Tipo de Modelo")
        model_types = ["Classificaﾃｧﾃ｣o", "Regressﾃ｣o", "Clustering"]
        st.session_state.model_type = st.selectbox("Selecione o tipo de modelo", model_types)

        if st.button("Confirmar Tipo de Modelo"):
            st.session_state.model_type_confirmed = True
            st.success("Tipo de modelo confirmado!")

    # 東 5. Escolha do Modelo Especﾃｭfico
    if st.session_state.model_type_confirmed and not st.session_state.selected_model_name:
        st.write("Selecione o(s) Modelo(s)")

        # Dicionﾃ｡rio com os modelos disponﾃｭveis para cada tipo
        if st.session_state.model_type == "Classificaﾃｧﾃ｣o":
            models = {
                "Support Vector Classification (SVC)": SVC(),
                "K-Nearest Neighbors (KNN)": KNeighborsClassifier(),
                "Random Forest": RandomForestClassifier()
            }
        elif st.session_state.model_type == "Regressﾃ｣o":
            models = {
                "Regressﾃ｣o Linear Simples (RLS)": LinearRegression(),
                "Regressﾃ｣o por Vetores de Suporte (SVR)": SVR(),
            }
        elif st.session_state.model_type == "Clustering":
            models = {
                "KMeans": KMeans(),
                "Clustering Hierﾃ｡rquico": AgglomerativeClustering(linkage='ward'),
            }

        # Armazena os modelos no estado da sessﾃ｣o para uso posterior
        st.session_state.models = models

        # 東 6. Criar lista de opﾃｧﾃｵes de modelos disponﾃｭveis
        model_options = list(models.keys())  # Lista com os nomes dos modelos

        # Definir o modelo predefinido para evitar erro de ﾃｭndice
        default_model_name = st.session_state.get("model_name", model_options[0])

        # Criar menu de seleﾃｧﾃ｣o do modelo
        model_name = st.selectbox(
            "Selecione o modelo", 
            options=model_options, 
            key="model_name_selectbox", 
            index=model_options.index(default_model_name)
        )

        # Atualizar o estado global do modelo selecionado
        st.session_state["model_name"] = model_name
        st.session_state.model_name = model_name

        # 東 7. Botﾃ｣o para confirmar o modelo selecionado
        if st.button("Confirmar Modelo"):
            if model_name:  # Verifica se um modelo foi selecionado
                st.session_state.selected_model_name = model_name
                st.success(f"Modelo selecionado: {st.session_state.selected_model_name}")
            else:
                st.warning("Selecione um modelo antes de continuar.")

    # Funﾃｧﾃ｣o para a configuraﾃｧﾃ｣o de Clustering
    import pandas as pd
    from sklearn.decomposition import PCA
    import numpy as np
    
    # Inicializar a variﾃ｡vel best_n_clusters_retrain com um valor padrﾃ｣o
    best_n_clusters_retrain = None
    
    # Inicializar estados se ainda nﾃ｣o existirem
    if 'pca_configured' not in st.session_state:
        st.session_state.pca_configured = False
    if 'ready_for_clustering' not in st.session_state:
        st.session_state.ready_for_clustering = False
    
    # Verifica se o modelo selecionado ﾃｩ de Clustering e se hﾃ｡ um modelo escolhido
    if st.session_state.model_type == "Clustering" and st.session_state.selected_model_name:
        st.write("### Configuraﾃｧﾃ｣o para Clustering")
    
        # Codificar variﾃ｡veis categﾃｳricas para representaﾃｧﾃ｣o numﾃｩrica
        X = pd.get_dummies(st.session_state.data)
    
        # Padronizar os dados para melhorar a eficﾃ｡cia dos algoritmos de clustering
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # ETAPA 1: Configuraﾃｧﾃ｣o do PCA para Clustering Hierﾃ｡rquico
        if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico" and not st.session_state.pca_configured:
            st.write("### Reduﾃｧﾃ｣o de Dimensionalidade com PCA para Clustering Hierﾃ｡rquico")
            
            # Verificar se o dataset ﾃｩ grande o suficiente para exigir PCA
            if X.shape[0] > 1000 or X.shape[1] > 10:
                st.warning(f"Atenﾃｧﾃ｣o: O seu dataset tem {X.shape[0]} registos e {X.shape[1]} dimensﾃｵes. A aplicaﾃｧﾃ｣o de PCA pode ser necessﾃ｡ria para otimizar o desempenho do Clustering Hierﾃ｡rquico.")
            
            # Permitir ao utilizador escolher o nﾃｺmero de componentes ou utilizar um valor automﾃ｡tico
            use_auto_components = st.checkbox("Determinar automaticamente o nﾃｺmero de componentes", value=True, key="auto_comp_hierarch")
            
            if use_auto_components:
                # Calcular o PCA para determinar a variﾃ｢ncia explicada
                pca_full = PCA().fit(X_scaled)
                explained_variance_ratio = pca_full.explained_variance_ratio_
                cumulative_variance = np.cumsum(explained_variance_ratio)
                
                # Determinar o nﾃｺmero de componentes que explicam pelo menos 90% da variﾃ｢ncia
                n_components = np.argmax(cumulative_variance >= 0.9) + 1
                n_components = min(n_components, 10)  # Limitar a no mﾃ｡ximo 10 componentes
                
                st.write(f"Nﾃｺmero de componentes selecionados automaticamente: {n_components} (explica aproximadamente {cumulative_variance[n_components-1]*100:.1f}% da variﾃ｢ncia)")
                
                # Criar um grﾃ｡fico para visualizar a variﾃ｢ncia explicada
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='-')
                ax.axhline(y=0.9, color='r', linestyle='--', label='90% Variﾃ｢ncia Explicada')
                ax.axvline(x=n_components, color='g', linestyle='--', label=f'{n_components} Componentes')
                ax.set_xlabel('Nﾃｺmero de Componentes')
                ax.set_ylabel('Variﾃ｢ncia Explicada Acumulada')
                ax.set_title('Variﾃ｢ncia Explicada por Componentes do PCA')
                ax.legend()
                st.pyplot(fig)
                plt.clf()
            else:
                # Permitir que o utilizador escolha manualmente o nﾃｺmero de componentes
                max_components = min(X.shape[1], 20)  # Limitar ao nﾃｺmero de features ou 20, o que for menor
                n_components = st.slider("Nﾃｺmero de componentes PCA para Hierﾃ｡rquico", 2, max_components, value=min(3, max_components), key="n_comp_hierarch")
            
            # Botﾃ｣o para confirmar a configuraﾃｧﾃ｣o do PCA
            if st.button("Confirmar Configuraﾃｧﾃ｣o do PCA para Clustering Hierﾃ｡rquico"):
                # Aplicar PCA com o nﾃｺmero de componentes escolhido
                pca = PCA(n_components=n_components)
                X_pca = pca.fit_transform(X_scaled)
                
                # Guardar os dados transformados e as configuraﾃｧﾃｵes no estado da sessﾃ｣o
                st.session_state.X_pca = X_pca
                st.session_state.pca_n_components = n_components
                st.session_state.pca_configured = True
                st.session_state.pca_model = pca
                st.session_state.explained_variance = pca.explained_variance_ratio_
                
                st.success(f"PCA configurado com sucesso! Dimensionalidade reduzida de {X_scaled.shape[1]} para {X_pca.shape[1]} componentes.")
                
                # Visualizar os dados apﾃｳs a aplicaﾃｧﾃ｣o do PCA se tivermos pelo menos 2 componentes
                if n_components >= 2:
                    st.write("### Visualizaﾃｧﾃ｣o dos Dados Apﾃｳs PCA")
                    
                    # Permitir ao utilizador escolher os componentes a visualizar
                    available_components = min(n_components, 10)  # Limitar a 10 para evitar sobrecarga
                    
                    component_x = st.selectbox(
                        "Escolha o componente para o eixo X:",
                        options=list(range(available_components)),
                        format_func=lambda x: f"Componente {x+1}",
                        index=0,
                        key="comp_x_hierarch"
                    )
                    
                    component_y = st.selectbox(
                        "Escolha o componente para o eixo Y:",
                        options=list(range(available_components)),
                        format_func=lambda x: f"Componente {x+1}",
                        index=1 if available_components > 1 else 0,
                        key="comp_y_hierarch"
                    )
                    
                    # Criar um grﾃ｡fico de dispersﾃ｣o com os componentes escolhidos
                    fig, ax = plt.subplots(figsize=(10, 6))
                    scatter = ax.scatter(X_pca[:, component_x], X_pca[:, component_y], alpha=0.7)
                    ax.set_xlabel(f'Componente Principal {component_x+1}', fontsize=12)
                    ax.set_ylabel(f'Componente Principal {component_y+1}', fontsize=12)
                    ax.set_title(f'Visualizaﾃｧﾃ｣o 2D dos Componentes PCA {component_x+1} e {component_y+1}', fontsize=14, fontweight='bold')
                    ax.grid(True, linestyle='--', alpha=0.7)
                    
                    # Mostrar a variﾃ｢ncia explicada por cada componente escolhido
                    if hasattr(pca, 'explained_variance_ratio_'):
                        var_x = pca.explained_variance_ratio_[component_x] * 100
                        var_y = pca.explained_variance_ratio_[component_y] * 100
                        ax.set_xlabel(f'Componente Principal {component_x+1} ({var_x:.1f}% variﾃ｢ncia)', fontsize=12)
                        ax.set_ylabel(f'Componente Principal {component_y+1} ({var_y:.1f}% variﾃ｢ncia)', fontsize=12)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.clf()
    
            # Botﾃ｣o para avanﾃｧar para a configuraﾃｧﾃ｣o do clustering
            if st.button("Prosseguir para Clustering"):
                st.session_state.ready_for_clustering = True
                st.rerun()
           
        # ETAPA 1: Configuraﾃｧﾃ｣o do PCA para KMeans
        if st.session_state.selected_model_name == "KMeans" and not st.session_state.pca_configured:
            st.write("### Reduﾃｧﾃ｣o de Dimensionalidade com PCA")
            
            # Verificar se o dataset ﾃｩ grande e pode beneficiar do PCA
            if X.shape[0] > 1000 or X.shape[1] > 10:
                st.warning(f"Atenﾃｧﾃ｣o: O seu dataset tem {X.shape[0]} registos e {X.shape[1]} dimensﾃｵes. A aplicaﾃｧﾃ｣o de PCA ﾃｩ altamente recomendada para melhorar a eficiﾃｪncia do modelo.")
        
            # Permitir ao utilizador escolher entre uma determinaﾃｧﾃ｣o automﾃ｡tica ou manual do nﾃｺmero de componentes
            use_auto_components = st.checkbox("Determinar automaticamente o nﾃｺmero de componentes", value=True)
        
            if use_auto_components:
                # Calcular o PCA para determinar a variﾃ｢ncia explicada por cada componente
                pca_full = PCA().fit(X_scaled)
                explained_variance_ratio = pca_full.explained_variance_ratio_
                cumulative_variance = np.cumsum(explained_variance_ratio)
        
                # Determinar o nﾃｺmero de componentes necessﾃ｡rios para explicar pelo menos 90% da variﾃ｢ncia total
                n_components = np.argmax(cumulative_variance >= 0.9) + 1
                n_components = min(n_components, 10)  # Limitar a no mﾃ｡ximo 10 componentes
        
                st.write(f"Nﾃｺmero de componentes selecionados automaticamente: {n_components} (explica aproximadamente {cumulative_variance[n_components-1]*100:.1f}% da variﾃ｢ncia)")
                
                # Criar um grﾃ｡fico para visualizar a variﾃ｢ncia explicada pelos componentes do PCA
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='-')
                ax.axhline(y=0.9, color='r', linestyle='--', label='90% Variﾃ｢ncia Explicada')
                ax.axvline(x=n_components, color='g', linestyle='--', label=f'{n_components} Componentes')
                ax.set_xlabel('Nﾃｺmero de Componentes')
                ax.set_ylabel('Variﾃ｢ncia Explicada Acumulada')
                ax.set_title('Variﾃ｢ncia Explicada por Componentes do PCA')
                ax.legend()
                st.pyplot(fig)
                plt.clf()
            else:
                # Permitir ao utilizador selecionar manualmente o nﾃｺmero de componentes a utilizar
                max_components = min(X.shape[1], 20)  # Limitar ao nﾃｺmero de features ou 20, o que for menor
                n_components = st.slider("Nﾃｺmero de componentes PCA", 2, max_components, value=min(3, max_components))
        
            # Botﾃ｣o para confirmar a configuraﾃｧﾃ｣o do PCA
            if st.button("Confirmar Configuraﾃｧﾃ｣o do PCA"):
                # Aplicar o PCA com o nﾃｺmero de componentes escolhido
                pca = PCA(n_components=n_components)
                X_pca = pca.fit_transform(X_scaled)
        
                # Guardar os dados transformados e as configuraﾃｧﾃｵes no estado da sessﾃ｣o
                st.session_state.X_pca = X_pca
                st.session_state.pca_n_components = n_components
                st.session_state.pca_configured = True
                st.session_state.pca_model = pca
                st.session_state.explained_variance = pca.explained_variance_ratio_
        
                st.success(f"PCA configurado com sucesso! Dimensionalidade reduzida de {X_scaled.shape[1]} para {X_pca.shape[1]} componentes.")
        
                # Visualizaﾃｧﾃ｣o 2D dos dados apﾃｳs PCA, caso tenhamos pelo menos 2 componentes
                if n_components >= 2:
                    st.write("### Visualizaﾃｧﾃ｣o dos Dados Apﾃｳs PCA")
        
                    # Permitir ao utilizador escolher os componentes a visualizar
                    available_components = min(n_components, 10)  # Limitar a 10 para evitar sobrecarga
        
                    component_x = st.selectbox(
                        "Escolha o componente para o eixo X:",
                        options=list(range(available_components)),
                        format_func=lambda x: f"Componente {x+1}",
                        index=0
                    )
        
                    component_y = st.selectbox(
                        "Escolha o componente para o eixo Y:",
                        options=list(range(available_components)),
                        format_func=lambda x: f"Componente {x+1}",
                        index=1 if available_components > 1 else 0
                    )
        
                    # Criar um grﾃ｡fico de dispersﾃ｣o com os componentes escolhidos
                    fig, ax = plt.subplots(figsize=(10, 6))
                    scatter = ax.scatter(X_pca[:, component_x], X_pca[:, component_y], alpha=0.7)
                    ax.set_xlabel(f'Componente Principal {component_x+1}', fontsize=12)
                    ax.set_ylabel(f'Componente Principal {component_y+1}', fontsize=12)
                    ax.set_title(f'Visualizaﾃｧﾃ｣o 2D dos Componentes PCA {component_x+1} e {component_y+1}', fontsize=14, fontweight='bold')
                    ax.grid(True, linestyle='--', alpha=0.7)
        
                    # Exibir a variﾃ｢ncia explicada pelos componentes selecionados, se disponﾃｭvel
                    if hasattr(pca, 'explained_variance_ratio_'):
                        var_x = pca.explained_variance_ratio_[component_x] * 100
                        var_y = pca.explained_variance_ratio_[component_y] * 100
                        ax.set_xlabel(f'Componente Principal {component_x+1} ({var_x:.1f}% variﾃ｢ncia)', fontsize=12)
                        ax.set_ylabel(f'Componente Principal {component_y+1} ({var_y:.1f}% variﾃ｢ncia)', fontsize=12)
        
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.clf()
        
                # Botﾃ｣o para avanﾃｧar para a configuraﾃｧﾃ｣o do clustering
                if st.button("Prosseguir para Clustering"):
                    st.session_state.ready_for_clustering = True
                    st.rerun()
    
        # ETAPA 2: Configuraﾃｧﾃ｣o do Clustering (apﾃｳs o PCA para Hierarchical ou diretamente para K-means)
        elif st.session_state.selected_model_name == "KMeans" or (st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico" and st.session_state.pca_configured):
            
            # Escolher o intervalo de clusters a explorar (reduzido para 2-10 por padrﾃ｣o para evitar processamento excessivo)
            num_clusters_range = st.slider("Intervalo de clusters para explorar (para anﾃ｡lise)", 2, 10, (2, 6))
        
            # Definir os dados de treino conforme o mﾃｩtodo de clustering escolhido
            if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                # Se for Clustering Hierﾃ｡rquico, usar os dados transformados pelo PCA
                training_data = st.session_state.X_pca
            else:
                # Se for K-Means, utilizar os dados normalizados sem PCA
                training_data = X_scaled
        
            # Opﾃｧﾃ｣o para utilizar amostragem, permitindo uma anﾃ｡lise mais rﾃ｡pida
            use_sampling = st.checkbox("Usar amostragem dos dados para anﾃ｡lise mais rﾃ｡pida", value=True)
            if use_sampling:
                # Permitir ao utilizador selecionar o tamanho da amostra para anﾃ｡lise
                sample_size = st.slider("Tamanho da amostra", 
                                        min_value=min(100, training_data.shape[0]),
                                        max_value=min(2000, training_data.shape[0]),
                                        value=min(1000, training_data.shape[0]))
                
                # Realizar a amostragem aleatﾃｳria dos dados
                np.random.seed(42)  # Para garantir reprodutibilidade dos resultados
                sample_indices = np.random.choice(training_data.shape[0], sample_size, replace=False)
                analysis_data = training_data[sample_indices]
                st.info(f"Usando {sample_size} pontos ({sample_size/training_data.shape[0]:.1%} dos dados) para anﾃ｡lise.")
            else:
                # Caso a amostragem nﾃ｣o seja ativada, utilizar todos os dados disponﾃｭveis
                analysis_data = training_data
        
            # Inﾃｭcio da anﾃ｡lise para determinar o nﾃｺmero ideal de clusters
            st.write("### Anﾃ｡lise para Determinaﾃｧﾃ｣o do Nﾃｺmero de Clusters")
        
            # Inicializar listas para armazenar as mﾃｩtricas de avaliaﾃｧﾃ｣o dos clusters
            silhouette_scores = []
            davies_bouldin_scores = []
            calinski_harabasz_scores = []
        
            # Criar uma barra de progresso e um espaﾃｧo para atualizar o status do processamento
            progress_bar = st.progress(0)
            status_text = st.empty()
        
            # Calcular mﾃｩtricas para cada nﾃｺmero de clusters dentro do intervalo selecionado
            total_iterations = num_clusters_range[1] - num_clusters_range[0] + 1
        
            # Loop para testar diferentes quantidades de clusters
            for i, n_clusters in enumerate(range(num_clusters_range[0], num_clusters_range[1] + 1)):
                # Atualizar a barra de progresso
                progress = (i + 1) / total_iterations
                progress_bar.progress(progress)
                status_text.text(f"Analisando com {n_clusters} clusters... ({i+1}/{total_iterations})")
        
                try:
                    # Verificar qual mﾃｩtodo de clustering foi escolhido
                    if st.session_state.selected_model_name == "KMeans":
                        # Para KMeans, otimizar os hiperparﾃ｢metros reduzindo n_init e max_iter
                        temp_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=5, max_iter=100)
                    else:
                        # Para Clustering Hierﾃ｡rquico, utilizar o mﾃｩtodo de ligaﾃｧﾃ｣o "ward"
                        temp_model = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')
        
                    # Treinar o modelo com os dados amostrados
                    temp_model.fit(analysis_data)
                    labels = temp_model.labels_
        
                    # Calcular e armazenar as mﾃｩtricas de avaliaﾃｧﾃ｣o do clustering
                    silhouette_scores.append(silhouette_score(analysis_data, labels))
                    davies_bouldin_scores.append(davies_bouldin_score(analysis_data, labels))
                    calinski_harabasz_scores.append(calinski_harabasz_score(analysis_data, labels))
        
                except Exception as e:
                    # Caso ocorra um erro durante a execuﾃｧﾃ｣o, mostrar mensagem ao utilizador
                    st.error(f"Erro ao processar {n_clusters} clusters: {str(e)}")
                    # Preencher com valores neutros para manter a estrutura do array
                    silhouette_scores.append(0)
                    davies_bouldin_scores.append(float('inf'))
                    calinski_harabasz_scores.append(0)
        
            # Limpar barra de progresso e status apﾃｳs a conclusﾃ｣o
            status_text.empty()
            progress_bar.empty()
        
            # Criar um DataFrame com os resultados das mﾃｩtricas calculadas
            metrics_df = pd.DataFrame({
                "Nﾃｺmero de Clusters": range(num_clusters_range[0], num_clusters_range[1] + 1),
                "Silhouette Score": silhouette_scores,
                "Davies-Bouldin Index": davies_bouldin_scores,
                "Calinski-Harabasz Score": calinski_harabasz_scores,
            })
        
            # Exibir a tabela de mﾃｩtricas no Streamlit
            st.write("#### Tabela de Mﾃｩtricas por Nﾃｺmero de Clusters")
            st.dataframe(fix_dataframe_types(metrics_df.style.format({
                "Silhouette Score": "{:.2f}",
                "Davies-Bouldin Index": "{:.2f}",
                "Calinski-Harabasz Score": "{:.2f}",
            })))
        
            # Exibir grﾃ｡ficos das mﾃｩtricas para facilitar a interpretaﾃｧﾃ｣o visual
            st.write("#### Grﾃ｡ficos das Mﾃｩtricas por Nﾃｺmero de Clusters")
            
            # Criar colunas para organizar a exibiﾃｧﾃ｣o dos grﾃ｡ficos
            col1, col2, col3 = st.columns(3)
        
            # Grﾃ｡fico do Silhouette Score
            with col1:
                plt.figure(figsize=(6, 4))
                plt.plot(metrics_df["Nﾃｺmero de Clusters"], metrics_df["Silhouette Score"], marker='o')
                plt.title("Silhouette Score por Nﾃｺmero de Clusters")
                plt.xlabel("Nﾃｺmero de Clusters")
                plt.ylabel("Silhouette Score")
                st.pyplot(plt.gcf())
                plt.clf()
        
            # Grﾃ｡fico do Davies-Bouldin Index
            with col2:
                plt.figure(figsize=(6, 4))
                plt.plot(metrics_df["Nﾃｺmero de Clusters"], metrics_df["Davies-Bouldin Index"], marker='o')
                plt.title("Davies-Bouldin Index por Nﾃｺmero de Clusters")
                plt.xlabel("Nﾃｺmero de Clusters")
                plt.ylabel("Davies-Bouldin Index")
                st.pyplot(plt.gcf())
                plt.clf()
        
            # Grﾃ｡fico do Calinski-Harabasz Score
            with col3:
                plt.figure(figsize=(6, 4))
                plt.plot(metrics_df["Nﾃｺmero de Clusters"], metrics_df["Calinski-Harabasz Score"], marker='o')
                plt.title("Calinski-Harabasz Score por Nﾃｺmero de Clusters")
                plt.xlabel("Nﾃｺmero de Clusters")
                plt.ylabel("Calinski-Harabasz Score")
                st.pyplot(plt.gcf())
                plt.clf()

            # Escolher o melhor nﾃｺmero de clusters com base no Silhouette Score
            if silhouette_scores and any(score > 0 for score in silhouette_scores):
                best_n_clusters = metrics_df.loc[metrics_df["Silhouette Score"].idxmax(), "Nﾃｺmero de Clusters"]
                st.write(f"**Melhor Nﾃｺmero de Clusters** (com base no Silhouette Score): {best_n_clusters}")
                best_n_clusters_retrain = best_n_clusters
            
            # Permitir ao utilizador escolher a abordagem para determinar o nﾃｺmero de clusters
            st.write("### Escolha a Abordagem para Determinar o Nﾃｺmero de Clusters")
            method = st.radio("Selecione a abordagem:", ["Automﾃ｡tico", "Manual"], key="initial_training_method")
            
            if method == "Automﾃ｡tico":
                # Determinar automaticamente o melhor nﾃｺmero de clusters com base no Silhouette Score
                if silhouette_scores and any(score > 0 for score in silhouette_scores):
                    best_n_clusters = range(num_clusters_range[0], num_clusters_range[1] + 1)[np.argmax(silhouette_scores)]
                    best_n_clusters_retrain = best_n_clusters  # Atualizar o valor para re-treino
                else:
                    # Caso a determinaﾃｧﾃ｣o automﾃ｡tica falhe, exibir erro e atribuir um valor padrﾃ｣o
                    st.error("Nﾃ｣o foi possﾃｭvel determinar automaticamente o nﾃｺmero de clusters. Por favor, selecione manualmente.")
                    best_n_clusters_retrain = 3  # Valor padrﾃ｣o
            
            elif method == "Manual":
                # Permitir ao utilizador escolher manualmente o nﾃｺmero de clusters
                best_n_clusters = st.slider("Escolha o nﾃｺmero de clusters", num_clusters_range[0], num_clusters_range[1], value=3)
                best_n_clusters_retrain = best_n_clusters  # Atualizar o valor para re-treino
            
            # Garantir que `best_n_clusters_retrain` tenha um valor vﾃ｡lido antes de continuar
            if best_n_clusters_retrain is None:
                st.warning("Por favor, selecione uma abordagem para determinar o nﾃｺmero de clusters.")
            else:
                # Treinar o modelo inicial
                if st.button(f"Treinar Modelo Inicial"):
                    # Configurar o modelo de clustering escolhido
                    if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                        model = st.session_state.models["Clustering Hierﾃ｡rquico"]
                        model.set_params(n_clusters=best_n_clusters_retrain, linkage='ward')
                    else:  # KMeans
                        model = st.session_state.models["KMeans"]
                        # Ajustar hiperparﾃ｢metros para otimizaﾃｧﾃ｣o no treino final
                        model.set_params(n_clusters=best_n_clusters_retrain, n_init=5, max_iter=300)
            
                    # Barra de progresso para o treino do modelo
                    with st.spinner(f"Treinando o modelo com {best_n_clusters_retrain} clusters..."):
                        model.fit(training_data)
                        st.session_state.clustering_labels = model.labels_
            
                    # Calcular mﾃｩtricas de avaliaﾃｧﾃ｣o do clustering
                    st.session_state.initial_metrics = {
                        "Nﾃｺmero de Clusters": best_n_clusters_retrain,
                        "Silhouette Score": silhouette_score(training_data, st.session_state.clustering_labels),
                        "Davies-Bouldin Index": davies_bouldin_score(training_data, st.session_state.clustering_labels),
                        "Calinski-Harabasz Score": calinski_harabasz_score(training_data, st.session_state.clustering_labels)
                    }
            
                    # Guardar informaﾃｧﾃｵes importantes no estado da sessﾃ｣o
                    st.session_state.training_data = training_data
                    st.session_state.training_completed = True
                    st.session_state.trained_model = model  # Guardar o modelo treinado
            
                    # Exibir mensagem de sucesso conforme o mﾃｩtodo escolhido
                    if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                        st.success(f"Modelo hierﾃ｡rquico treinado com sucesso usando {best_n_clusters_retrain} clusters e {st.session_state.pca_n_components} componentes PCA!")
                    else:
                        st.success(f"Modelo K-Means treinado com sucesso usando {best_n_clusters_retrain} clusters!")
            
            # Exibir mﾃｩtricas e visualizaﾃｧﾃ｣o apenas apﾃｳs o treino do modelo
            if st.session_state.get("training_completed", False):
                st.write("### Mﾃｩtricas do Treino Inicial")
                st.table(fix_dataframe_types(pd.DataFrame([st.session_state.initial_metrics])))
            
                # Visualizaﾃｧﾃ｣o dos clusters treinados
                if 'clustering_labels' in st.session_state:
                    st.write("### Visualizaﾃｧﾃ｣o dos Clusters")
            
                    # Para K-Means, mostrar os centroides dos clusters
                    if st.session_state.selected_model_name == "KMeans":
                        if "trained_model" in st.session_state and hasattr(st.session_state.trained_model, 'cluster_centers_'):
                            st.write("#### Centroides dos Clusters")
                            centroids = st.session_state.trained_model.cluster_centers_
                            
                            # Exibir apenas as primeiras 10 dimensﾃｵes, se existirem muitas dimensﾃｵes
                            if centroids.shape[1] > 10:
                                st.write(f"(Mostrando apenas as primeiras 10 dimensﾃｵes de {centroids.shape[1]})")
                                centroids_df = pd.DataFrame(centroids[:, :10])
                            else:
                                centroids_df = pd.DataFrame(centroids)
            
                            st.dataframe(fix_dataframe_types(centroids_df))
            
                    # Preparar dados para visualizaﾃｧﾃ｣o dos clusters
                    if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                        # Para Clustering Hierﾃ｡rquico, utilizar os dados reduzidos pelo PCA
                        plot_data = st.session_state.X_pca
                    else:
                        # Para K-Means, reduzir dimensionalidade se necessﾃ｡rio
                        if X_scaled.shape[1] > 3:
                            pca_viz = PCA(n_components=3)
                            plot_data = pca_viz.fit_transform(X_scaled)
                            st.write("(Dados reduzidos via PCA para visualizaﾃｧﾃ｣o)")
                        else:
                            plot_data = X_scaled
            
                    # Obter o nﾃｺmero total de componentes disponﾃｭveis para visualizaﾃｧﾃ｣o
                    total_components = plot_data.shape[1]
            
                    # Permitir ao utilizador escolher os componentes para visualizaﾃｧﾃ｣o
                    st.write("### Escolha os Componentes para Visualizaﾃｧﾃ｣o")
                    col1, col2 = st.columns(2)
            
                    with col1:
                        x_component = st.selectbox(
                            "Componente para o Eixo X",
                            list(range(total_components)),
                            index=0,
                            format_func=lambda x: f"Componente {x+1}",
                            key="initial_x_component"
                        )
            
                    with col2:
                        y_component = st.selectbox(
                            "Componente para o Eixo Y",
                            list(range(total_components)),
                            index=1 if total_components > 1 else 0,
                            format_func=lambda x: f"Componente {x+1}",
                            key="initial_y_component"
                        )
            
                    # Verificar se os componentes escolhidos sﾃ｣o diferentes
                    if x_component == y_component:
                        st.warning("Por favor, selecione componentes diferentes para X e Y.")
                    else:
                        # Criar grﾃ｡fico de dispersﾃ｣o para visualizaﾃｧﾃ｣o dos clusters
                        fig, ax = plt.subplots(figsize=(10, 6))
                        scatter = ax.scatter(
                            plot_data[:, x_component],
                            plot_data[:, y_component],
                            c=st.session_state.clustering_labels,
                            cmap='viridis',
                            alpha=0.7
                        )
                        ax.set_title(f'Visualizaﾃｧﾃ｣o 2D dos Clusters ({best_n_clusters_retrain} clusters)')
                        ax.set_xlabel(f'Componente {x_component+1}')
                        ax.set_ylabel(f'Componente {y_component+1}')
                        legend = ax.legend(*scatter.legend_elements(), title="Clusters")
                        ax.add_artist(legend)
                        st.pyplot(fig)
                        plt.clf()
            
                # Opﾃｧﾃ｣o para o utilizador escolher a aﾃｧﾃ｣o seguinte
                next_action = st.selectbox(
                    "Selecione a prﾃｳxima aﾃｧﾃ｣o:",
                    ["Re-Treinar o Modelo", "Finalizar"]
                )
            
                # Botﾃ｣o para confirmar a escolha do utilizador
                if st.button("Confirmar Escolha"):
                    if next_action == "Finalizar":
                        st.session_state.step = 'clustering_final_page'
                        st.rerun()
                    elif next_action == "Re-Treinar o Modelo":
                        st.session_state.retrain_mode = True

            # Re-Treinar o Modelo (sﾃｳ aparece se o utilizador escolher esta opﾃｧﾃ｣o)
            if st.session_state.get("retrain_mode", False):
                st.write("### Re-Treino do Modelo")
                
                # Escolha do mﾃｩtodo para determinar o nﾃｺmero de clusters no re-treino
                retrain_method = st.radio(
                    "Escolha a Abordagem para Determinar o Nﾃｺmero de Clusters no novo treino:",
                    ["Automﾃ｡tico", "Manual"]
                )
            
                if retrain_method == "Manual":
                    # Permitir ao utilizador escolher manualmente o nﾃｺmero de clusters
                    st.session_state.num_clusters = st.slider(
                        "Selecione o nﾃｺmero de clusters para o re-treino",
                        min_value=2,
                        max_value=20,
                        value=st.session_state.num_clusters if "num_clusters" in st.session_state else 3
                    )
                    best_n_clusters_retrain = st.session_state.num_clusters
            
                elif retrain_method == "Automﾃ｡tico":
                    # Determinar o melhor nﾃｺmero de clusters com base no Silhouette Score
                    if silhouette_scores and any(score > 0 for score in silhouette_scores):
                        best_n_clusters_retrain = range(num_clusters_range[0], num_clusters_range[1] + 1)[np.argmax(silhouette_scores)]
                    else:
                        # Caso a determinaﾃｧﾃ｣o automﾃ｡tica falhe, exibir erro e atribuir um valor padrﾃ｣o
                        st.error("Nﾃ｣o foi possﾃｭvel determinar automaticamente o nﾃｺmero de clusters. Por favor, selecione manualmente.")
                        best_n_clusters_retrain = 3  # Valor padrﾃ｣o
            
                # Botﾃ｣o para executar o re-treino do modelo
                if st.button("Treinar Novamente"):
                    # Selecionar o modelo previamente escolhido pelo utilizador
                    model = st.session_state.models[st.session_state.selected_model_name]
                    
                    # Configurar o modelo com o novo nﾃｺmero de clusters
                    if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                        model.set_params(n_clusters=best_n_clusters_retrain, linkage='ward')
                    else:
                        model.set_params(n_clusters=best_n_clusters_retrain, n_init=5, max_iter=300)
            
                    # Treinar o modelo com uma barra de progresso para indicar o progresso ao utilizador
                    with st.spinner(f"Realizando re-treino com {best_n_clusters_retrain} clusters..."):
                        model.fit(st.session_state.training_data)
            
                    # Calcular mﾃｩtricas de avaliaﾃｧﾃ｣o do clustering apﾃｳs o re-treino
                    st.session_state.retrain_metrics = {
                        "Nﾃｺmero de Clusters": best_n_clusters_retrain,
                        "Silhouette Score": silhouette_score(st.session_state.training_data, model.labels_),
                        "Davies-Bouldin Index": davies_bouldin_score(st.session_state.training_data, model.labels_),
                        "Calinski-Harabasz Score": calinski_harabasz_score(st.session_state.training_data, model.labels_)
                    }
            
                    # Atualizar rﾃｳtulos dos clusters no estado da sessﾃ｣o
                    st.session_state.retrain_labels = model.labels_
                    st.session_state.retrain_completed = True
            
                    # Exibir mensagem de sucesso com informaﾃｧﾃｵes relevantes
                    if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                        st.success(f"Re-treino concluﾃｭdo com sucesso com {best_n_clusters_retrain} clusters e {st.session_state.pca_n_components} componentes PCA!")
                    else:
                        st.success(f"Re-treino concluﾃｭdo com sucesso com {best_n_clusters_retrain} clusters!")
            
                # Exibir mﾃｩtricas do re-treino apﾃｳs a execuﾃｧﾃ｣o
                if st.session_state.get("retrain_completed", False):
                    st.write("### Mﾃｩtricas do Re-Treino")
                    st.table(fix_dataframe_types(pd.DataFrame([st.session_state.retrain_metrics])))
            
                    # Recuperar o modelo atualizado do estado da sessﾃ｣o
                    current_model = st.session_state.models[st.session_state.selected_model_name]
            
                    # Verificar centroides para KMeans e exibi-los
                    if st.session_state.selected_model_name == "KMeans":
                        if hasattr(current_model, 'cluster_centers_'):
                            st.write("#### Centroides dos Clusters")
                            centroids = current_model.cluster_centers_
                            if centroids.shape[1] > 10:
                                st.write(f"(Mostrando apenas as primeiras 10 dimensﾃｵes de {centroids.shape[1]})")
                                centroids_df = pd.DataFrame(centroids[:, :10])
                            else:
                                centroids_df = pd.DataFrame(centroids)
                            
                            st.dataframe(fix_dataframe_types(centroids_df))
            
                    # Visualizaﾃｧﾃ｣o dos clusters apﾃｳs o re-treino
                    if 'retrain_labels' in st.session_state:
                        st.write("### Visualizaﾃｧﾃ｣o dos Clusters do Re-Treino")
            
                        # Preparar dados para visualizaﾃｧﾃ｣o 2D
                        if st.session_state.selected_model_name == "Clustering Hierﾃ｡rquico":
                            # Para Clustering Hierﾃ｡rquico, utilizar os dados reduzidos pelo PCA
                            plot_data = st.session_state.X_pca
                        else:
                            # Para K-Means, aplicar PCA para reduzir os dados e facilitar a visualizaﾃｧﾃ｣o
                            X_for_viz = X_scaled  # Utilizar os dados originais normalizados
                            if X_for_viz.shape[1] > 3:
                                pca_viz = PCA(n_components=3)
                                plot_data = pca_viz.fit_transform(X_for_viz)
                                st.write("(Dados reduzidos via PCA para visualizaﾃｧﾃ｣o)")
                            else:
                                plot_data = X_for_viz
            
                        # Determinar o nﾃｺmero total de componentes disponﾃｭveis para visualizaﾃｧﾃ｣o
                        total_components = plot_data.shape[1]
            
                        # Permitir ao utilizador escolher os componentes para visualizaﾃｧﾃ｣o
                        st.write("### Escolha os Componentes para Visualizaﾃｧﾃ｣o")
                        col1, col2 = st.columns(2)
            
                        with col1:
                            x_component = st.selectbox(
                                "Componente para o Eixo X", 
                                list(range(total_components)), 
                                index=0,
                                format_func=lambda x: f"Componente {x+1}",
                                key="retrain_x_component"  # Chave ﾃｺnica para evitar conflitos no estado da sessﾃ｣o
                            )
            
                        with col2:
                            y_component = st.selectbox(
                                "Componente para o Eixo Y", 
                                list(range(total_components)), 
                                index=1 if total_components > 1 else 0,
                                format_func=lambda x: f"Componente {x+1}",
                                key="retrain_y_component"  # Chave ﾃｺnica para evitar conflitos no estado da sessﾃ｣o
                            )
            
                        # Garantir que os componentes escolhidos sﾃ｣o diferentes antes da visualizaﾃｧﾃ｣o
                        if x_component == y_component:
                            st.warning("Por favor, selecione componentes diferentes para X e Y.")
                        else:
                            # Criar grﾃ｡fico de dispersﾃ｣o dos clusters re-treinados
                            fig, ax = plt.subplots(figsize=(10, 6))
                            scatter = ax.scatter(
                                plot_data[:, x_component], 
                                plot_data[:, y_component], 
                                c=st.session_state.retrain_labels, 
                                cmap='viridis', 
                                alpha=0.7
                            )
                            ax.set_title(f'Visualizaﾃｧﾃ｣o 2D dos Clusters do Re-Treino ({best_n_clusters_retrain} clusters)')
                            ax.set_xlabel(f'Componente {x_component+1}')
                            ax.set_ylabel(f'Componente {y_component+1}')
                            legend = ax.legend(*scatter.legend_elements(), title="Clusters")
                            ax.add_artist(legend)
                            st.pyplot(fig)
                            plt.clf()
            
                # Finalizar o processo apﾃｳs o re-treino bem-sucedido
                if st.session_state.get("retrain_completed", False):
                    st.write("## Concluir o Processo de Clustering")
                    if st.button("Seguir para o Relatﾃｳrio"):
                        st.session_state.step = 'clustering_final_page'
                        st.rerun()

    # 3. Seleﾃｧﾃ｣o da Coluna Alvo
    from sklearn.preprocessing import LabelEncoder
    import pandas as pd
    
    # Inicializar variﾃ｡veis de estado no session_state se nﾃ｣o existirem
    if 'bins_confirmed' not in st.session_state:
        st.session_state['bins_confirmed'] = False  # Confirmaﾃｧﾃ｣o da escolha dos bins
    if 'bins_value' not in st.session_state:
        st.session_state['bins_value'] = 3  # Definir um valor padrﾃ｣o para os bins
    
    # **Filtrar colunas disponﾃｭveis para seleﾃｧﾃ｣o da variﾃ｡vel alvo, dependendo do tipo de modelo**
    if st.session_state.model_type == "Classificaﾃｧﾃ｣o":
        # Para modelos de classificaﾃｧﾃ｣o: considerar colunas categﾃｳricas (object) e colunas numﾃｩricas com poucas categorias
        valid_columns = [col for col in columns if data[col].dtype in ['object', 'int64'] or data[col].nunique() <= 10]
    else:
        # Para modelos de regressﾃ｣o: considerar apenas colunas numﾃｩricas contﾃｭnuas (float64 e int64) com muitas categorias
        valid_columns = [col for col in columns if data[col].dtype in ['float64', 'int64'] and data[col].nunique() > 10]
    
    # **Seleﾃｧﾃ｣o da Coluna Alvo**
    # Apenas necessﾃ｡rio para modelos de Classificaﾃｧﾃ｣o e Regressﾃ｣o (nﾃ｣o aplicﾃ｡vel a Clustering)
    if st.session_state.model_type != "Clustering" and st.session_state.selected_model_name and not st.session_state.target_column_confirmed:
        st.write("### Escolha a Coluna Alvo")
        
        # Criar um menu suspenso para o utilizador selecionar a coluna alvo
        target_column = st.selectbox(
            "Selecione a coluna alvo",
            options=valid_columns,  # Exibir apenas as colunas vﾃ｡lidas
            key='target_column_selectbox'
        )
    
        # **Botﾃ｣o para confirmar a seleﾃｧﾃ｣o da coluna alvo**
        if st.button("Confirmar Coluna Alvo"):
            if target_column in columns:  # Verificar se a coluna selecionada estﾃ｡ nos dados
                st.session_state.target_column = target_column
                st.session_state.target_column_confirmed = True  # Confirmar a seleﾃｧﾃ｣o
                st.session_state.validation_method = None  # Resetar mﾃｩtodo de validaﾃｧﾃ｣o
                st.session_state.validation_confirmed = False  # Resetar confirmaﾃｧﾃ｣o de validaﾃｧﾃ｣o
    
                # Armazenar os valores da variﾃ｡vel alvo
                y = data[st.session_state.target_column]
    
                # **Verificar o tipo de modelo**
                model_type = st.session_state.model_type
    
                # **Se o modelo for de Classificaﾃｧﾃ｣o**
                if model_type == "Classificaﾃｧﾃ｣o":
                    # Utilizar LabelEncoder para transformar colunas categﾃｳricas em valores numﾃｩricos
                    le = LabelEncoder()
                    y_encoded = le.fit_transform(y)
                    st.session_state['target_column_encoded'] = y_encoded
                    st.success("Coluna categﾃｳrica detectada e codificada com LabelEncoder.")
    
                # **Se o modelo for de Regressﾃ｣o**
                elif model_type == "Regressﾃ｣o":
                    if y.dtype in ['float64', 'int64']:  # Verificar se a variﾃ｡vel ﾃｩ contﾃｭnua
                        st.session_state['target_column_encoded'] = y  # Manter os valores originais
                        st.success("Coluna contﾃｭnua detectada e pronta para regressﾃ｣o.")
                    else:
                        # Se a coluna nﾃ｣o for contﾃｭnua, exibir um erro e interromper o processo
                        st.error("Modelos de regressﾃ｣o requerem uma coluna contﾃｭnua como alvo.")
                        st.stop()  # Parar a execuﾃｧﾃ｣o para evitar erros futuros
    
    # **Exibir a Coluna Alvo Confirmada**
    if st.session_state.model_type != "Clustering" and st.session_state.target_column_confirmed:
        st.write(f"### Coluna Alvo Confirmada: {st.session_state.target_column}")
        st.write(f"Tipo: {st.session_state.get('target_column_type', 'Nﾃ｣o definido')}")  # Mostrar tipo da variﾃ｡vel alvo

        # 4. GridSearch - Ajuste de Hiperparﾃ｢metros
        # **Funﾃｧﾃ｣o para limpar parﾃ｢metros invﾃ｡lidos no session_state**
        def limpar_parametros_invalidos():
            """Remove parﾃ｢metros invﾃ｡lidos do session_state."""
            if 'manual_params' in st.session_state:
                if 'gamma' in st.session_state['manual_params']:
                    del st.session_state['manual_params']['gamma']  # Remove 'gamma' se presente
        
        # **Definir modelos que nﾃ｣o possuem hiperparﾃ｢metros ajustﾃ｡veis**
        NO_HYPERPARAM_MODELS = ["Regressﾃ｣o Linear Simples (RLS)"]
        
        # **Verificar se o modelo foi selecionado e se o GridSearch ainda nﾃ｣o foi confirmado**
        if st.session_state.selected_model_name and not st.session_state.grid_search_confirmed:
        
            # **Caso o modelo nﾃ｣o tenha hiperparﾃ｢metros ajustﾃ｡veis**
            if st.session_state.selected_model_name in NO_HYPERPARAM_MODELS:
                st.write(f"O modelo {st.session_state.selected_model_name} nﾃ｣o possui hiperparﾃ｢metros ajustﾃ｡veis.")
                st.session_state.use_grid_search = "Nﾃ｣o"
                param_grid = {}  # Nenhum parﾃ｢metro para ajustar
                st.session_state.grid_search_confirmed = True
        
            else:
                # **Perguntar ao utilizador se quer usar GridSearch**
                use_grid_search = st.radio(
                    "Usar GridSearch?", 
                    ["Sim", "Nﾃ｣o"], 
                    key='grid_search_radio', 
                    index=0 if st.session_state.get('use_grid_search', "Sim") == "Sim" else 1
                )
                st.session_state.use_grid_search = use_grid_search
        
                # **Inicializar param_grid como vazio**
                param_grid = {}  # Evita erros de variﾃ｡vel nﾃ｣o definida
        
                if use_grid_search == "Sim":
                    # **Perguntar como os parﾃ｢metros devem ser escolhidos**
                    param_choice = st.radio(
                        "Escolher os parﾃ｢metros de GridSearch?",
                        ["Utilizar os melhores parﾃ｢metros", "Escolher manualmente os parﾃ｢metros de GridSearch"],
                        key='param_choice_radio',
                        index=0 if st.session_state.get('param_choice', "Utilizar os melhores parﾃ｢metros") == "Utilizar os melhores parﾃ｢metros" else 1
                    )
                    st.session_state.param_choice = param_choice
        
                    # **Inicializar parﾃ｢metros manuais**
                    if 'manual_params' not in st.session_state:
                        st.session_state.manual_params = {}
        
                    manual_params = st.session_state.manual_params
        
                    # **Configuraﾃｧﾃ｣o manual dos parﾃ｢metros**
                    if param_choice == "Escolher manualmente os parﾃ｢metros de GridSearch":
                        # **Recuperar o modelo selecionado**
                        model_key = st.session_state.selected_model_name
        
                        # **Obter os parﾃ｢metros padrﾃ｣o para o modelo selecionado**
                        param_grid = get_default_param_grid(model_key)
        
                        # **Se nﾃ｣o houver parﾃ｢metros padrﾃ｣o, informar o utilizador**
                        if not param_grid:
                            st.warning(f"Parﾃ｢metros padrﾃ｣o nﾃ｣o definidos para o modelo {model_key}.")
                            param_grid = {}
        
                        # **Exibir os parﾃ｢metros para o utilizador ajustar manualmente**
                        manual_params = {}
                        for param, values in param_grid.items():
                            # **Tratar parﾃ｢metros especﾃｭficos como 'kernel'**
                            if param == "kernel":
                                manual_params[param] = st.selectbox(
                                    f"Escolha o valor para '{param}':",
                                    values,  # Lista de valores permitidos
                                    index=0,  # Primeiro valor como padrﾃ｣o
                                    key=f"{model_key}_{param}"
                                )
        
                            # **Mostrar 'gamma' apenas se o kernel for 'rbf'**
                            elif param == "gamma":
                                if "kernel" in manual_params and manual_params["kernel"] == "rbf":
                                    manual_params[param] = st.selectbox(
                                        f"Escolha o valor para '{param}':",
                                        values,  # Lista de valores permitidos
                                        index=0,  # Primeiro valor como padrﾃ｣o
                                        key=f"{model_key}_{param}"
                                    )
                                else:
                                    # **Remover 'gamma' se nﾃ｣o for necessﾃ｡rio**
                                    manual_params.pop(param, None)
                                    if 'manual_params' in st.session_state and param in st.session_state['manual_params']:
                                        del st.session_state['manual_params'][param]
        
                            # **Tratar parﾃ｢metros numﾃｩricos (ex.: C, epsilon)**
                            elif isinstance(values[0], (int, float)):
                                st.write(f"Parﾃ｢metro: **{param}** | Intervalo disponﾃｭvel: [{min(values)}, {max(values)}]")
        
                                param_type = float if any(isinstance(v, float) for v in values) else int
        
                                manual_params[param] = st.number_input(
                                    f"Escolha o valor para '{param}':",
                                    min_value=float(min(values)) if param_type == float else int(min(values)),
                                    max_value=float(max(values)) if param_type == float else int(max(values)),
                                    value=float(values[0]) if param_type == float else int(values[0]),
                                    step=0.1 if param_type == float else 1,  
                                    key=f"{model_key}_{param}"
                                )
        
                            # **Tratar `max_depth` separadamente como um selectbox**
                            elif param == "max_depth":
                                st.write(f"Parﾃ｢metro: **{param}** | Valores disponﾃｭveis: {values}")
                                manual_params[param] = st.selectbox(
                                    f"Escolha o valor para '{param}':",
                                    values,
                                    index=0,  # Primeiro valor como padrﾃ｣o
                                    key=f"{model_key}_{param}"
                                )
        
                            # **Tratar parﾃ｢metros categﾃｳricos (ex.: 'weights')**
                            elif isinstance(values[0], str):
                                st.write(f"Parﾃ｢metro: **{param}** | Valores disponﾃｭveis: {values}")
                                manual_params[param] = st.selectbox(
                                    f"Escolha o valor para '{param}':",
                                    values,  # Lista de valores permitidos
                                    index=0,  # Primeiro valor como padrﾃ｣o
                                    key=f"{model_key}_{param}"
                                )
        
                        # **Salvar os parﾃ｢metros manuais no estado global**
                        st.session_state['manual_params'] = manual_params
                        st.write("Parﾃ｢metros manuais salvos:", manual_params)
        
                # **Botﾃ｣o para confirmar configuraﾃｧﾃｵes do GridSearch**
                if st.button("Confirmar GridSearch"):
                    st.session_state.grid_search_confirmed = True
                    st.success("Configuraﾃｧﾃ｣o do GridSearch confirmada!")
        
                    # **Se o utilizador escolheu "Utilizar os melhores parﾃ｢metros", armazenar um dicionﾃ｡rio vazio**
                    if st.session_state.use_grid_search == "Sim" and st.session_state.param_choice == "Utilizar os melhores parﾃ｢metros":
                        st.session_state['manual_params'] = {}
                        st.session_state['best_params_str'] = "{}"
                        st.session_state['best_params'] = param_grid
                        st.session_state['best_params_selected'] = param_grid
                                
        # 5. Escolha do Mﾃｩtodo de Validaﾃｧﾃ｣o
        
        # O mﾃｩtodo de validaﾃｧﾃ｣o sﾃｳ aparece apﾃｳs a confirmaﾃｧﾃ｣o do GridSearch
        if st.session_state.grid_search_confirmed and st.session_state.selected_model_name and not st.session_state.validation_method:
            
            st.write("### Escolha o Mﾃｩtodo de Validaﾃｧﾃ｣o")
            
            # Lista dos mﾃｩtodos disponﾃｭveis
            validation_methods = ["Divisﾃ｣o em Treino e Teste", "Holdout"]
        
            # Escolha do mﾃｩtodo pelo utilizador
            validation_method = st.radio(
                "Selecione o mﾃｩtodo de validaﾃｧﾃ｣o",
                validation_methods,
                key='validation_method_radio'
            )
        
            # Configuraﾃｧﾃｵes especﾃｭficas para cada mﾃｩtodo de validaﾃｧﾃ｣o
            if validation_method == "Divisﾃ｣o em Treino e Teste":
                # O utilizador escolhe a proporﾃｧﾃ｣o do conjunto de teste
                test_size = st.slider(
                    "Proporﾃｧﾃ｣o do conjunto de teste",
                    min_value=0.1, max_value=0.9, value=0.3, step=0.1
                )
                st.session_state.test_size = test_size
        
            elif validation_method == "Holdout":
                # O utilizador escolhe a proporﾃｧﾃ｣o do conjunto de treino
                train_size = st.slider(
                    "Proporﾃｧﾃ｣o do conjunto de treino",
                    min_value=0.1, max_value=0.9, value=0.7, step=0.1
                )
                st.session_state.train_size = train_size
        
            # **Botﾃ｣o para confirmar a escolha do mﾃｩtodo de validaﾃｧﾃ｣o**
            if st.button("Confirmar Validaﾃｧﾃ｣o"):
                # Guardar o mﾃｩtodo de validaﾃｧﾃ｣o escolhido
                st.session_state.validation_method = validation_method  
        
                # **Preparaﾃｧﾃ｣o dos dados**
                # Remover a coluna alvo do conjunto de caracterﾃｭsticas
                X = data.drop(columns=[st.session_state.target_column])
                y = data[st.session_state.target_column]
        
                # **Conversﾃ｣o de variﾃ｡veis categﾃｳricas para numﾃｩricas**
                X = pd.get_dummies(X)  # Criaﾃｧﾃ｣o de variﾃ｡veis dummy para colunas categﾃｳricas
        
                try:
                    # **Divisﾃ｣o dos dados com base no mﾃｩtodo escolhido**
                    if st.session_state.validation_method == "Divisﾃ｣o em Treino e Teste":
                        # Divisﾃ｣o clﾃ｡ssica em treino e teste
                        st.session_state.X_train, st.session_state.X_test, st.session_state.y_train, st.session_state.y_test = train_test_split(
                            X, y, test_size=st.session_state.test_size, random_state=42
                        )
                        st.success("Divisﾃ｣o dos dados realizada com sucesso!")
        
                    elif st.session_state.validation_method == "Holdout":
                        # Outro mﾃｩtodo de divisﾃ｣o treino-teste, baseado na proporﾃｧﾃ｣o de treino
                        st.session_state.X_train, st.session_state.X_test, st.session_state.y_train, st.session_state.y_test = train_test_split(
                            X, y, train_size=st.session_state.train_size, random_state=42
                        )
                        st.success("Divisﾃ｣o dos dados realizada com sucesso!")
        
                    # **Confirma que a validaﾃｧﾃ｣o foi concluﾃｭda**
                    st.session_state.validation_confirmed = True
        
                except Exception as e:
                    st.error(f"Erro na divisﾃ｣o dos dados: {e}")
        
                # **Exibir o mﾃｩtodo de validaﾃｧﾃ｣o confirmado**
                if st.session_state.validation_confirmed:
                    st.write(f"**Mﾃｩtodo de Validaﾃｧﾃ｣o Confirmado:** {st.session_state.validation_method}")

        # 6. Treino do Modelo
        
        # **Exibir o botﾃ｣o para treinar o modelo apenas apﾃｳs a validaﾃｧﾃ｣o ser confirmada**
        if st.session_state.validation_confirmed:
            if st.button("Treinar o Modelo"):
                st.session_state.validation_confirmed = False  # Resetar a validaﾃｧﾃ｣o apﾃｳs o treino
                st.success("Treino iniciado com sucesso!")
        
                # **Recuperar o modelo selecionado**
                model_name = st.session_state.selected_model_name
                model = st.session_state.models.get(st.session_state.selected_model_name)
        
                # **Verificar se o modelo foi encontrado**
                if model is None:
                    st.error(f"Modelo {st.session_state.selected_model_name} nﾃ｣o encontrado.")
                    return  # Interrompe a execuﾃｧﾃ｣o caso o modelo nﾃ｣o seja encontrado
        
                # **Inicializar 'treinos_realizados' no estado global caso ainda nﾃ｣o exista**
                if 'treinos_realizados' not in st.session_state:
                    st.session_state['treinos_realizados'] = []
        
                # **Recolher as informaﾃｧﾃｵes necessﾃ｡rias do estado global**
                target_column = st.session_state.target_column
                validation_method = st.session_state.validation_method
                use_grid_search = st.session_state.use_grid_search
                manual_params = st.session_state.manual_params
                X_train = st.session_state.X_train
                y_train = st.session_state.y_train
                X_test = st.session_state.X_test
                y_test = st.session_state.y_test
        
                # **Remover parﾃ｢metros invﾃ｡lidos antes do treino**
                if 'manual_params' in st.session_state:
                    if manual_params.get('kernel') == 'linear' and 'gamma' in manual_params:
                        del manual_params['gamma']  # Remover parﾃ｢metro invﾃ｡lido localmente
                    if 'gamma' in st.session_state['manual_params']:
                        del st.session_state['manual_params']['gamma']  # Remover do estado global
        
                # **Tratar valores ausentes antes do treino**
                from sklearn.impute import SimpleImputer
                imputer = SimpleImputer(strategy="mean")  # Estratﾃｩgia de imputaﾃｧﾃ｣o ("mean" pode ser alterado para "median")
                X_train = imputer.fit_transform(X_train)  # Aplicar imputaﾃｧﾃ｣o no conjunto de treino
                X_test = imputer.transform(X_test)        # Aplicar imputaﾃｧﾃ｣o no conjunto de teste
        
                # **Exibir resumo das escolhas feitas pelo utilizador**
                st.write("### Resumo das Escolhas Feitas:")
                st.write(f"**Modelo Selecionado**: {model_name}")
                st.write(f"**Coluna Alvo**: {target_column}")
                st.write(f"**Mﾃｩtodo de Validaﾃｧﾃ｣o**: {validation_method}")
                st.write(f"**GridSearch Ativado?** {use_grid_search}")  # Informaﾃｧﾃ｣o adicional para depuraﾃｧﾃ｣o
        
                # **Iniciar o treino do modelo**
                param_grid = get_default_param_grid(model_name) if use_grid_search == "Sim" else {}
                resultado = train_and_evaluate(
                    model, param_grid, X_train, y_train, X_test, y_test, use_grid_search, manual_params
                )
        
                # **Guardar os melhores parﾃ｢metros no estado global apﾃｳs o treino**
                if 'Best Parameters' in resultado:
                    st.session_state['best_params'] = resultado['Best Parameters']
                    st.session_state['best_params_selected'] = resultado['Best Parameters']
                    st.session_state['best_params_str'] = json.dumps(st.session_state['best_params'], indent=2)
                    st.write("Parﾃ｢metros salvos no estado global:", st.session_state['best_params'])
                else:
                    st.warning("Nenhum parﾃ｢metro encontrado para salvar.")
        
                # **Guardar os resultados apﾃｳs o primeiro treino**
                if resultado:
                    st.session_state['resultado_sem_selecao'] = resultado  # Salvar resultado sem seleﾃｧﾃ｣o de features
                    st.session_state['treinos_realizados'].append(resultado)
        
                    # **Criar um DataFrame com as mﾃｩtricas do modelo treinado**
                    df_resultado = pd.DataFrame([resultado])
        
                    # **Corrigir os tipos de dados antes de exibir**
                    df_corrigido = fix_dataframe_types(df_resultado)
        
                    # **Exibir mﾃｩtricas do modelo**
                    st.write("### Mﾃｩtricas do Modelo Treinado:")
                    formatted_display = df_corrigido.style.format(
                        {col: "{:.4f}" for col in df_corrigido.select_dtypes(include=['float', 'float64']).columns}
                    )
                    st.dataframe(formatted_display)
        
                    # **Gerar grﾃ｡fico com as mﾃｩtricas do modelo**
                    plot_metrics(df_corrigido)
        
                    # **Marcar o treino como concluﾃｭdo**
                    st.session_state['treino_concluido'] = True
                else:
                    st.error("O treino do modelo falhou.")
        
        # **Avanﾃｧar para Seleﾃｧﾃ｣o de Features APENAS apﾃｳs a exibiﾃｧﾃ｣o das mﾃｩtricas**
        if st.session_state.get('treino_concluido', False):
            st.write("### Avanﾃｧar para Seleﾃｧﾃ｣o de Features")
        
            # **Verificar se hﾃ｡ treinos realizados**
            if 'treinos_realizados' in st.session_state and st.session_state['treinos_realizados']:
                
                # **Identificar o melhor modelo com base na mﾃｩtrica apropriada**
                if st.session_state.model_type == "Classificaﾃｧﾃ｣o":
                    melhores_metricas = sorted(
                        st.session_state['treinos_realizados'], 
                        key=lambda x: x.get('Accuracy', 0),  # Ordenaﾃｧﾃ｣o pela mﾃｩtrica Accuracy
                        reverse=True
                    )[0]  # Seleciona o melhor modelo
                elif st.session_state.model_type == "Regressﾃ｣o":
                    melhores_metricas = sorted(
                        st.session_state['treinos_realizados'], 
                        key=lambda x: x.get('Rﾂｲ', 0),  # Ordenaﾃｧﾃ｣o pela mﾃｩtrica Rﾂｲ
                        reverse=True
                    )[0]  # Seleciona o melhor modelo
        
                # **Permitir ao utilizador escolher um modelo manualmente ou manter o melhor**
                model_options = [resultado['Modelo'] for resultado in st.session_state['treinos_realizados']]
                default_index = model_options.index(melhores_metricas['Modelo']) if melhores_metricas['Modelo'] in model_options else 0
        
                selected_model_temp = st.selectbox(
                    "Escolha um modelo para avanﾃｧar para a Seleﾃｧﾃ｣o de Features:",
                    options=model_options,
                    index=default_index
                )
        
                # **Botﾃ｣o para avanﾃｧar para a prﾃｳxima etapa**
                if st.button("Avanﾃｧar para Seleﾃｧﾃ｣o de Features"):
                    st.session_state.selected_model_name = selected_model_temp  # Atualiza o modelo selecionado
                    st.session_state.step = 'feature_selection'  # Atualiza a etapa do fluxo
                    st.session_state['treino_concluido'] = False  # Reseta o estado do treino
                    st.rerun()
            else:
                st.error("Nenhum modelo foi treinado. Execute o treino primeiro.")

# Funﾃｧﾃ｣o para treinar e avaliar os modelos de clustering
def train_clustering_model(model, X_data, model_name):
    """
    Treina um modelo de clustering (KMeans ou Clustering Hierﾃ｡rquico) e armazena os rﾃｳtulos dos clusters.

    Parﾃ｢metros:
    - model: Modelo de clustering selecionado (KMeans ou Clustering Hierﾃ｡rquico).
    - X_data: Dados de entrada para treino do modelo.
    - model_name: Nome do modelo a ser treinado.

    """
    try:
        # **Padronizar os dados para melhor desempenho dos modelos**
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_data)  # Normaliza os dados

        # **Treinar o modelo conforme o tipo de clustering selecionado**
        if model_name == "KMeans":
            model.set_params(n_clusters=st.session_state.kmeans_clusters)  # Definir o nﾃｺmero de clusters
            model.fit(X_scaled)  # Ajustar o modelo aos dados normalizados
            st.session_state['labels'] = model.labels_  # Armazenar os rﾃｳtulos dos clusters
        
        elif model_name == "Clustering Hierﾃ｡rquico":
            # Configurar todos os parﾃ｢metros necessﾃ｡rios para o modelo Hierﾃ｡rquico
            model.set_params(n_clusters=st.session_state.kmeans_clusters, linkage="ward")
            model.fit(X_scaled)  # Ajustar o modelo aos dados
            st.session_state['labels'] = model.labels_  # Armazenar os rﾃｳtulos dos clusters
        
        # **Exibir mensagem de sucesso**
        st.write(f"Clusterizaﾃｧﾃ｣o realizada com sucesso usando o modelo {model_name}!")

    except Exception as e:
        # **Capturar e exibir erros, caso ocorram**
        st.error(f"Erro ao treinar o modelo {model_name}: {str(e)}")


# Funﾃｧﾃ｣o para visualizaﾃｧﾃ｣o dos clusters usando PCA
def visualize_clusters(X_data):
    """
    Gera uma visualizaﾃｧﾃ｣o dos clusters em 2D usando PCA para reduzir a dimensionalidade dos dados.

    Parﾃ｢metros:
    - X_data: Dados de entrada que serﾃ｣o projetados em 2D para visualizaﾃｧﾃ｣o dos clusters.

    """
    if 'labels' in st.session_state:  # Verifica se os rﾃｳtulos dos clusters jﾃ｡ foram gerados
        # **Aplicar PCA para reduzir os dados para 2 dimensﾃｵes**
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_data)

        # **Criar grﾃ｡fico de dispersﾃ｣o dos clusters**
        plt.figure(figsize=(8, 6))
        plt.scatter(X_pca[:, 0], X_pca[:, 1], c=st.session_state['labels'], cmap='viridis', alpha=0.7)
        plt.xlabel('Componente Principal 1')
        plt.ylabel('Componente Principal 2')
        plt.title('Visualizaﾃｧﾃ｣o dos Clusters em 2D')

        # **Exibir o grﾃ｡fico no Streamlit**
        st.pyplot(plt.gcf())


from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR, SVC
from sklearn.linear_model import LinearRegression

def evaluate_regression_model(y_true, y_pred):
    """
    Avalia um modelo de regressﾃ｣o com base em trﾃｪs mﾃｩtricas principais:
    - Rﾂｲ: Coeficiente de determinaﾃｧﾃ｣o (quanto maior, melhor).
    - MAE: Erro absoluto mﾃｩdio (quanto menor, melhor).
    - MSE: Erro quadrﾃ｡tico mﾃｩdio (quanto menor, melhor).

    Parﾃ｢metros:
    - y_true: Valores reais da variﾃ｡vel de saﾃｭda.
    - y_pred: Valores previstos pelo modelo.

    Retorna:
    - Um dicionﾃ｡rio com as mﾃｩtricas calculadas.
    """
    r2 = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    return {"Rﾂｲ": r2, "MAE": mae, "MSE": mse}

def train_and_evaluate(model, param_grid, X_train, y_train, X_test, y_test, use_grid_search, manual_params=None):
    """
    Treina e avalia um modelo de Machine Learning utilizando GridSearch para otimizaﾃｧﾃ｣o dos hiperparﾃ｢metros.

    Parﾃ｢metros:
    - model: O modelo de Machine Learning a ser treinado (ex.: SVR, SVC, LinearRegression).
    - param_grid: Dicionﾃ｡rio contendo os parﾃ｢metros para GridSearchCV (se ativado).
    - X_train: Conjunto de treino para as variﾃ｡veis preditoras.
    - y_train: Conjunto de treino para a variﾃ｡vel alvo.
    - X_test: Conjunto de teste para as variﾃ｡veis preditoras.
    - y_test: Conjunto de teste para a variﾃ｡vel alvo.
    - use_grid_search: Booleano que indica se o GridSearchCV deve ser utilizado.
    - manual_params: Parﾃ｢metros fornecidos manualmente pelo utilizador (se houver).

    Retorna:
    - Um dicionﾃ｡rio com as mﾃｩtricas de avaliaﾃｧﾃ｣o do modelo treinado.
    """
    try:
        # **Verificar o tipo de modelo**
        is_svr = isinstance(model, SVR)  # Identifica se o modelo ﾃｩ uma regressﾃ｣o por vetores de suporte (SVR)
        is_svc = isinstance(model, SVC)  # Identifica se o modelo ﾃｩ um classificador SVC
        is_regression = is_svr or isinstance(model, LinearRegression)  # Identifica se o modelo ﾃｩ de regressﾃ｣o

        # **Escalonamento dos dados apenas para SVR (necessﾃ｡rio para otimizar o desempenho)**
        if is_svr:
            scaler = StandardScaler()
            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

        # **Configuraﾃｧﾃ｣o do GridSearchCV**
        if use_grid_search:
            cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Validaﾃｧﾃ｣o cruzada com 5 divisﾃｵes
            scoring = 'r2' if is_regression else 'accuracy'  # Define a mﾃｩtrica de avaliaﾃｧﾃ｣o conforme o tipo de problema
            
            # **Otimizaﾃｧﾃ｣o para modelos SVC (Classificaﾃｧﾃ｣o por Vetores de Suporte)**
            if is_svc:
                # Reduz o nﾃｺmero de parﾃ｢metros testados para acelerar o GridSearch
                simplified_grid = {
                    'C': [1],            # Apenas um valor para C
                    'kernel': ['rbf'],   # Apenas um tipo de kernel
                    'gamma': ['scale']   # Apenas uma configuraﾃｧﾃ｣o de gamma
                }
                
                # **Aplicar parﾃ｢metros manuais, se fornecidos pelo utilizador**
                if manual_params:
                    for param, value in manual_params.items():
                        simplified_grid[param] = [value]  # Garante que os valores sejam listas para GridSearch
                
                actual_grid = simplified_grid  # Usa o grid simplificado para SVC
                cv = KFold(n_splits=3, shuffle=True, random_state=42)  # Reduz o nﾃｺmero de folds para otimizar tempo
                
            else:
                actual_grid = param_grid  # Para outros modelos, usa o grid normal
                
                # **Se o utilizador forneceu parﾃ｢metros manuais, incorporﾃ｡-los ao grid**
                if manual_params:
                    actual_grid.update({k: [v] for k, v in manual_params.items()})

            # **Executar o GridSearch para encontrar os melhores hiperparﾃ｢metros**
            grid_search = GridSearchCV(
                model, 
                actual_grid,
                cv=cv,
                scoring=scoring,
                n_jobs=-1  # Usa todos os nﾃｺcleos disponﾃｭveis para acelerar a busca
            )
            grid_search.fit(X_train, y_train)
            
            best_model = grid_search.best_estimator_  # Melhor modelo encontrado pelo GridSearch
            best_params = grid_search.best_params_  # Melhores hiperparﾃ｢metros identificados

        else:
            # **Se nﾃ｣o usar GridSearch, aplicar os parﾃ｢metros manualmente (se fornecidos)**
            if manual_params:
                model.set_params(**manual_params)

            model.fit(X_train, y_train)  # Treinar o modelo com os dados de treino
            best_model = model  # O modelo treinado sem otimizaﾃｧﾃ｣o
            best_params = manual_params or {}  # Se nﾃ｣o houver parﾃ｢metros manuais, define um dicionﾃ｡rio vazio

        # **Fazer previsﾃｵes com o modelo treinado**
        y_pred = best_model.predict(X_test)

        # **Calcular mﾃｩtricas de desempenho**
        metrics = {
            "Modelo": model.__class__.__name__,
            **(
                # **Se for um modelo de regressﾃ｣o**
                {
                    "Rﾂｲ": r2_score(y_test, y_pred),
                    "MAE": mean_absolute_error(y_test, y_pred),
                    "MSE": mean_squared_error(y_test, y_pred)
                } if is_regression else 
                # **Se for um modelo de classificaﾃｧﾃ｣o**
                {
                    "Accuracy": accuracy_score(y_test, y_pred),
                    "Precision": precision_score(y_test, y_pred, average='weighted'),
                    "Recall": recall_score(y_test, y_pred, average='weighted'),
                    "F1-Score": f1_score(y_test, y_pred, average='weighted')
                }
            ),
            "Best Parameters": best_params
        }

        return metrics  # Retorna as mﾃｩtricas do modelo treinado

    except Exception as e:
        # **Capturar erros e exibir no Streamlit**
        st.error(f"Erro ao treinar o modelo: {str(e)}")
        return None

# **Funﾃｧﾃ｣o para selecionar o mﾃｩtodo de avaliaﾃｧﾃ｣o (Scoring)**
def select_scoring():
    """
    Permite ao utilizador selecionar a mﾃｩtrica de avaliaﾃｧﾃ｣o a ser usada na seleﾃｧﾃ｣o de features.
    A escolha ﾃｩ armazenada no session_state para ser utilizada posteriormente.

    - Se o utilizador jﾃ｡ tiver feito uma escolha anteriormente, ela serﾃ｡ mantida.
    - Se for a primeira vez, a mﾃｩtrica padrﾃ｣o serﾃ｡ "F1-Score".
    - A escolha pode ser guardada num ficheiro para persistﾃｪncia.

    Retorna:
    - Nenhum valor explﾃｭcito, mas a mﾃｩtrica escolhida ﾃｩ armazenada no session_state.
    """
    # Verifica se a mﾃｩtrica jﾃ｡ foi selecionada; se nﾃ｣o, define "F1-Score" como padrﾃ｣o
    if 'selected_scoring' not in st.session_state:
        st.session_state.selected_scoring = 'F1-Score'

    # Criar a caixa de seleﾃｧﾃ｣o para escolha da mﾃｩtrica
    st.session_state.selected_scoring = st.selectbox(
        "Escolha o scoring para a seleﾃｧﾃ｣o de features:",
        ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
        index=['Accuracy', 'Precision', 'Recall', 'F1-Score'].index(st.session_state.selected_scoring)
    )

    # Exibir a escolha feita
    st.write("Scoring selecionado:", st.session_state.selected_scoring)

    # Opﾃｧﾃ｣o para guardar a escolha num ficheiro
    if st.button("Salvar escolha"):
        with open("scoring_choice.txt", "w") as file:
            file.write(st.session_state.selected_scoring)  # Grava a escolha no ficheiro
        st.success("Escolha salva com sucesso!")


# **Funﾃｧﾃ｣o para remover features altamente correlacionadas**
def remove_highly_correlated_features(df, threshold=0.9):
    """
    Remove colunas do DataFrame que apresentam uma correlaﾃｧﾃ｣o superior a um determinado limiar.

    Parﾃ｢metros:
    - df (DataFrame): Conjunto de dados de entrada.
    - threshold (float): Limiar de correlaﾃｧﾃ｣o acima do qual as colunas serﾃ｣o removidas (padrﾃ｣o: 0.9).

    Retorna:
    - DataFrame sem as colunas altamente correlacionadas.
    """
    # **1. Calcular a matriz de correlaﾃｧﾃ｣o absoluta**
    corr_matrix = df.corr().abs()  # Calcula os coeficientes de correlaﾃｧﾃ｣o absolutos

    # **2. Criar uma matriz triangular superior**
    # Esta matriz exclui a diagonal principal e os valores abaixo dela, para evitar redundﾃ｢ncias
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

    # **3. Identificar as colunas a serem removidas**
    # Se qualquer valor na matriz for superior ao threshold, removemos a coluna correspondente
    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]

    # **4. Informar ao utilizador quais colunas foram removidas**
    if to_drop:
        st.info(f"Features removidas por alta correlaﾃｧﾃ｣o: {to_drop}")

    # **5. Retornar o DataFrame sem as colunas altamente correlacionadas**
    return df.drop(columns=to_drop)

# **Funﾃｧﾃ｣o para selecionar features importantes com RandomForest**
def select_important_features(X, y, threshold=0.01, model_type=None):
    """
    Seleciona as features mais relevantes utilizando RandomForest.

    Parﾃ｢metros:
    - X: Matriz de features (DataFrame).
    - y: Vetor alvo (sﾃｩrie de labels ou valores numﾃｩricos).
    - threshold: Limiar mﾃｭnimo de importﾃ｢ncia (padrﾃ｣o = 0.01).
    - model_type: Tipo de modelo ("Classificaﾃｧﾃ｣o" ou "Regressﾃ｣o").

    Retorna:
    - DataFrame contendo apenas as features selecionadas.
    """

    # **1. Definir o modelo conforme o tipo de problema**
    if model_type == "Classificaﾃｧﾃ｣o":
        model = RandomForestClassifier(n_estimators=100, random_state=42)
    elif model_type == "Regressﾃ｣o":
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    else:
        raise ValueError("O tipo de modelo deve ser 'Classificaﾃｧﾃ｣o' ou 'Regressﾃ｣o'.")

    # **2. Tratar valores ausentes utilizando SimpleImputer**
    imputer = SimpleImputer(strategy='mean')  # Substitui valores ausentes pela mﾃｩdia
    X_imputed = imputer.fit_transform(X)

    # **3. Treinar o modelo RandomForest**
    model.fit(X_imputed, y)

    # **4. Obter a importﾃ｢ncia de cada feature**
    importances = model.feature_importances_

    # **5. Criar um DataFrame com as importﾃ｢ncias ordenadas**
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': importances
    }).sort_values('importance', ascending=False)

    # **6. Selecionar apenas as features que ultrapassam o threshold**
    important_features = feature_importance[feature_importance['importance'] > threshold]['feature']

    # **7. Exibir as features selecionadas ao utilizador**
    st.info(f"Features selecionadas: {list(important_features)}")

    # **8. Retornar o DataFrame contendo apenas as features selecionadas**
    return X[important_features]


# **Funﾃｧﾃ｣o principal para seleﾃｧﾃ｣o de features**
def feature_selection():
    """
    Interface para a seleﾃｧﾃ｣o de features em modelos de Machine Learning.
    
    - Permite ao utilizador escolher a mﾃｩtrica de scoring.
    - Dﾃ｡ a opﾃｧﾃ｣o de selecionar as features automaticamente ou manualmente.
    - Mostra um DataFrame com as importﾃ｢ncias das features.
    """

    st.header("Seleﾃｧﾃ｣o de Features")

    # Inicializar o estado de seleﾃｧﾃ｣o de features
    if 'feature_selection_done' not in st.session_state:
        st.session_state.feature_selection_done = False

    # Obter o tipo de modelo armazenado na sessﾃ｣o (Classificaﾃｧﾃ｣o ou Regressﾃ｣o)
    model_type = st.session_state.get('model_type', 'Classificaﾃｧﾃ｣o')

    # Definir opﾃｧﾃｵes de scoring disponﾃｭveis conforme o tipo de modelo
    scoring_options = {
        "Classificaﾃｧﾃ｣o": ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
        "Regressﾃ｣o": ['Rﾂｲ', 'MAE', 'MSE']
    }

    # **1. Escolha da mﾃｩtrica de avaliaﾃｧﾃ｣o**
    selected_scoring = st.selectbox(
        "Escolha a mﾃｩtrica de scoring:",
        scoring_options.get(model_type, [])  # Exibe opﾃｧﾃｵes conforme o tipo de modelo
    )

    # **Confirmar a escolha da mﾃｩtrica**
    if st.button("Confirmar Scoring"):
        st.session_state.selected_scoring = selected_scoring
        st.session_state.scoring_confirmed = True
        st.success(f"Mﾃｩtrica de scoring {selected_scoring} confirmada!")

    # **2. Escolha do mﾃｩtodo de seleﾃｧﾃ｣o de features**
    if st.session_state.scoring_confirmed:
        method_selection = st.radio(
            "Escolha o mﾃｩtodo de seleﾃｧﾃ｣o de features:",
            ["Automﾃ｡tico", "Manual"]
        )

        # **Confirmar mﾃｩtodo escolhido**
        if st.button("Confirmar Mﾃｩtodo"):
            st.session_state.method_selection = method_selection
            st.success(f"Mﾃｩtodo {method_selection} confirmado!")

        # Obter os dados de treino e teste da sessﾃ｣o
        X_train, X_test, y_train, y_test = (
            st.session_state.X_train, 
            st.session_state.X_test, 
            st.session_state.y_train, 
            st.session_state.y_test
        )

        # **3. Seleﾃｧﾃ｣o Automﾃ｡tica de Features**
        if method_selection == "Automﾃ｡tico":
            feature_selector = (
                RandomForestClassifier(n_estimators=100, random_state=42)
                if model_type == "Classificaﾃｧﾃ｣o"
                else RandomForestRegressor(n_estimators=100, random_state=42)
            )

            # Treinar o modelo para obter importﾃ｢ncias
            feature_selector.fit(X_train, y_train)

            # Criar DataFrame com as importﾃ｢ncias ordenadas
            feature_importances = pd.DataFrame({
                'feature': X_train.columns,
                'importance': feature_selector.feature_importances_
            }).sort_values('importance', ascending=False)

            # Exibir o DataFrame com as importﾃ｢ncias das features
            st.dataframe(feature_importances)

            # **Selecionar as features mais importantes com threshold > 0.01**
            selected_features = feature_importances[feature_importances['importance'] > 0.01]['feature'].tolist()

        # **4. Seleﾃｧﾃ｣o Manual de Features**
        else:
            feature_selector = (
                RandomForestClassifier(n_estimators=100, random_state=42)
                if model_type == "Classificaﾃｧﾃ｣o"
                else RandomForestRegressor(n_estimators=100, random_state=42)
            )

            # Treinar o modelo para obter importﾃ｢ncias
            feature_selector.fit(X_train, y_train)

            # Criar DataFrame com as importﾃ｢ncias ordenadas
            feature_importances = pd.DataFrame({
                'feature': X_train.columns,
                'importance': feature_selector.feature_importances_
            }).sort_values('importance', ascending=False)

            # Exibir o DataFrame com as importﾃ｢ncias das features
            st.dataframe(feature_importances)

            # **Permitir ao utilizador escolher quantas features deseja manter**
            num_features = st.slider(
                "Nﾃｺmero de Features a Selecionar",
                1, X_train.shape[1], min(5, X_train.shape[1])
            )

            # Selecionar as top-N features com base na escolha do utilizador
            selected_features = feature_importances['feature'].head(num_features).tolist()

        # **5. Atualizar o estado global com as features selecionadas**
        st.session_state.X_train_selected = X_train[selected_features]
        st.session_state.X_test_selected = X_test[selected_features]
        st.session_state.selected_features = selected_features
        st.session_state.feature_selection_done = True

        # **6. Botﾃ｣o para treinar o modelo com as features selecionadas**
        if st.button("Treinar Modelo com Features Selecionadas"):
            st.session_state.step = 'train_with_selected_features'
            st.rerun()

# **Funﾃｧﾃ｣o para treinar o modelo com as features selecionadas**
def train_with_selected_features_page():
    st.title("Treino do Modelo com Features Selecionadas")
    
    # **Mapeamento de modelos para evitar inconsistﾃｪncias nos nomes**
    model_name_map = {
        "SVC": "Support Vector Classification (SVC)",
        "KNeighborsClassifier": "K-Nearest Neighbors (KNN)",
        "RandomForestClassifier": "Random Forest",
        "LinearRegression": "Regressﾃ｣o Linear Simples (RLS)",
        "SVR": "Regressﾃ｣o por Vetores de Suporte (SVR)",
        "Support Vector Classification (SVC)": "SVC",
        "K-Nearest Neighbors (KNN)": "KNeighborsClassifier", 
        "Random Forest": "RandomForestClassifier",
        "Regressﾃ｣o Linear Simples (RLS)": "LinearRegression",
        "Regressﾃ｣o por Vetores de Suporte (SVR)": "SVR"
    }
    
    # **Verificar se hﾃ｡ modelos disponﾃｭveis**
    if 'models' not in st.session_state or not st.session_state.models:
        st.error("Erro: Nenhum modelo foi treinado ou selecionado.")
        return

    if 'selected_model_name' not in st.session_state or not st.session_state.selected_model_name:
        st.error("Nenhum modelo foi selecionado. Por favor, selecione um modelo antes de continuar.")
        return

    # **Obter o nome do modelo selecionado e verificar a sua existﾃｪncia**
    selected_model_name = st.session_state.selected_model_name.strip()
    model_class_name = model_name_map.get(selected_model_name, selected_model_name)

    if model_class_name not in st.session_state.models:
        st.error(f"O modelo '{selected_model_name}' nﾃ｣o foi encontrado na sessﾃ｣o.")
        st.write("Modelos disponﾃｭveis:", list(st.session_state.models.keys()))
        return

    # **Recuperar o modelo**
    model = st.session_state.models[model_class_name]
    
    # **Recuperar os dados selecionados**
    X_train_selected, X_test_selected = st.session_state.X_train_selected, st.session_state.X_test_selected
    y_train, y_test = st.session_state.y_train, st.session_state.y_test
    
    st.write(f"Treinando o modelo {selected_model_name} com {len(st.session_state.selected_features)} features selecionadas...")
    
    # **Treinar e armazenar mﾃｩtricas**
    selected_metrics = train_and_store_metrics(
        model, X_train_selected, y_train, X_test_selected, y_test, "Com Seleﾃｧﾃ｣o", False
    )
    
    # **Exibir mﾃｩtricas se o treino for bem-sucedido**
    if selected_metrics:
        st.session_state['resultado_com_selecao'] = selected_metrics
        st.success("Treinamento concluﾃｭdo!")
        
        st.subheader("Mﾃｩtricas do Modelo com Features Selecionadas")
        metrics_df = pd.DataFrame([selected_metrics])
        metrics_df.insert(0, "Modelo", "Com Seleﾃｧﾃ｣o de Features")
        st.table(metrics_df)
    
    # **Botﾃ｣o para comparar modelos**
    if st.button("Comparar Modelos"):
        st.session_state.step = 'evaluate_and_compare_models'
        st.rerun()


# **Funﾃｧﾃ｣o para treinar o modelo e armazenar mﾃｩtricas**
def train_and_store_metrics(model, X_train, y_train, X_test, y_test, metric_type, use_grid_search=False, manual_params=None):
    """
    Treina o modelo e armazena as mﾃｩtricas de desempenho.
    
    Parﾃ｢metros:
    - model: Modelo a ser treinado.
    - X_train, y_train: Dados de treino.
    - X_test, y_test: Dados de teste.
    - metric_type: Tipo de treino ("Com Seleﾃｧﾃ｣o" ou "Sem Seleﾃｧﾃ｣o").
    - use_grid_search: Se True, aplica GridSearchCV.
    - manual_params: Parﾃ｢metros manuais a serem aplicados.
    
    Retorna:
    - Dicionﾃ｡rio com mﾃｩtricas do modelo.
    """
    try:
        # **1. Tratar valores ausentes**
        imputer = SimpleImputer(strategy="mean")  # Preenche valores ausentes com a mﾃｩdia
        X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)
        X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)

        # **2. Converter variﾃ｡veis categﾃｳricas**
        if y_train.dtype == 'object':
            from sklearn.preprocessing import LabelEncoder
            le = LabelEncoder()
            y_train = le.fit_transform(y_train)
            y_test = le.transform(y_test)
        else:
            y_train = y_train.fillna(y_train.mean())
            y_test = y_test.fillna(y_test.mean())

        # **3. Aplicar parﾃ｢metros salvos ao modelo, se existirem**
        if metric_type == "Com Seleﾃｧﾃ｣o":
            saved_params = st.session_state.get('best_params_selected', None) or st.session_state.get('best_params', None)
        else:
            saved_params = st.session_state.get('best_params', None)

        if saved_params and hasattr(model, 'get_params') and all(param in model.get_params() for param in saved_params):
            st.info(f"Aplicando parﾃ｢metros salvos ao modelo: {saved_params}")
            model.set_params(**saved_params)

        # **4. Treinar o modelo com ou sem GridSearch**
        if use_grid_search and metric_type == "Sem Seleﾃｧﾃ｣o":
            param_grid = st.session_state.get('param_grid', {
                'n_neighbors': [3, 5, 7, 9],
                'weights': ['uniform', 'distance']
            })

            cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)
            scoring = 'accuracy' if st.session_state.model_type == "Classificaﾃｧﾃ｣o" else 'r2'

            grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=cv_strategy, n_jobs=-1)
            grid_search.fit(X_train, y_train)

            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_

            # **Salvar os melhores parﾃ｢metros no estado global**
            st.session_state['best_params'] = best_params
            st.session_state['best_params_selected'] = best_params

        else:
            model.fit(X_train, y_train)
            best_model = model
            best_params = saved_params if saved_params else {}

        # **5. Armazenar o modelo treinado na sessﾃ｣o**
        st.session_state['trained_model'] = best_model
        st.session_state['trained_model_name'] = best_model.__class__.__name__
        
        # **6. Fazer previsﾃｵes**
        y_pred = best_model.predict(X_test)

        # **7. Calcular as mﾃｩtricas de desempenho**
        if st.session_state.model_type == "Classificaﾃｧﾃ｣o":
            metrics = {
                'F1-Score': f1_score(y_test, y_pred, average='weighted'),
                'Precision': precision_score(y_test, y_pred, average='weighted'),
                'Recall': recall_score(y_test, y_pred, average='weighted'),
                'Accuracy': accuracy_score(y_test, y_pred),
                'Best Parameters': best_params
            }
        else:
            metrics = {
                'Rﾂｲ': r2_score(y_test, y_pred),
                'MSE': mean_squared_error(y_test, y_pred),
                'MAE': mean_absolute_error(y_test, y_pred),
                'Best Parameters': best_params
            }

        # **8. Armazenar mﾃｩtricas no estado global**
        if 'metrics' not in st.session_state:
            st.session_state['metrics'] = {}
        st.session_state['metrics'][metric_type] = metrics

        return metrics

    except Exception as e:
        st.error(f"Erro ao treinar o modelo: {str(e)}")
        return None
        
def evaluate_and_compare_models():
    st.title("Comparaﾃｧﾃ｣o dos Resultados do Treino dos Modelos")

    # **Mapeamento de modelos para garantir compatibilidade de nomenclatura**
    model_name_map = {
        "SVC": "Support Vector Classification (SVC)",
        "KNeighborsClassifier": "K-Nearest Neighbors (KNN)",
        "RandomForestClassifier": "Random Forest",
        "LinearRegression": "Regressﾃ｣o Linear Simples (RLS)",
        "SVR": "Regressﾃ｣o por Vetores de Suporte (SVR)",
        "Support Vector Classification (SVC)": "SVC",
        "K-Nearest Neighbors (KNN)": "KNeighborsClassifier", 
        "Random Forest": "RandomForestClassifier",
        "Regressﾃ｣o Linear Simples (RLS)": "LinearRegression",
        "Regressﾃ｣o por Vetores de Suporte (SVR)": "SVR"
    }

    # **Verificaﾃｧﾃｵes preliminares para garantir que todas as etapas anteriores foram concluﾃｭdas**
    if 'selected_features' not in st.session_state:
        st.error("Nenhuma feature foi selecionada. Por favor, volte ﾃ etapa de seleﾃｧﾃ｣o de features.")
        return

    if 'models' not in st.session_state or not st.session_state.models:
        st.error("Configuraﾃｧﾃ｣o de modelos nﾃ｣o encontrada. Por favor, reinicie o processo de seleﾃｧﾃ｣o de modelos.")
        return

    # **Obter tipo de modelo e mﾃｩtrica escolhida**
    model_type = st.session_state.get('model_type', 'Indefinido')
    scoring_metric = st.session_state.get("selected_scoring", None)
    
    if not scoring_metric:
        st.error("Nenhuma mﾃｩtrica de avaliaﾃｧﾃ｣o foi escolhida. Por favor, volte ﾃ etapa de seleﾃｧﾃ｣o de mﾃｩtricas.")
        return

    # **Recuperar o nome do modelo selecionado**
    model_name = st.session_state.get('selected_model_name')
    if not model_name:
        st.error("Nenhum modelo foi selecionado. Por favor, volte ﾃ etapa de seleﾃｧﾃ｣o de modelos.")
        return

    # **Verificar se o modelo estﾃ｡ no mapeamento**
    model_class_name = model_name_map.get(model_name)
    if model_class_name is None:
        st.error(f"O modelo {model_name} nﾃ｣o foi encontrado na lista de modelos disponﾃｭveis.")
        st.write("Modelos disponﾃｭveis:", list(model_name_map.keys()))
        return

    # **Recuperar o modelo treinado**
    model = st.session_state.models.get(model_class_name)
    if model is None:
        st.error(f"O modelo {model_class_name} nﾃ｣o foi encontrado na sessﾃ｣o.")
        st.write("Modelos disponﾃｭveis:", list(st.session_state.models.keys()))
        return

    # **Obter as mﾃｩtricas dos modelos treinados**
    original_metrics = st.session_state.get('resultado_sem_selecao', {}) 
    selected_metrics = st.session_state.get('resultado_com_selecao', {})

    if not original_metrics:
        st.error("Nﾃ｣o foi possﾃｭvel encontrar as mﾃｩtricas originais. Por favor, refaﾃｧa o treinamento.")
        return
        
    if not selected_metrics:
        st.error("Nﾃ｣o foi possﾃｭvel encontrar as mﾃｩtricas com seleﾃｧﾃ｣o de features. Por favor, execute o treino com features selecionadas.")
        return

    # **Criar DataFrame de comparaﾃｧﾃ｣o**
    if model_type == "Classificaﾃｧﾃ｣o":
        comparison_df = pd.DataFrame({
            'Modelo': ['Sem Seleﾃｧﾃ｣o de Features', 'Com Seleﾃｧﾃ｣o de Features'],
            'Accuracy': [original_metrics.get('Accuracy', 0), selected_metrics.get('Accuracy', 0)],
            'Precision': [original_metrics.get('Precision', 0), selected_metrics.get('Precision', 0)],
            'Recall': [original_metrics.get('Recall', 0), selected_metrics.get('Recall', 0)],
            'F1-Score': [original_metrics.get('F1-Score', 0), selected_metrics.get('F1-Score', 0)],
            'Best Parameters': [original_metrics.get('Best Parameters', 'N/A'), selected_metrics.get('Best Parameters', 'N/A')]
        })
    elif model_type == "Regressﾃ｣o":
        comparison_df = pd.DataFrame({
            'Modelo': ['Sem Seleﾃｧﾃ｣o de Features', 'Com Seleﾃｧﾃ｣o de Features'],
            'Rﾂｲ': [original_metrics.get('Rﾂｲ', 0), selected_metrics.get('Rﾂｲ', 0)],
            'MAE': [original_metrics.get('MAE', 0), selected_metrics.get('MAE', 0)],
            'MSE': [original_metrics.get('MSE', 0), selected_metrics.get('MSE', 0)],
            'Best Parameters': [original_metrics.get('Best Parameters', 'N/A'), selected_metrics.get('Best Parameters', 'N/A')]
        })
    else:
        st.error(f"Tipo de modelo nﾃ｣o reconhecido: {model_type}")
        return

    # **Exibir tabela de comparaﾃｧﾃ｣o**
    st.subheader("嶋 Comparaﾃｧﾃ｣o dos Resultados:")
    
    format_dict = {}
    for col in comparison_df.columns:
        if col != 'Modelo' and col != 'Best Parameters':
            format_dict[col] = '{:.4f}'
    
    st.dataframe(
        comparison_df.style.format(format_dict).set_table_styles(
            [{'selector': 'th', 'props': [('font-size', '18px')]}, 
             {'selector': 'td', 'props': [('font-size', '12px')]},  
             {'selector': 'table', 'props': [('width', '100%')]},    
            ]
        )
    )
    
    # **Criar grﾃ｡fico de comparaﾃｧﾃ｣o com base na mﾃｩtrica selecionada**
    if scoring_metric in comparison_df.columns:
        fig, ax = plt.subplots(figsize=(10, 6))

        x_pos = [0, 1]
        width = 0.4

        bars1 = ax.bar(x_pos[0], comparison_df[scoring_metric].iloc[0], width=width, label="Sem Seleﾃｧﾃ｣o de Features", color='#90EE90', align='center')
        bars2 = ax.bar(x_pos[1], comparison_df[scoring_metric].iloc[1], width=width, label="Com Seleﾃｧﾃ｣o de Features", color='#006400', align='center')

        for bar in bars1:
            ax.annotate(f'{bar.get_height():.4f}', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()), 
                        xytext=(0, 3), textcoords="offset points", ha='center', fontsize=12, color='black')

        for bar in bars2:
            ax.annotate(f'{bar.get_height():.4f}', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()), 
                        xytext=(0, 3), textcoords="offset points", ha='center', fontsize=12, color='black')

        ax.set_title(f'Comparaﾃｧﾃ｣o de {scoring_metric}', fontsize=16, fontweight='bold')
        ax.set_ylabel(scoring_metric, fontsize=14)
        ax.set_xlabel("Modelos", fontsize=14)

        plt.xticks(x_pos, ['Sem Seleﾃｧﾃ｣o de Features', 'Com Seleﾃｧﾃ｣o de Features'], fontsize=12)
        plt.yticks(fontsize=12)

        ax.legend()
        plt.tight_layout()

        st.pyplot(fig)

    # **Determinar o melhor modelo com base na mﾃｩtrica escolhida**
    score_without = comparison_df[scoring_metric].iloc[0]
    score_with = comparison_df[scoring_metric].iloc[1]

    better_model = "Com Seleﾃｧﾃ｣o de Features" if score_with > score_without else "Sem Seleﾃｧﾃ｣o de Features"
    better_score = max(score_with, score_without)

    st.success(f"醇 **Melhor modelo:** {better_model} com {scoring_metric} = {better_score:.4f}")
    
    # **Botﾃ｣o para avanﾃｧar para a prﾃｳxima etapa**
    if st.button("Seguir para Resumo Final", key="btn_resumo_final"):
        st.session_state.step = 'final_page'
        st.rerun()

# Funﾃｧﾃ｣o para gerar interpretaﾃｧﾃ｣o personalizada das mﾃｩtricas de classificaﾃｧﾃ｣o
def generate_metrics_interpretation(metrics):
    """Gera interpretaﾃｧﾃ｣o personalizada para mﾃｩtricas de modelos de classificaﾃｧﾃ｣o."""
    interpretacao = []

    # **Verificar se as mﾃｩtricas estﾃ｣o no formato esperado**
    if not isinstance(metrics, dict):
        return "Formato de mﾃｩtricas invﾃ｡lido."

    # **Interpretaﾃｧﾃ｣o para Acurﾃ｡cia (Accuracy)**
    if 'Accuracy' in metrics:
        try:
            accuracy = float(metrics['Accuracy'])
            if accuracy > 0.9:
                interpretacao.append(f"- Acurﾃ｡cia: {accuracy:.4f} - Excelente! O modelo tem uma taxa de acerto muito elevada.")
            elif accuracy > 0.75:
                interpretacao.append(f"- Acurﾃ｡cia: {accuracy:.4f} - Boa. O modelo estﾃ｡ a funcionar bem, mas pode ser otimizado.")
            elif accuracy > 0.5:
                interpretacao.append(f"- Acurﾃ｡cia: {accuracy:.4f} - Moderada. O modelo apresenta um nﾃｭvel de erro considerﾃ｡vel.")
            else:
                interpretacao.append(f"- Acurﾃ｡cia: {accuracy:.4f} - Fraca. O modelo falha em muitas previsﾃｵes e precisa de ajustes.")
        except (ValueError, TypeError):
            interpretacao.append("- Acurﾃ｡cia: Nﾃ｣o disponﾃｭvel ou invﾃ｡lida.")

    # **Interpretaﾃｧﾃ｣o para Precisﾃ｣o (Precision)**
    if 'Precision' in metrics:
        try:
            precision = float(metrics['Precision'])
            if precision > 0.9:
                interpretacao.append(f"- Precisﾃ｣o: {precision:.4f} - Excelente! O modelo evita falsos positivos com alta confianﾃｧa.")
            elif precision > 0.75:
                interpretacao.append(f"- Precisﾃ｣o: {precision:.4f} - Boa. O modelo ﾃｩ confiﾃ｡vel, mas pode ser mais rigoroso na seleﾃｧﾃ｣o.")
            elif precision > 0.5:
                interpretacao.append(f"- Precisﾃ｣o: {precision:.4f} - Moderada. O modelo ainda produz muitos falsos positivos.")
            else:
                interpretacao.append(f"- Precisﾃ｣o: {precision:.4f} - Fraca. Muitos falsos positivos comprometem a confiabilidade.")
        except (ValueError, TypeError):
            interpretacao.append("- Precisﾃ｣o: Nﾃ｣o disponﾃｭvel ou invﾃ｡lida.")

    # **Interpretaﾃｧﾃ｣o para Recall (Sensibilidade)**
    if 'Recall' in metrics:
        try:
            recall = float(metrics['Recall'])
            if recall > 0.9:
                interpretacao.append(f"- Recall: {recall:.4f} - Excelente! O modelo deteta quase todos os casos positivos.")
            elif recall > 0.75:
                interpretacao.append(f"- Recall: {recall:.4f} - Bom. A maioria dos positivos sﾃ｣o identificados.")
            elif recall > 0.5:
                interpretacao.append(f"- Recall: {recall:.4f} - Moderado. O modelo estﾃ｡ a perder muitos casos positivos.")
            else:
                interpretacao.append(f"- Recall: {recall:.4f} - Fraco. O modelo falha em detetar muitos casos positivos.")
        except (ValueError, TypeError):
            interpretacao.append("- Recall: Nﾃ｣o disponﾃｭvel ou invﾃ｡lido.")

    # **Interpretaﾃｧﾃ｣o para F1-Score**
    if 'F1-Score' in metrics:
        try:
            f1_score = float(metrics['F1-Score'])
            if f1_score > 0.9:
                interpretacao.append(f"- F1-Score: {f1_score:.4f} - Excelente equilﾃｭbrio entre precisﾃ｣o e recall.")
            elif f1_score > 0.75:
                interpretacao.append(f"- F1-Score: {f1_score:.4f} - Bom, mas pode ser melhorado.")
            elif f1_score > 0.5:
                interpretacao.append(f"- F1-Score: {f1_score:.4f} - Moderado. Ajustes podem melhorar o desempenho.")
            else:
                interpretacao.append(f"- F1-Score: {f1_score:.4f} - Fraco. Ajustes profundos sﾃ｣o necessﾃ｡rios.")
        except (ValueError, TypeError):
            interpretacao.append("- F1-Score: Nﾃ｣o disponﾃｭvel ou invﾃ｡lido.")

    # **Conclusﾃ｣o Geral**
    if all(key in metrics for key in ['F1-Score', 'Precision', 'Recall']):
        try:
            f1_score = float(metrics['F1-Score'])
            precision = float(metrics['Precision'])
            recall = float(metrics['Recall'])

            if f1_score > 0.9 and precision > 0.9 and recall > 0.9:
                interpretacao.append("\nConclusﾃ｣o: 脂 O modelo tem um desempenho excecional!")
            elif f1_score > 0.75 and precision > 0.75 and recall > 0.75:
                interpretacao.append("\nConclusﾃ｣o: 総 O modelo tem um bom desempenho geral.")
            elif f1_score > 0.5 or precision > 0.5 or recall > 0.5:
                interpretacao.append("\nConclusﾃ｣o: 笞ｸ O modelo ﾃｩ funcional, mas pode ser melhorado.")
            else:
                interpretacao.append("\nConclusﾃ｣o: 笶 O modelo apresenta desempenho insatisfatﾃｳrio.")
        except (ValueError, TypeError):
            pass

    return "\n".join(interpretacao)


# Funﾃｧﾃ｣o para gerar interpretaﾃｧﾃ｣o personalizada das mﾃｩtricas de regressﾃ｣o
def generate_regression_interpretation(metrics):
    """Gera interpretaﾃｧﾃ｣o personalizada para mﾃｩtricas de regressﾃ｣o."""
    interpretation = []

    # **Verificar se as mﾃｩtricas estﾃ｣o no formato esperado**
    if not isinstance(metrics, dict):
        return "Formato de mﾃｩtricas invﾃ｡lido."

    # **Interpretaﾃｧﾃ｣o para Rﾂｲ (Coeficiente de Determinaﾃｧﾃ｣o)**
    if 'Rﾂｲ' in metrics:
        try:
            r2 = float(metrics['Rﾂｲ'])
            if r2 > 0.9:
                interpretation.append(f"- Rﾂｲ: {r2:.4f} - Excelente! O modelo explica quase toda a variabilidade dos dados.")
            elif r2 > 0.75:
                interpretation.append(f"- Rﾂｲ: {r2:.4f} - Muito bom! O modelo tem um ﾃｳtimo ajuste.")
            elif r2 > 0.5:
                interpretation.append(f"- Rﾂｲ: {r2:.4f} - Moderado. O modelo precisa de ajustes para melhor explicaﾃｧﾃ｣o dos dados.")
            else:
                interpretation.append(f"- Rﾂｲ: {r2:.4f} - Fraco. O modelo tem um ajuste insatisfatﾃｳrio.")
        except (ValueError, TypeError):
            interpretation.append("- Rﾂｲ: Nﾃ｣o disponﾃｭvel ou invﾃ｡lido.")

    # **Interpretaﾃｧﾃ｣o para MAE (Erro Absoluto Mﾃｩdio)**
    if 'MAE' in metrics:
        try:
            mae = float(metrics['MAE'])
            if mae < 0.1:
                interpretation.append(f"- MAE: {mae:.4f} - Excelente! As previsﾃｵes estﾃ｣o muito prﾃｳximas dos valores reais.")
            elif mae < 1:
                interpretation.append(f"- MAE: {mae:.4f} - Bom. O erro ﾃｩ aceitﾃ｡vel, mas pode ser reduzido.")
            else:
                interpretation.append(f"- MAE: {mae:.4f} - Alto. O modelo apresenta desvios significativos.")
        except (ValueError, TypeError):
            interpretation.append("- MAE: Nﾃ｣o disponﾃｭvel ou invﾃ｡lido.")

    # **Interpretaﾃｧﾃ｣o para MSE (Erro Quadrﾃ｡tico Mﾃｩdio)**
    if 'MSE' in metrics:
        try:
            mse = float(metrics['MSE'])
            if mse < 0.1:
                interpretation.append(f"- MSE: {mse:.4f} - Excelente! As previsﾃｵes tﾃｪm erros mﾃｭnimos.")
            elif mse < 1:
                interpretation.append(f"- MSE: {mse:.4f} - Bom. O erro estﾃ｡ sob controlo, mas pode ser otimizado.")
            else:
                interpretation.append(f"- MSE: {mse:.4f} - Alto. As previsﾃｵes estﾃ｣o significativamente afastadas dos valores reais.")
        except (ValueError, TypeError):
            interpretation.append("- MSE: Nﾃ｣o disponﾃｭvel ou invﾃ｡lido.")

    # **Conclusﾃ｣o Geral**
    if all(key in metrics for key in ['Rﾂｲ', 'MAE', 'MSE']):
        try:
            r2 = float(metrics['Rﾂｲ'])
            mse = float(metrics['MSE'])
            mae = float(metrics['MAE'])

            if r2 > 0.9 and mse < 0.1 and mae < 0.1:
                interpretation.append("\nConclusﾃ｣o: 脂 O modelo apresenta um desempenho excecional!")
            elif r2 > 0.75 and mse < 1 and mae < 1:
                interpretation.append("\nConclusﾃ｣o: 総 O modelo tem um bom desempenho geral.")
            elif r2 > 0.5 or mse < 1 or mae < 1:
                interpretation.append("\nConclusﾃ｣o: 笞ｸ O modelo precisa de melhorias.")
            else:
                interpretation.append("\nConclusﾃ｣o: 笶 O modelo apresenta um desempenho insatisfatﾃｳrio.")
        except (ValueError, TypeError):
            pass

    return "\n".join(interpretation)


import joblib

# Funﾃｧﾃ｣o para salvar o modelo treinado com um nome dinﾃ｢mico
def save_best_model(model, with_feature_selection=True):
    """
    Salva o modelo treinado em um ficheiro .pkl, permitindo a recuperaﾃｧﾃ｣o posterior.

    Parﾃ｢metros:
    - model: Modelo treinado a ser salvo.
    - with_feature_selection (bool): Se True, indica que o modelo foi treinado com seleﾃｧﾃ｣o de features.

    Retorna:
    - str: Nome do ficheiro onde o modelo foi salvo, ou None em caso de erro.
    """
    try:
        # Determinar o nome do ficheiro dependendo se houve seleﾃｧﾃ｣o de features
        if with_feature_selection:
            model_filename = "best_model_com_selecao_features.pkl"
        else:
            model_filename = "best_model_sem_selecao_features.pkl"

        # Salvar o modelo utilizando joblib
        joblib.dump(model, model_filename)
        
        # Mensagem de sucesso
        st.success(f"Modelo salvo com sucesso como {model_filename}")
        
        return model_filename
    except Exception as e:
        # Exibir erro caso ocorra alguma falha no processo de salvamento
        st.error(f"Erro ao salvar o modelo: {str(e)}")
        return None


# Funﾃｧﾃ｣o para executar o treino e avanﾃｧar para a etapa final
def execute_training():
    """
    Executa o treino do modelo armazenado no session_state e avanﾃｧa para a pﾃ｡gina final.

    Esta funﾃｧﾃ｣o:
    - Recupera o modelo selecionado pelo utilizador.
    - Treina o modelo e armazena as mﾃｩtricas resultantes.
    - Exibe informaﾃｧﾃｵes de depuraﾃｧﾃ｣o.
    - Redireciona para a pﾃ｡gina final apﾃｳs o treino.
    """
    if st.session_state.step == 'train_and_store_metrics':
        # Recuperar o modelo selecionado
        model = st.session_state.models[st.session_state.selected_model_name]

        # Treinar o modelo e armazenar as mﾃｩtricas
        metrics = train_and_store_metrics(
            model,
            st.session_state.X_train,
            st.session_state.y_train,
            st.session_state.X_test,
            st.session_state.y_test,
            metric_type="sem_selecao_features"
        )

        # **Depuraﾃｧﾃ｣o**: Exibir as mﾃｩtricas armazenadas no session_state apﾃｳs o treino
        st.write("Conteﾃｺdo de metrics apﾃｳs treino:", st.session_state.get('metrics', {}))

        # Avanﾃｧar para a pﾃ｡gina final apﾃｳs o treino ser concluﾃｭdo
        st.session_state.step = 'final_page'
        st.rerun()


## Relatﾃｳrio Final para Classificaﾃｧﾃ｣o/Regressao ##

# Funﾃｧﾃ｣o para gerar o relatﾃｳrio em PDF
from fpdf import FPDF
import requests
import tempfile
from datetime import datetime
from io import BytesIO
import matplotlib.pyplot as plt
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import Paragraph

# Classe personalizada para a geraﾃｧﾃ｣o de PDFs
class CustomPDF(FPDF):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # Inicializar a variﾃ｡vel do caminho do logﾃｳtipo
        self.logo_path = None
        
        # URL do logﾃｳtipo institucional
        logo_url = 'https://www.ipleiria.pt/normasgraficas/wp-content/uploads/sites/80/2017/09/estg_v-01.jpg'
        
        try:
            # Tentar fazer o download do logﾃｳtipo
            response = requests.get(logo_url)
            if response.status_code == 200:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmpfile:
                    tmpfile.write(response.content)
                    self.logo_path = tmpfile.name
        except Exception as e:
            print(f"Erro ao baixar o logﾃｳtipo: {e}")

    def header(self):
        """Cabeﾃｧalho do relatﾃｳrio"""
        
        # Posicionar o cabeﾃｧalho no topo da pﾃ｡gina
        self.set_y(10)
        
        # Inserir o logﾃｳtipo se foi baixado com sucesso
        if self.logo_path:
            self.image(self.logo_path, 10, 10, 25)
        
        # Definir a fonte e tamanho do tﾃｭtulo
        self.set_font('Arial', 'B', 12)
        
        # Adicionar o tﾃｭtulo centralizado
        self.cell(25)  # Criar espaﾃｧo para o logﾃｳtipo
        self.cell(0, 10, 'MLCase - Plataforma de Machine Learning', 0, 0, 'C')
        
        # Criar uma linha horizontal para separar o cabeﾃｧalho do conteﾃｺdo
        self.ln(15)
        self.ln(5)  # Criar espaﾃｧo apﾃｳs o cabeﾃｧalho

    def footer(self):
        """Rodapﾃｩ do relatﾃｳrio"""
        
        # Posicionar o rodapﾃｩ a 1.5 cm da parte inferior
        self.set_y(-20)
        
        # Adicionar uma linha horizontal acima do rodapﾃｩ
        self.line(10, self.get_y(), 200, self.get_y())
        self.ln(3)
        
        # Definir a fonte do rodapﾃｩ
        self.set_font('Arial', 'I', 8)
        
        # Obter a data atual
        current_date = datetime.now().strftime('%d/%m/%Y')
        
        # Adicionar a data e nﾃｺmero da pﾃ｡gina
        self.cell(0, 10, f'{current_date} - Pﾃ｡gina {self.page_no()}  |  Autora da Plataforma: Bruna Sousa', 0, 0, 'C')


# Classe responsﾃ｡vel pela geraﾃｧﾃ｣o do relatﾃｳrio da performance do modelo
class MLCaseModelReportGenerator:
    def __init__(self, output_path='model_performance_report.pdf', logo_url=None):
        """
        Inicializa o gerador de relatﾃｳrios de performance do modelo.

        Parﾃ｢metros:
        - output_path (str): Caminho para salvar o PDF.
        - logo_url (str, opcional): URL do logﾃｳtipo da instituiﾃｧﾃ｣o.
        """
        self.output_path = output_path
        
        # Definir a URL padrﾃ｣o do logﾃｳtipo se nﾃ｣o for especificada
        self.logo_url = logo_url or 'https://www.ipleiria.pt/normasgraficas/wp-content/uploads/sites/80/2017/09/estg_v-01.jpg'
        
        # Fazer o download do logﾃｳtipo
        self.logo_path = self._fetch_logo()
        
        # Preparar estilos personalizados
        self.styles = getSampleStyleSheet()
        self._create_custom_styles()
    
    def _fetch_logo(self):
        """Faz o download do logﾃｳtipo e armazena temporariamente."""
        try:
            response = requests.get(self.logo_url)
            if response.status_code == 200:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmpfile:
                    tmpfile.write(response.content)
                    return tmpfile.name
            return None
        except Exception:
            return None
    
    def _create_custom_styles(self):
        """Define estilos personalizados para os textos do relatﾃｳrio."""
        
        # Estilo do tﾃｭtulo
        self.styles.add(ParagraphStyle(
            name='MLCaseTitle',
            parent=self.styles['Title'],
            fontSize=18,
            textColor=colors.HexColor('#2C3E50'),
            alignment=1,  # Centralizado
            spaceAfter=12
        ))
        
        # Estilo do subtﾃｭtulo
        self.styles.add(ParagraphStyle(
            name='MLCaseSubtitle',
            parent=self.styles['Heading2'],
            fontSize=14,
            textColor=colors.HexColor('#34495E'),
            spaceAfter=6
        ))
        
        # Estilo do texto normal
        self.styles.add(ParagraphStyle(
            name='MLCaseNormal',
            parent=self.styles['Normal'],
            fontSize=10,
            textColor=colors.HexColor('#2C3E50'),
            leading=14  # Espaﾃｧamento entre linhas
        ))
    
    def create_bar_chart(self, data, labels, title):
        """
        Gera um grﾃ｡fico de barras para exibiﾃｧﾃ｣o no relatﾃｳrio.

        Parﾃ｢metros:
        - data (list): Valores das mﾃｩtricas.
        - labels (list): Nome das mﾃｩtricas.
        - title (str): Tﾃｭtulo do grﾃ｡fico.

        Retorna:
        - Objeto de buffer com o grﾃ｡fico gerado.
        """
        
        # Criar o grﾃ｡fico de barras com tamanho definido
        plt.figure(figsize=(6, 4), dpi=100)
        
        # Criar barras com cores diferenciadas
        plt.bar(labels, data, color=['#3498DB', '#2980B9'])
        
        # Definir tﾃｭtulo e rﾃｳtulos do grﾃ｡fico
        plt.title(title, fontsize=12, color='#2C3E50')
        plt.ylabel('Valor', color='#2C3E50')
        
        # Rotacionar os rﾃｳtulos do eixo X para melhor visualizaﾃｧﾃ｣o
        plt.xticks(rotation=45, ha='right', color='#2C3E50')
        
        # Ajustar automaticamente o layout para evitar sobreposiﾃｧﾃ｣o
        plt.tight_layout()
        
        # Criar um buffer de memﾃｳria para armazenar a imagem
        buf = BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        buf.seek(0)
        
        # Fechar a figura para evitar consumo de memﾃｳria
        plt.close()
        
        return buf
    
def gerar_relatorio_pdf(comparison_df, best_model, session_state):
    """
    Gera um relatﾃｳrio PDF com os resultados da comparaﾃｧﾃ｣o de modelos.

    Args:
        comparison_df: DataFrame contendo as mﾃｩtricas comparativas dos modelos.
        best_model: Nome do melhor modelo identificado.
        session_state: Estado da sessﾃ｣o do Streamlit com informaﾃｧﾃｵes do treino.

    Returns:
        BytesIO: Buffer contendo o PDF gerado.
    """

    # Inicializaﾃｧﾃ｣o do PDF com cabeﾃｧalho e rodapﾃｩ personalizados
    pdf = CustomPDF(format='A4')
    pdf.set_margins(10, 30, 10)  # Margens: esquerda, topo, direita
    pdf.set_auto_page_break(auto=True, margin=30)  # Margem inferior para o rodapﾃｩ
    pdf.add_page()
    
    # Funﾃｧﾃ｣o auxiliar para limpar texto e evitar erros de codificaﾃｧﾃ｣o Latin-1
    def clean_text(text):
        if not isinstance(text, str):
            return str(text)
        return text.encode('latin-1', errors='ignore').decode('latin-1')
    

    # Tﾃｭtulo do Relatﾃｳrio
    pdf.set_font("Arial", style="B", size=16)
    pdf.cell(0, 10, txt=clean_text("Relatﾃｳrio Final do Modelo Treinado"), ln=True, align="C")
    pdf.ln(10)
    
    # Tipo de Modelo Utilizado
    model_type = session_state.get('model_type', 'Indefinido')
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(60, 10, txt=clean_text("Tipo de Modelo:"), ln=False)
    pdf.set_font("Arial", size=12)
    pdf.cell(0, 10, txt=clean_text(model_type), ln=True)
    
    # Modelo Selecionado pelo Utilizador
    selected_model_name = session_state.get('selected_model_name', 'Nﾃ｣o Selecionado')
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(60, 10, txt=clean_text("Modelo Selecionado:"), ln=False)
    pdf.set_font("Arial", size=12)
    pdf.cell(0, 10, txt=clean_text(selected_model_name), ln=True)
    
    # Melhor Modelo Identificado com Base nas Mﾃｩtricas
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(60, 10, txt=clean_text("Melhor Modelo:"), ln=False)
    pdf.set_font("Arial", size=12)
    pdf.cell(0, 10, txt=clean_text(best_model), ln=True)
    pdf.ln(10)
    
    # Informaﾃｧﾃｵes sobre os Conjuntos de Dados Utilizados no Treino
    if 'X_train' in session_state and 'X_test' in session_state:
        X_train = session_state.X_train
        X_test = session_state.X_test
        
        # Calcular percentagem de amostras de treino e teste
        total_samples = X_train.shape[0] + X_test.shape[0]
        train_percent = (X_train.shape[0] / total_samples) * 100
        test_percent = (X_test.shape[0] / total_samples) * 100
        
        pdf.set_font("Arial", style="B", size=14)
        pdf.cell(0, 10, txt=clean_text("Informaﾃｧﾃｵes dos Conjuntos de Dados"), ln=True)
        pdf.ln(5)
        
        # Criar tabela com informaﾃｧﾃｵes do conjunto de dados
        data_info = [
            ["Amostras de Treino", f"{X_train.shape[0]} ({train_percent:.1f}%)"],
            ["Amostras de Teste", f"{X_test.shape[0]} ({test_percent:.1f}%)"],
            ["Features Originais", f"{X_train.shape[1]}"]
        ]
        
        # Adicionar nﾃｺmero de features apﾃｳs a seleﾃｧﾃ｣o, se disponﾃｭvel
        if 'X_train_selected' in session_state:
            data_info.append(["Features Apﾃｳs Seleﾃｧﾃ｣o", f"{session_state.X_train_selected.shape[1]}"])
        
        # Formatar e adicionar a tabela ao PDF
        pdf.set_font("Arial", size=10)
        pdf.set_fill_color(144, 238, 144)  # Cor de fundo do cabeﾃｧalho
        
        for i, (label, value) in enumerate(data_info):
            if i % 2 == 0:  # Linhas alternadas para melhor leitura
                pdf.set_fill_color(240, 240, 240)
            else:
                pdf.set_fill_color(255, 255, 255)
            
            pdf.cell(70, 8, txt=clean_text(label), border=1, ln=0, fill=True)
            pdf.cell(0, 8, txt=clean_text(value), border=1, ln=1, fill=True)
        
        pdf.ln(10)
    
    # Features Selecionadas no Processo de Seleﾃｧﾃ｣o de Features
    if 'selected_features' in session_state:
        pdf.set_font("Arial", style="B", size=14)
        pdf.cell(0, 10, txt=clean_text("Features Selecionadas"), ln=True)
        
        # Listar todas as features utilizadas apﾃｳs a seleﾃｧﾃ｣o
        features = session_state.selected_features
        pdf.set_font("Arial", size=10)
        for i, feature in enumerate(features):
            pdf.cell(0, 6, txt=clean_text(f"窶｢ {feature}"), ln=True)
        
        pdf.ln(10)
    
    # Comparaﾃｧﾃ｣o de Mﾃｩtricas entre Modelos
    pdf.set_font("Arial", style="B", size=14)
    pdf.cell(0, 10, txt=clean_text("Comparaﾃｧﾃ｣o de Mﾃｩtricas"), ln=True)
    
    # Determinar o tipo de modelo (Regressﾃ｣o ou Classificaﾃｧﾃ｣o) para escolher as mﾃｩtricas adequadas
    is_regression = model_type == "Regressﾃ｣o"
    metric_columns = ['Rﾂｲ', 'MAE', 'MSE'] if is_regression else ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    
    # Criar tabela de mﾃｩtricas no relatﾃｳrio
    pdf.set_font("Arial", style="B", size=10)
    pdf.set_fill_color(144, 238, 144)  # Definir cor do cabeﾃｧalho
    
    # Definir largura das colunas
    column_width = 30
    first_column_width = 60
    
    # Criar cabeﾃｧalho da tabela
    pdf.cell(first_column_width, 10, "Modelo", 1, 0, 'C', True)
    for col in metric_columns:
        pdf.cell(column_width, 10, clean_text(col), 1, 0, 'C', True)
    pdf.ln()
    
    # Preencher as linhas da tabela com os valores das mﾃｩtricas
    pdf.set_font("Arial", size=10)
    for _, row in comparison_df.iterrows():
        model_name = row['Modelo']
        pdf.cell(first_column_width, 10, clean_text(model_name), 1, 0, 'L')
        
        for col in metric_columns:
            if col in row:
                # Formatar valores numﾃｩricos para 4 casas decimais
                if isinstance(row[col], (int, float)):
                    value = f"{row[col]:.4f}"
                else:
                    value = str(row[col])
                pdf.cell(column_width, 10, clean_text(value), 1, 0, 'C')
        
        pdf.ln()
    
    pdf.ln(10)

    # Grﾃ｡ficos de Mﾃｩtricas
    for metric in metric_columns:
        if metric in comparison_df.columns:
            # Criar o grﾃ｡fico com tamanho adequado
            plt.figure(figsize=(10, 6))
            
            # Obter os modelos e os valores da mﾃｩtrica atual
            models = comparison_df['Modelo'].tolist()
            values = comparison_df[metric].tolist()
            
            # Criar grﾃ｡fico de barras com cores diferenciadas para melhor visualizaﾃｧﾃ｣o
            plt.bar(models, values, color=['#90EE90', '#006400'], width=0.4)
            
            # Adicionar valores sobre as barras para melhor compreensﾃ｣o
            for i, v in enumerate(values):
                if isinstance(v, (int, float)):  # Garantir que o valor ﾃｩ numﾃｩrico
                    plt.text(i, v + 0.01, f"{v:.4f}", ha='center', fontsize=10)
            
            # Configuraﾃｧﾃ｣o do eixo X sem rotaﾃｧﾃ｣o para manter alinhamento claro
            plt.xticks(rotation=0, ha='center', fontsize=8)  # Antes era rotation=45, alterado para 0
            
            # Estilizaﾃｧﾃ｣o do grﾃ｡fico
            plt.title(f"Comparaﾃｧﾃ｣o de {metric}", fontsize=14, pad=15)  # Aumentar o espaﾃｧo acima do tﾃｭtulo
            plt.ylabel(metric, fontsize=12)
            
            # Ajustar espaﾃｧo do grﾃ｡fico para garantir melhor apresentaﾃｧﾃ｣o
            plt.subplots_adjust(bottom=0.2, left=0.15)  # Aumentar margem inferior e lateral esquerda
            
            # Ajustar a altura do grﾃ｡fico para evitar cortes no eixo Y
            plt.ylim(0, max(values) * 1.2)  # Aumenta o limite superior em 20% para evitar sobrecarga visual
            
            plt.tight_layout()  # Ajustar automaticamente o layout para evitar sobreposiﾃｧﾃｵes
            
            # Guardar o grﾃ｡fico num ficheiro temporﾃ｡rio com DPI superior para melhor qualidade
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
            plt.savefig(temp_file.name, bbox_inches='tight', dpi=150)  # DPI aumentado para evitar pixelizaﾃｧﾃ｣o
            plt.close()
        
            # Adicionar o grﾃ｡fico ao PDF
            pdf.add_page()
            pdf.set_font("Arial", style="B", size=14)
            pdf.cell(0, 10, txt=clean_text(f"Grﾃ｡fico de Comparaﾃｧﾃ｣o - {metric}"), ln=True, align="C")
            
            # Posicionar o grﾃ｡fico mais abaixo para evitar sobreposiﾃｧﾃ｣o com o cabeﾃｧalho
            pdf.image(temp_file.name, x=10, y=45, w=180)  # Posiﾃｧﾃ｣o Y ajustada para evitar cortes
            
            # Fechar e eliminar o ficheiro temporﾃ｡rio apﾃｳs utilizaﾃｧﾃ｣o
            temp_file.close()
            try:
                os.remove(temp_file.name)  # Remover o ficheiro temporﾃ｡rio para evitar acumulaﾃｧﾃ｣o de arquivos
            except:
                pass  # Se houver erro ao eliminar, ignorar e seguir em frente
    
    # Adicionar uma nova pﾃ｡gina ao PDF para interpretaﾃｧﾃ｣o das mﾃｩtricas
    pdf.add_page()
    pdf.set_font("Arial", style="B", size=14)
    pdf.cell(0, 10, txt=clean_text("Interpretaﾃｧﾃ｣o das Mﾃｩtricas"), ln=True, align="C")

    # Funﾃｧﾃ｣o para gerar interpretaﾃｧﾃ｣o de mﾃｩtricas
    def generate_metrics_interpretation(metrics, model_type):
        """
        Gera uma interpretaﾃｧﾃ｣o personalizada das mﾃｩtricas do modelo.
        
        Args:
            metrics (dict): Dicionﾃ｡rio contendo as mﾃｩtricas do modelo.
            model_type (str): Tipo do modelo ('Classificaﾃｧﾃ｣o' ou 'Regressﾃ｣o').
        
        Returns:
            list: Lista de strings com a interpretaﾃｧﾃ｣o das mﾃｩtricas.
        """
        interpretacao = []
        
        # Caso o modelo seja de Classificaﾃｧﾃ｣o
        if model_type == "Classificaﾃｧﾃ｣o":
            # Interpretar a Acurﾃ｡cia (Accuracy)
            accuracy = float(metrics.get('Accuracy', 0))
            if accuracy > 0.9:
                interpretacao.append(f"Acurﾃ｡cia: {accuracy:.4f} - Excelente! O modelo tem uma taxa de acerto muito elevada.")
            elif accuracy > 0.75:
                interpretacao.append(f"Acurﾃ｡cia: {accuracy:.4f} - Boa, mas ainda hﾃ｡ margem para otimizaﾃｧﾃ｣o.")
            elif accuracy > 0.5:
                interpretacao.append(f"Acurﾃ｡cia: {accuracy:.4f} - Moderada. O modelo apresenta erros significativos.")
            else:
                interpretacao.append(f"Acurﾃ｡cia: {accuracy:.4f} - Fraca. O modelo precisa ser revisto e melhorado.")
            
            # Interpretar a Precisﾃ｣o (Precision)
            precision = float(metrics.get('Precision', 0))
            if precision > 0.9:
                interpretacao.append(f"Precisﾃ｣o: {precision:.4f} - Excelente! Poucos falsos positivos.")
            elif precision > 0.75:
                interpretacao.append(f"Precisﾃ｣o: {precision:.4f} - Bom, mas ainda pode melhorar.")
            elif precision > 0.5:
                interpretacao.append(f"Precisﾃ｣o: {precision:.4f} - Moderada. O modelo tem um nﾃｺmero significativo de falsos positivos.")
            else:
                interpretacao.append(f"Precisﾃ｣o: {precision:.4f} - Fraca. Muitos falsos positivos prejudicam o desempenho.")
    
            # Interpretar o Recall (Sensibilidade)
            recall = float(metrics.get('Recall', 0))
            if recall > 0.9:
                interpretacao.append(f"Recall: {recall:.4f} - Excelente! A maioria dos positivos verdadeiros sﾃ｣o identificados.")
            elif recall > 0.75:
                interpretacao.append(f"Recall: {recall:.4f} - Bom. O modelo capta a maioria dos casos positivos.")
            elif recall > 0.5:
                interpretacao.append(f"Recall: {recall:.4f} - Moderado. Alguns positivos verdadeiros nﾃ｣o estﾃ｣o a ser reconhecidos.")
            else:
                interpretacao.append(f"Recall: {recall:.4f} - Fraco. O modelo perde muitos casos positivos.")
    
            # Interpretar o F1-Score
            f1_score = float(metrics.get('F1-Score', 0))
            if f1_score > 0.9:
                interpretacao.append(f"F1-Score: {f1_score:.4f} - Excelente equilﾃｭbrio entre precisﾃ｣o e recall.")
            elif f1_score > 0.75:
                interpretacao.append(f"F1-Score: {f1_score:.4f} - Bom, mas ainda hﾃ｡ margem para melhorias.")
            elif f1_score > 0.5:
                interpretacao.append(f"F1-Score: {f1_score:.4f} - Moderado.")
            else:
                interpretacao.append(f"F1-Score: {f1_score:.4f} - Fraco.")
    
        # Caso o modelo seja de Regressﾃ｣o
        elif model_type == "Regressﾃ｣o":
            # Interpretar o Coeficiente de Determinaﾃｧﾃ｣o Rﾂｲ
            r2 = float(metrics.get('Rﾂｲ', 0))
            if r2 > 0.9:
                interpretacao.append(f"Rﾂｲ: {r2:.4f} - Excelente! O modelo explica quase toda a variabilidade dos dados.")
            elif r2 > 0.75:
                interpretacao.append(f"Rﾂｲ: {r2:.4f} - Muito bom! Explica a maioria da variabilidade dos dados.")
            elif r2 > 0.5:
                interpretacao.append(f"Rﾂｲ: {r2:.4f} - Moderado. Ainda hﾃ｡ limitaﾃｧﾃｵes no ajuste do modelo.")
            else:
                interpretacao.append(f"Rﾂｲ: {r2:.4f} - Fraco. O modelo nﾃ｣o estﾃ｡ a explicar bem a variabilidade dos dados.")
    
            # Interpretar o Erro Absoluto Mﾃｩdio (MAE)
            mae = float(metrics.get('MAE', 0))
            if mae < 0.1:
                interpretacao.append(f"MAE: {mae:.4f} - Excelente! O erro mﾃｩdio ﾃｩ muito pequeno.")
            elif mae < 1:
                interpretacao.append(f"MAE: {mae:.4f} - Bom. O erro mﾃｩdio ﾃｩ aceitﾃ｡vel.")
            else:
                interpretacao.append(f"MAE: {mae:.4f} - Alto. As previsﾃｵes desviam-se significativamente dos valores reais.")
    
            # Interpretar o Erro Quadrﾃ｡tico Mﾃｩdio (MSE)
            mse = float(metrics.get('MSE', 0))
            if mse < 0.1:
                interpretacao.append(f"MSE: {mse:.4f} - Excelente! O erro quadrﾃ｡tico mﾃｩdio ﾃｩ muito baixo.")
            elif mse < 1:
                interpretacao.append(f"MSE: {mse:.4f} - Bom. O erro ﾃｩ relativamente baixo.")
            else:
                interpretacao.append(f"MSE: {mse:.4f} - Alto. O modelo tem um erro significativo.")
    
        return interpretacao
    
    # Gerar interpretaﾃｧﾃｵes para os modelos com e sem seleﾃｧﾃ｣o de features
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Modelo Sem Seleﾃｧﾃ｣o de Features"), ln=True)
    pdf.set_font("Arial", size=10)
    
    # Adicionar interpretaﾃｧﾃ｣o do modelo sem seleﾃｧﾃ｣o de features
    for line in generate_metrics_interpretation(original_metrics, model_type):
        pdf.multi_cell(0, 8, txt=clean_text(f"窶｢ {line}"))
    
    pdf.ln(5)
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt=clean_text("Modelo Com Seleﾃｧﾃ｣o de Features"), ln=True)
    pdf.set_font("Arial", size=10)
    
    # Adicionar interpretaﾃｧﾃ｣o do modelo com seleﾃｧﾃ｣o de features
    for line in generate_metrics_interpretation(selected_metrics, model_type):
        pdf.multi_cell(0, 8, txt=clean_text(f"窶｢ {line}"))
    
    # Conclusﾃ｣o
    pdf.ln(10)
    pdf.set_font("Arial", style="B", size=14)
    pdf.cell(0, 10, txt=clean_text("Conclusﾃ｣o"), ln=True)
    
    # Escolher a mﾃｩtrica principal para avaliaﾃｧﾃ｣o do modelo
    scoring_metric = session_state.get("selected_scoring", None)
    if not scoring_metric or scoring_metric not in metric_columns:
        main_metric = 'Rﾂｲ' if model_type == "Regressﾃ｣o" else 'F1-Score'
    else:
        main_metric = scoring_metric
    
    # Obter valores da mﾃｩtrica principal
    original_value = original_metrics.get(main_metric, 0)
    selected_value = selected_metrics.get(main_metric, 0)
    
    # Conclusﾃ｣o baseada no desempenho
    pdf.set_font("Arial", size=10)
    conclusion_text = f"Com base na mﾃｩtrica principal ({main_metric}), o modelo {best_model} apresentou o melhor desempenho."
    pdf.multi_cell(0, 8, txt=clean_text(conclusion_text))
    
    if original_value > selected_value:
        recommendation_text = "Recomenda-se utilizar o modelo sem seleﾃｧﾃ｣o de features, pois apresentou melhor desempenho geral."
    else:
        feature_reduction = session_state.X_train.shape[1] - session_state.X_train_selected.shape[1]
        recommendation_text = f"Recomenda-se utilizar o modelo com seleﾃｧﾃ｣o de features, pois alﾃｩm de melhorar o desempenho, reduziu a dimensionalidade em {feature_reduction} features."
    
    pdf.multi_cell(0, 8, txt=clean_text(recommendation_text))
    
    # Guardar o PDF
    pdf_buffer = BytesIO()
    pdf_output = pdf.output(dest='S').encode('latin1', errors='ignore')
    pdf_buffer.write(pdf_output)
    pdf_buffer.seek(0)
    return pdf_buffer


# Funﾃｧﾃ｣o para exibir a pﾃ｡gina final com o relatﾃｳrio
# Mapeamento de nomes de mﾃｩtricas para as colunas do DataFrame
METRIC_MAPPING = {
    "accuracy": "Accuracy",
    "precision": "Precision", 
    "recall": "Recall",
    "f1-score": "F1-Score",
    "r2": "Rﾂｲ",
    "Rﾂｲ": "Rﾂｲ",  # Adicionar mapeamento direto para Rﾂｲ
    "r-squared": "Rﾂｲ",
    "coefficient_of_determination": "Rﾂｲ",
    "mean_squared_error": "MSE",
    "mse": "MSE",  # Adicionar versﾃ｣o minﾃｺscula de MSE
    "mean_absolute_error": "MAE",
    "mae": "MAE"  # Adicionar versﾃ｣o minﾃｺscula de MAE
}

def get_metric_mapping(metric):
    """
    Funﾃｧﾃ｣o para obter o nome da mﾃｩtrica de forma mais flexﾃｭvel
    
    Args:
        metric (str): Nome da mﾃｩtrica a ser mapeada
    
    Returns:
        str: Nome da mﾃｩtrica mapeado ou None se nﾃ｣o encontrado
    """
    # Garantir que seja uma string
    if not isinstance(metric, str):
        st.write(f"Metric nﾃ｣o ﾃｩ uma string: {metric}, tipo: {type(metric)}")
        return None
    
    # Converter para minﾃｺsculas, remover espaﾃｧos, acentos
    import unidecode # Normaliza caracteres acentuados, ﾃｺtil para lidar com strings em diferentes idiomas.
    metric_clean = unidecode.unidecode(metric.lower().replace(' ', '').replace('-', '').replace('_', ''))
    
    # Verificar se a mﾃｩtrica jﾃ｡ estﾃ｡ diretamente no formato esperado
    if metric in METRIC_MAPPING.values():
        return metric
    
    # Dicionﾃ｡rio expandido de mapeamentos
    extended_mapping = {
        **METRIC_MAPPING,
        "r2score": "Rﾂｲ",
        "rsquared": "Rﾂｲ",
        "determinacao": "Rﾂｲ",
        "coeficienteajuste": "Rﾂｲ",
        "mae": "MAE",
        "erro_absoluto_medio": "MAE",
        "mean_absolute_error": "MAE",
        "erro_absoluto": "MAE",
        "mse": "MSE",
        "erro_quadratico_medio": "MSE",
        "mean_squared_error": "MSE",
        "erro_quadratico": "MSE"
    }
    
    # Tentar mapear
    mapped_metric = extended_mapping.get(metric_clean)
    
    # Se nﾃ｣o encontrou, verificar diretamente nas chaves do METRIC_MAPPING
    if mapped_metric is None and metric in METRIC_MAPPING:
        mapped_metric = METRIC_MAPPING[metric]
        
    # Adicionar debug
    st.write(f"Mﾃｩtrica original: {metric}, limpa: {metric_clean}, mapeada: {mapped_metric}")
    
    return mapped_metric
    
def final_page():
    st.title("Resumo Final dos Modelos Treinados")

    # **CONFIGURAﾃﾃ髭S UTILIZADAS**
    st.subheader("Configuraﾃｧﾃｵes Utilizadas")

    # Tipo de Modelo
    model_type = st.session_state.get('model_type', 'Indefinido')
    st.write(f"**Tipo de Modelo:** {model_type}")

    # Modelo Selecionado
    selected_model_name = st.session_state.get('selected_model_name', 'Nﾃ｣o Selecionado')
    st.write(f"**Modelo Selecionado:** {selected_model_name}")

    # Recupera mﾃｩtricas salvas (sem re-treinar)
    original_metrics = st.session_state.get('resultado_sem_selecao', {})
    selected_metrics = st.session_state.get('resultado_com_selecao', {})

    # Exibir estatﾃｭsticas sobre os conjuntos de dados
    if 'X_train' in st.session_state and 'X_train_selected' in st.session_state:
        X_train_original = st.session_state.X_train
        X_train_selected = st.session_state.X_train_selected
        
        # Calcular percentuais
        total_samples = X_train_original.shape[0] + st.session_state.X_test.shape[0]
        train_percent = (X_train_original.shape[0] / total_samples) * 100
        test_percent = (st.session_state.X_test.shape[0] / total_samples) * 100
        
        st.subheader("投 Informaﾃｧﾃｵes dos Conjuntos de Dados")
        st.write(f"窶｢ Amostras de Treino: {X_train_original.shape[0]} ({train_percent:.1f}% do total)")
        st.write(f"窶｢ Amostras de Teste: {st.session_state.X_test.shape[0]} ({test_percent:.1f}% do total)")
        st.write(f"窶｢ Features Originais: {st.session_state.X_train_original.shape[1] if 'X_train_original' in st.session_state else X_train_original.shape[1]}")
        st.write(f"窶｢ Features Apﾃｳs Seleﾃｧﾃ｣o: {X_train_selected.shape[1]}")

    # Recuperar features selecionadas
    if 'selected_features' in st.session_state:
        st.subheader("笨 Features Selecionadas")
        st.write(st.session_state.selected_features)

    # Recupera a mﾃｩtrica escolhida para seleﾃｧﾃ｣o de features
    scoring_metric = st.session_state.get("selected_scoring", None)

    # Validar se a mﾃｩtrica foi definida
    if not scoring_metric:
        st.error("Nenhuma mﾃｩtrica foi selecionada. Volte para a etapa de Seleﾃｧﾃ｣o de Features.")
        return

    # Obter o nome capitalizado da mﾃｩtrica com base no mapeamento
    scoring_metric_capitalized = get_metric_mapping(scoring_metric)
    if not scoring_metric_capitalized:
        st.error(f"A mﾃｩtrica '{scoring_metric}' nﾃ｣o ﾃｩ vﾃ｡lida ou nﾃ｣o estﾃ｡ disponﾃｭvel.")
        return

    # **COMPARAﾃﾃグ DE Mﾃ欝RICAS**
    st.subheader("Comparaﾃｧﾃ｣o de Mﾃｩtricas")

    # Formatar valores com 4 casas decimais
    def format_metric(value):
        try:
            return float(f"{float(value):.4f}")
        except (ValueError, TypeError):
            return None

    # Criar tabela de mﾃｩtricas
    if model_type == "Classificaﾃｧﾃ｣o":
        comparison_df = pd.DataFrame({
            'Modelo': ['Sem Seleﾃｧﾃ｣o de Features', 'Com Seleﾃｧﾃ｣o de Features'],
            'Accuracy': [
                format_metric(original_metrics.get('Accuracy', 'N/A')),
                format_metric(selected_metrics.get('Accuracy', 'N/A'))
            ],
            'Precision': [
                format_metric(original_metrics.get('Precision', 'N/A')),
                format_metric(selected_metrics.get('Precision', 'N/A'))
            ],
            'Recall': [
                format_metric(original_metrics.get('Recall', 'N/A')),
                format_metric(selected_metrics.get('Recall', 'N/A'))
            ],
            'F1-Score': [
                format_metric(original_metrics.get('F1-Score', 'N/A')),
                format_metric(selected_metrics.get('F1-Score', 'N/A'))
            ],
            'Best Parameters': [
                st.session_state.get('best_params', 'N/A'),
                st.session_state.get('best_params_selected', 'N/A')
            ]
        })
    elif model_type == "Regressﾃ｣o":
        comparison_df = pd.DataFrame({
            'Modelo': ['Sem Seleﾃｧﾃ｣o de Features', 'Com Seleﾃｧﾃ｣o de Features'],
            'Rﾂｲ': [
                format_metric(original_metrics.get('Rﾂｲ', 'N/A')),
                format_metric(selected_metrics.get('Rﾂｲ', 'N/A'))
            ],
            'MAE': [
                format_metric(original_metrics.get('MAE', 'N/A')),
                format_metric(selected_metrics.get('MAE', 'N/A'))
            ],
            'MSE': [
                format_metric(original_metrics.get('MSE', 'N/A')),
                format_metric(selected_metrics.get('MSE', 'N/A'))
            ],
            'Best Parameters': [
                st.session_state.get('best_params', 'N/A'),
                st.session_state.get('best_params_selected', 'N/A')
            ]
        })
    else:
        st.error("Tipo de modelo nﾃ｣o reconhecido. Nﾃ｣o ﾃｩ possﾃｭvel gerar a tabela de mﾃｩtricas.")
        return

    # Exibir tabela de mﾃｩtricas com ajustes finos
    st.dataframe(comparison_df.style.format({
        'Accuracy': '{:.4f}' if 'Accuracy' in comparison_df.columns else None,
        'Precision': '{:.4f}' if 'Precision' in comparison_df.columns else None,
        'Recall': '{:.4f}' if 'Recall' in comparison_df.columns else None,
        'F1-Score': '{:.4f}' if 'F1-Score' in comparison_df.columns else None,
        'Rﾂｲ': '{:.4f}' if 'Rﾂｲ' in comparison_df.columns else None,
        'MAE': '{:.4f}' if 'MAE' in comparison_df.columns else None,
        'MSE': '{:.4f}' if 'MSE' in comparison_df.columns else None,
    }).set_table_styles([
        {'selector': 'th', 'props': [('font-size', '14px'), ('background-color', '#f0f0f0'), ('text-align', 'center'), ('font-weight', 'bold')]},  # Cabeﾃｧalho
        {'selector': 'td', 'props': [('font-size', '14px'), ('text-align', 'center')]},  # Tamanho das cﾃｩlulas e alinhamento
        {'selector': 'table', 'props': [('width', '100%'), ('border-collapse', 'collapse')]},  # Largura da tabela e bordas
        {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#f9f9f9')]},  # Cor de fundo alternada para as linhas
        {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#ffffff')]},  # Cor de fundo para linhas ﾃｭmpares
    ]))

    # Verificar se a mﾃｩtrica escolhida existe no DataFrame
    if scoring_metric_capitalized not in comparison_df.columns:
        st.error(f"A mﾃｩtrica '{scoring_metric}' nﾃ｣o estﾃ｡ disponﾃｭvel no DataFrame.")
        return


    # **GRﾃ：ICOS DAS Mﾃ欝RICAS**
    st.subheader("Grﾃ｡fico Interativo de Comparaﾃｧﾃ｣o de Mﾃｩtricas")

    # Determinar as mﾃｩtricas disponﾃｭveis com base no tipo de modelo
    if model_type == "Classificaﾃｧﾃ｣o":
        metric_columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    elif model_type == "Regressﾃ｣o":
        metric_columns = ['Rﾂｲ', 'MAE', 'MSE']
    else:
        st.error("Tipo de modelo nﾃ｣o reconhecido. Nﾃ｣o ﾃｩ possﾃｭvel gerar grﾃ｡ficos.")
        return

    # Adicionar um filtro interativo para a seleﾃｧﾃ｣o da mﾃｩtrica
    selected_metric = st.selectbox(
        "Selecione a mﾃｩtrica para visualizar:",
        metric_columns,
        index=0  # Mﾃｩtrica padrﾃ｣o exibida no inﾃｭcio
    )

    # Criar o grﾃ｡fico apenas para a mﾃｩtrica selecionada
    if selected_metric in comparison_df.columns:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Dados para o grﾃ｡fico
        bars = ax.bar(
            comparison_df['Modelo'],
            comparison_df[selected_metric],
            color=['#9ACD32', '#006400']  # Verde claro e verde escuro
        )
        
        # Adicionar valores nas barras
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.4f}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom',
                        fontsize=12)
        
        ax.set_title(f"Comparaﾃｧﾃ｣o de {selected_metric}", fontsize=14)
        ax.set_ylabel(selected_metric, fontsize=12)
        ax.set_xlabel("Modelo", fontsize=12)
        
        # Ajustar altura para caber os valores
        plt.ylim(0, max(comparison_df[selected_metric]) * 1.1)
        
        # Exibir grﾃ｡fico no Streamlit
        st.pyplot(fig)
    else:
        st.error(f"A mﾃｩtrica selecionada '{selected_metric}' nﾃ｣o estﾃ｡ disponﾃｭvel.")

    # **DETERMINAR O MELHOR MODELO BASEADO NA Mﾃ欝RICA ESCOLHIDA**
    scoring_values = comparison_df[scoring_metric_capitalized].values  # Recupera os valores da mﾃｩtrica na tabela
    if len(scoring_values) == 2:  # Certifique-se de que existem dois valores (sem e com seleﾃｧﾃ｣o)
        score_without_selection = scoring_values[0]
        score_with_selection = scoring_values[1]

        # Determina o melhor modelo
        if score_with_selection > score_without_selection:
            best_model = "Com Seleﾃｧﾃ｣o de Features"
            best_score = score_with_selection
        else:
            best_model = "Sem Seleﾃｧﾃ｣o de Features"
            best_score = score_without_selection
    else:
        st.warning("Erro na determinaﾃｧﾃ｣o das mﾃｩtricas na tabela.")
        return

    # Exibir mensagem com o melhor modelo
    st.success(f"脂 **O melhor modelo ﾃｩ:** {best_model} com base na mﾃｩtrica: {scoring_metric_capitalized} ({best_score:.4f})")

    # **INTERPRETAﾃﾃグ DAS Mﾃ欝RICAS**
    st.subheader("Interpretaﾃｧﾃ｣o das Mﾃｩtricas")
    try:
        # Gerar interpretaﾃｧﾃ｣o para cada modelo
        if model_type == "Classificaﾃｧﾃ｣o":
            interpretation_without = generate_metrics_interpretation(original_metrics)
            interpretation_with = generate_metrics_interpretation(selected_metrics)
        elif model_type == "Regressﾃ｣o":
            interpretation_without = generate_regression_interpretation(original_metrics)
            interpretation_with = generate_regression_interpretation(selected_metrics)
        else:
            raise ValueError("Tipo de modelo desconhecido para interpretaﾃｧﾃ｣o.")

        # Exibir interpretaﾃｧﾃｵes
        st.write("### Sem Seleﾃｧﾃ｣o de Features")
        st.write(interpretation_without)

        st.write("### Com Seleﾃｧﾃ｣o de Features")
        st.write(interpretation_with)
    except Exception as e:
        st.error(f"Erro ao gerar a interpretaﾃｧﾃ｣o das mﾃｩtricas: {e}")
        
    # **DOWNLOAD DO MODELO TREINADO**
    st.subheader("Download do Melhor Modelo Treinado")
    model = st.session_state.models.get(st.session_state.selected_model_name)
    model_filename = save_best_model(model, with_feature_selection=(best_model == "Com Seleﾃｧﾃ｣o de Features"))

    if model_filename:
        with open(model_filename, "rb") as file:
            st.download_button(
                label="沈 Download Melhor Modelo",
                data=file,
                file_name=model_filename,
                mime="application/octet-stream",
            )

    # **DOWNLOAD DO RELATﾃ迭IO EM PDF**
    try:
        pdf_buffer = gerar_relatorio_pdf(comparison_df, best_model, st.session_state)
        pdf_file_name = f"relatorio_final_{st.session_state.get('selected_model_name', 'modelo')}.pdf"
        st.download_button(
            label="沈 Download Relatﾃｳrio PDF",
            data=pdf_buffer,
            file_name=pdf_file_name,
            mime="application/pdf",
        )
    except Exception as e:
        st.error(f"Erro ao gerar relatﾃｳrio em PDF: {e}")

    # **CONCLUIR**
    if st.button("Concluir"):
        st.session_state.clear()  # Limpa o cache do Streamlit
        st.rerun()

############ Relatﾃｳrio Final para Clustering ###################
# Classe personalizada para PDF
class CustomPDF(FPDF):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Baixar o logo no inﾃｭcio para reutilizﾃ｡-lo
        self.logo_path = None
        logo_url = 'https://www.ipleiria.pt/normasgraficas/wp-content/uploads/sites/80/2017/09/estg_v-01.jpg'
        try:
            response = requests.get(logo_url)
            if response.status_code == 200:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmpfile:
                    tmpfile.write(response.content)
                    self.logo_path = tmpfile.name
        except Exception as e:
            print(f"Erro ao baixar o logo: {e}")

    def header(self):
        # Posicionar o cabeﾃｧalho no topo da pﾃ｡gina
        self.set_y(10)
        
        # Adicionar a imagem no cabeﾃｧalho se o logo foi baixado com sucesso
        if self.logo_path:
            self.image(self.logo_path, 10, 10, 25)
        
        # Configurar fonte para o tﾃｭtulo
        self.set_font('Arial', 'B', 12)
        
        # Adicionar o tﾃｭtulo centralizado
        # Deixar espaﾃｧo para o logo
        self.cell(25)  # Espaﾃｧo para o logo
        self.cell(0, 10, 'MLCase - Plataforma de Machine Learning', 0, 0, 'C')
        
        # Adicionar uma linha horizontal apﾃｳs o cabeﾃｧalho
        self.ln(15)
        self.ln(5)  # Espaﾃｧo apﾃｳs o cabeﾃｧalho

    def footer(self):
        # Ir para 1.5 cm da parte inferior
        self.set_y(-20)
        
        # Adicionar uma linha horizontal antes do rodapﾃｩ
        self.line(10, self.get_y(), 200, self.get_y())
        self.ln(3)
        
        # Definir fonte para o rodapﾃｩ
        self.set_font('Arial', 'I', 8)
        
        # Data atual
        current_date = datetime.now().strftime('%d/%m/%Y')
        
        # Adicionar rodapﾃｩ com a data e nﾃｺmero da pﾃ｡gina
        self.cell(0, 10, f'{current_date} - Pﾃ｡gina {self.page_no()}  |  Autora da Plataforma: Bruna Sousa', 0, 0, 'C')
# Funﾃｧﾃ｣o para gerar o relatﾃｳrio PDF
import os
import matplotlib.pyplot as plt
from fpdf import FPDF
from io import BytesIO

def gerar_relatorio_clustering_pdf(initial_metrics, retrain_metrics, best_model_type, st_session):
    pdf = CustomPDF(format='A4')
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()

    # Tﾃｭtulo
    pdf.set_font("Arial", style="B", size=16)
    pdf.cell(0, 10, txt="Relatﾃｳrio Final do Modelo Treinados", ln=True, align="C")
    pdf.ln(10)

    # Modelo Selecionado
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(50, 10, txt="Modelo Selecionado:", ln=False)
    pdf.set_font("Arial", size=12)
    model_info = st_session['selected_model_name']
    
    # Adicionar informaﾃｧﾃ｣o de componentes para KMeans e Clustering Hierﾃ｡rquico
    if st_session['selected_model_name'] in ["KMeans", "Clustering Hierﾃ｡rquico"]:
        model_info += f" (PCA: {st_session.get('pca_n_components', 'N/A')} componentes)"
    
    pdf.cell(0, 10, txt=model_info, ln=True)
    pdf.ln(5)

    # Melhor Modelo
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(50, 10, txt="Melhor Modelo Treinado:", ln=False)
    pdf.set_font("Arial", size=12)
    pdf.cell(0, 10, txt=best_model_type, ln=True)
    pdf.ln(10)

    # Adicionar mﾃｩtricas do treino inicial e re-treino
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt="Mﾃｩtricas Obtidas", ln=True)
    pdf.set_font("Arial", size=9)
    pdf.set_fill_color(200, 220, 255)

    # Cabeﾃｧalho da tabela
    pdf.set_fill_color(144, 238, 144)  # Verde claro (light green)
    col_widths = [40, 40, 40, 40]
    pdf.cell(col_widths[0], 10, "Treino", 1, 0, 'C', True)
    pdf.cell(col_widths[1], 10, "Silhouette Score", 1, 0, 'C', True)
    pdf.cell(col_widths[2], 10, "Davies-Bouldin Index", 1, 0, 'C', True)
    pdf.cell(col_widths[3], 10, "Calinski-Harabasz Score", 1, 1, 'C', True)

    # Dados da tabela
    pdf.set_font("Arial", size=8)
    pdf.cell(col_widths[0], 10, "Treino Inicial", 1, 0, 'C')
    pdf.cell(col_widths[1], 10, f"{initial_metrics['Silhouette Score']:.2f}", 1, 0, 'C')
    pdf.cell(col_widths[2], 10, f"{initial_metrics['Davies-Bouldin Index']:.2f}", 1, 0, 'C')
    pdf.cell(col_widths[3], 10, f"{initial_metrics['Calinski-Harabasz Score']:.2f}", 1, 1, 'C')

    if retrain_metrics:
        pdf.cell(col_widths[0], 10, "Re-Treino", 1, 0, 'C')
        pdf.cell(col_widths[1], 10, f"{retrain_metrics['Silhouette Score']:.2f}", 1, 0, 'C')
        pdf.cell(col_widths[2], 10, f"{retrain_metrics['Davies-Bouldin Index']:.2f}", 1, 0, 'C')
        pdf.cell(col_widths[3], 10, f"{retrain_metrics['Calinski-Harabasz Score']:.2f}", 1, 1, 'C')

    pdf.ln(10)

    # Adicionar interpretaﾃｧﾃｵes
    def add_interpretation(metrics, treino_name):
        pdf.set_font("Arial", size=10)
        pdf.cell(0, 10, txt=f"{treino_name}:", ln=True)
        pdf.multi_cell(0, 10, txt=f"  Silhouette Score: {metrics['Silhouette Score']:.2f} - "
                                  f"{'Excelente' if metrics['Silhouette Score'] > 0.75 else 'Bom' if metrics['Silhouette Score'] > 0.5 else 'Moderado' if metrics['Silhouette Score'] > 0.25 else 'Fraco'} separaﾃｧﾃ｣o entre clusters.")
        pdf.multi_cell(0, 10, txt=f"  Davies-Bouldin Index: {metrics['Davies-Bouldin Index']:.2f} - "
                                  f"{'Muito bom' if metrics['Davies-Bouldin Index'] < 0.5 else 'Bom' if metrics['Davies-Bouldin Index'] < 1.0 else 'Moderado' if metrics['Davies-Bouldin Index'] < 2.0 else 'Fraco'} compactaﾃｧﾃ｣o e separaﾃｧﾃ｣o.")
        pdf.multi_cell(0, 10, txt=f"  Calinski-Harabasz Score: {metrics['Calinski-Harabasz Score']:.2f} - "
                                  f"{'Excelente' if metrics['Calinski-Harabasz Score'] > 2500 else 'Bom' if metrics['Calinski-Harabasz Score'] > 1500 else 'Moderado' if metrics['Calinski-Harabasz Score'] > 500 else 'Fraco'} densidade e separaﾃｧﾃ｣o.")
        pdf.ln(5)

    add_interpretation(initial_metrics, "Treino Inicial")
    if retrain_metrics:
        add_interpretation(retrain_metrics, "Re-Treino")

    # Adicionar grﾃ｡ficos
    metrics_to_plot = ["Silhouette Score", "Davies-Bouldin Index", "Calinski-Harabasz Score"]
    graphs = []
    for metric in metrics_to_plot:
        plt.figure(figsize=(6, 4))
        labels = ["Treino Inicial"]
        values = [initial_metrics[metric]]
        if retrain_metrics:
            labels.append("Re-Treino")
            values.append(retrain_metrics[metric])
        plt.bar(labels, values, color=['#90EE90', '#006400'], edgecolor='black')
        plt.title(f"{metric} por Treino")
        plt.ylabel(metric)
        plt.xlabel("Treino")
        graph_path = f"temp_{metric.replace(' ', '_')}.png"
        plt.savefig(graph_path)
        plt.close()
        graphs.append(graph_path)

    # Inserir grﾃ｡ficos no PDF
    pdf.add_page()
    pdf.set_font("Arial", style="B", size=12)
    pdf.cell(0, 10, txt="Grﾃ｡ficos das Mﾃｩtricas", ln=True, align='C')
    pdf.ln(10)

    x_offset = 10
    y_offset = pdf.get_y()
    for i, graph in enumerate(graphs):
        pdf.image(graph, x=x_offset, y=y_offset, w=90, h=70)
        x_offset += 100
        if (i + 1) % 2 == 0:  # Nova linha a cada dois grﾃ｡ficos
            x_offset = 10
            y_offset += 75
        os.remove(graph)  # Remover o arquivo temporﾃ｡rio apﾃｳs usﾃ｡-lo

    # Salvar o PDF no buffer
    pdf_buffer = BytesIO()
    pdf_output = pdf.output(dest='S').encode('latin1')
    pdf_buffer.write(pdf_output)
    pdf_buffer.seek(0)

    return pdf_buffer

# Pﾃ｡gina final para clustering
def clustering_final_page():
    st.title("Relatﾃｳrio Final do Clustering")

    # Verificar se os dados estﾃ｣o disponﾃｭveis
    if "selected_model_name" not in st.session_state or "initial_metrics" not in st.session_state:
        st.error("Nenhuma informaﾃｧﾃ｣o de clustering disponﾃｭvel. Por favor, execute o treino primeiro.")
        return

    # Mostrar o modelo selecionado
    st.subheader("Modelo Selecionado")
    st.write(f"**Modelo:** {st.session_state.selected_model_name}")

    # Adicionar informaﾃｧﾃ｣o sobre o nﾃｺmero de componentes
    if st.session_state.selected_model_name in ["KMeans", "Clustering Hierﾃ｡rquico"]:
        st.write(f"**Nﾃｺmero de Componentes PCA:** {st.session_state.get('pca_n_components', 'N/A')}")
    
# Exibir mﾃｩtricas do treino inicial
    st.subheader("Mﾃｩtricas do Treino Inicial")
    st.table(fix_dataframe_types(pd.DataFrame([st.session_state.initial_metrics])))

    # Interpretaﾃｧﾃ｣o personalizada para o treino inicial
    initial_metrics = st.session_state.initial_metrics
    st.write("**Interpretaﾃｧﾃ｣o do Treino Inicial:**")
    st.markdown(f"""
    - **Silhouette Score:** {initial_metrics["Silhouette Score"]:.2f} - {"Excelente" if initial_metrics["Silhouette Score"] > 0.75 else "Bom" if initial_metrics["Silhouette Score"] > 0.5 else "Moderado" if initial_metrics["Silhouette Score"] > 0.25 else "Fraco"} separaﾃｧﾃ｣o entre clusters.
    - **Davies-Bouldin Index:** {initial_metrics["Davies-Bouldin Index"]:.2f} - {"Muito bom" if initial_metrics["Davies-Bouldin Index"] < 0.5 else "Bom" if initial_metrics["Davies-Bouldin Index"] < 1.0 else "Moderado" if initial_metrics["Davies-Bouldin Index"] < 2.0 else "Fraco"} compactaﾃｧﾃ｣o e separaﾃｧﾃ｣o.
    - **Calinski-Harabasz Score:** {initial_metrics["Calinski-Harabasz Score"]:.2f} - {"Excelente" if initial_metrics["Calinski-Harabasz Score"] > 2500 else "Bom" if initial_metrics["Calinski-Harabasz Score"] > 1500 else "Moderado" if initial_metrics["Calinski-Harabasz Score"] > 500 else "Fraco"} densidade e separaﾃｧﾃ｣o.
    """)

    # Exibir mﾃｩtricas do re-treino (se disponﾃｭveis)
    retrain_silhouette_score = None  # Inicializa como None para evitar erros
    if "retrain_metrics" in st.session_state:
        st.subheader("Mﾃｩtricas do Re-Treino")
        st.table(fix_dataframe_types(pd.DataFrame([st.session_state.retrain_metrics])))

        # Interpretaﾃｧﾃ｣o personalizada para o re-treino
        retrain_metrics = st.session_state.retrain_metrics
        retrain_silhouette_score = retrain_metrics["Silhouette Score"]
        st.write("**Interpretaﾃｧﾃ｣o do Re-Treino:**")
        st.markdown(f"""
        - **Silhouette Score:** {retrain_metrics["Silhouette Score"]:.2f} - {"Excelente" if retrain_metrics["Silhouette Score"] > 0.75 else "Bom" if retrain_metrics["Silhouette Score"] > 0.5 else "Moderado" if retrain_metrics["Silhouette Score"] > 0.25 else "Fraco"} separaﾃｧﾃ｣o entre clusters.
        - **Davies-Bouldin Index:** {retrain_metrics["Davies-Bouldin Index"]:.2f} - {"Muito bom" if retrain_metrics["Davies-Bouldin Index"] < 0.5 else "Bom" if retrain_metrics["Davies-Bouldin Index"] < 1.0 else "Moderado" if retrain_metrics["Davies-Bouldin Index"] < 2.0 else "Fraco"} compactaﾃｧﾃ｣o e separaﾃｧﾃ｣o.
        - **Calinski-Harabasz Score:** {retrain_metrics["Calinski-Harabasz Score"]:.2f} - {"Excelente" if retrain_metrics["Calinski-Harabasz Score"] > 2500 else "Bom" if retrain_metrics["Calinski-Harabasz Score"] > 1500 else "Moderado" if retrain_metrics["Calinski-Harabasz Score"] > 500 else "Fraco"} densidade e separaﾃｧﾃ｣o.
        """)

    # Determinar o melhor modelo considerando apenas o Silhouette Score
    if retrain_silhouette_score is not None and retrain_silhouette_score > initial_metrics["Silhouette Score"]:
        melhor_modelo = "Re-Treino"
        best_metrics = st.session_state.retrain_metrics
        best_model = st.session_state.models[st.session_state.selected_model_name]
    else:
        melhor_modelo = "Treino Inicial"
        best_metrics = st.session_state.initial_metrics
        best_model = st.session_state.models[st.session_state.selected_model_name]

    st.subheader("Melhor Modelo")
    st.success(f"脂 **{melhor_modelo}** com Silhouette Score: {max(initial_metrics['Silhouette Score'], retrain_silhouette_score or 0):.4f}")


    # **Grﾃ｡ficos Interativos das Mﾃｩtricas**
    st.subheader("Grﾃ｡fico Interativo de Mﾃｩtricas")
    metrics_to_plot = ["Silhouette Score", "Davies-Bouldin Index", "Calinski-Harabasz Score"]
    selected_metric = st.selectbox("Selecione a mﾃｩtrica para visualizar:", metrics_to_plot)
    
    # Criar o grﾃ｡fico
    if selected_metric:
        # Verificar se os dados do re-treino estﾃ｣o presentes
        if "retrain_metrics" in st.session_state:
            # Se o re-treino foi realizado, exibe "Treino Inicial" e "Re-Treino"
            data_to_plot = pd.DataFrame({
                "Treino": ["Treino Inicial", "Re-Treino"],
                selected_metric: [
                    initial_metrics[selected_metric],
                    retrain_metrics[selected_metric]
                ]
            })
        else:
            # Se o re-treino nﾃ｣o foi realizado, exibe todas as mﾃｩtricas para "Treino Inicial"
            data_to_plot = pd.DataFrame({
                "Treino": ["Treino Inicial"] * len(metrics_to_plot),
                selected_metric: [initial_metrics[metric] for metric in metrics_to_plot]
            })
    
        # Criar grﾃ｡fico com base nos dados disponﾃｭveis
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.bar(data_to_plot["Treino"], data_to_plot[selected_metric], color=['#a8ddb5', '#005a32'], edgecolor='black')
        ax.set_title(f"Comparaﾃｧﾃ｣o de {selected_metric}", fontsize=14, fontweight='bold')
        ax.set_ylabel(selected_metric, fontsize=12)
        ax.set_xlabel("Treino", fontsize=12)
        ax.tick_params(axis='both', which='major', labelsize=10)
        st.pyplot(fig) 


    # Gerar o relatﾃｳrio PDF
    pdf_buffer = gerar_relatorio_clustering_pdf(
        initial_metrics,
        st.session_state.get("retrain_metrics"),
        melhor_modelo,
        st.session_state
    )

    # Botﾃ｣o para download do relatﾃｳrio em PDF
    pdf_filename = f"Relatorio__{st.session_state.selected_model_name}_{st.session_state.model_type}_{melhor_modelo.replace(' ', '_').lower()}.pdf"
    st.download_button(
        label="Baixar Relatﾃｳrio em PDF",
        data=pdf_buffer,
        file_name=pdf_filename,
        mime="application/pdf"
    )

    # Botﾃ｣o para download do melhor modelo treinado
    model_buffer = BytesIO()
    pickle.dump(best_model, model_buffer)
    model_buffer.seek(0)

    st.download_button(
        label="Baixar Melhor Modelo Treinado",
        data=model_buffer,
        file_name=f"melhor_modelo_{melhor_modelo.replace(' ', '_').lower()}.pkl",
        mime="application/octet-stream"
    )

    # Botﾃ｣o para concluir o processo
    if st.button("Concluir"):
        st.info("Clustering finalizado. Redirecionando para o inﾃｭcio...")
        st.session_state.clear()
        st.session_state.step = 'file_upload'
        st.rerun()

def initialize_session_state():
    # Inicializando as variﾃ｡veis principais de estado
    default_values = {
        'step': 'file_upload',
        'page': 'file_upload',
        'data': None,
        'target_column': None,
        'target_column_confirmed': False,
        'validation_method': None,
        'validation_confirmed': False,
        'model_type': None,
        'model_type_confirmed': False,
        'X_train': None,
        'X_test': None,
        'y_train': None,
        'y_test': None,
        'knn_neighbors': 5,
        'rf_estimators': 100,
        'svc_kernel': 'rbf',
        'kmeans_clusters': 3,
        'feature_selection_done': False,
        'X_train_selected': None,
        'X_test_selected': None,
        'model_name': None,
        'selected_model': None,
        'selected_model_name': None,
        'models': {
            "Support Vector Classification (SVC)": SVC(),
            "K-Nearest Neighbors (KNN)": KNeighborsClassifier(),
            "Random Forest": RandomForestClassifier(),
            "KMeans": KMeans(),
            "Clustering Hierﾃ｡rquico": AgglomerativeClustering(linkage='ward'),
            "Regressﾃ｣o Linear Simples (RLS)": LinearRegression(),
            "Regressﾃ｣o por Vetores de Suporte (SVR)": SVR(),
        },
        'model_trained': False,
        'clustering_final_page': False,  # Pﾃ｡gina do relatﾃｳrio final de clustering
        'grid_search_confirmed': False,  # Adicionando grid_search_confirmed ao estado
        'manual_params': {}, # Inicializando manual_params como um dicionﾃ｡rio vazio
        'best_params_str': {},
        'treinos_realizados': [],  # Inicializando a lista de treinos realizados
        'scoring_confirmed': False,  # Inicializando scoring_confirmed
        'target_column_type': None,  # Adiciona tipo da coluna alvo
        'selected_scoring': 'F1-Score'  # Inicializando 'selected_scoring' com o valor 'f1'
    }

    # Usando valores padrﾃ｣o para inicializar session_state
    for key, value in default_values.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # Adicionalmente, vocﾃｪ pode garantir que os parﾃ｢metros do modelo sejam vﾃ｡lidos:
    if st.session_state.knn_neighbors < 1:
        st.session_state.knn_neighbors = 5  # Default para KNN
    if st.session_state.kmeans_clusters < 1:
        st.session_state.kmeans_clusters = 3  # Default para KMeans

# Funﾃｧﾃ｣o principal
def main():
    # Inicializaﾃｧﾃ｣o das variﾃ｡veis de estado da sessﾃ｣o
    initialize_session_state()

    # Exibir estado atual para depuraﾃｧﾃ｣o
    #st.write(f"東 Estado atual: {st.session_state.step}")

    # Roteamento baseado no estado atual
    if st.session_state.step == 'file_upload':
        upload_file()
    elif st.session_state.step == 'data_preview':
        data_preview()
    elif st.session_state.step == 'missing_values':
        handle_missing_values()
    elif st.session_state.step == 'outlier_detection':
        outlier_detection()
    elif st.session_state.step == 'data_summary':
        data_summary()
    elif st.session_state.step == 'model_selection':
        model_selection()
    elif st.session_state.step == 'feature_selection':
        feature_selection()
    elif st.session_state.step == 'train_with_selected_features':  
        train_with_selected_features_page()
    elif st.session_state.step == 'evaluate_and_compare_models':
        evaluate_and_compare_models()
    elif st.session_state.step == 'clustering_final_page':  # 笨 Adicionado!
        clustering_final_page()  # 笨 Chama a funﾃｧﾃ｣o do relatﾃｳrio final de clustering
    elif st.session_state.step == 'final_page':
        final_page()
    else:
        st.error(f"笞 Etapa desconhecida: {st.session_state.step}. Reiniciando a aplicaﾃｧﾃ｣o.")
        st.session_state.step = 'file_upload'
        st.rerun()
        
    # Exibir o estado apﾃｳs a execuﾃｧﾃ｣o para depuraﾃｧﾃ｣o
    #st.write(f"Estado final: {st.session_state.step}")


if __name__ == "__main__":
    main()
